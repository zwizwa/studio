mixer

with direct out connected to delta1010 in
all post-fader
 1 guitar/bass clean
 2 guitar effect chain
 3 microbruite
 4 volca keys
 5 volca bass
 6 volca beats
 7 monitron / paia (todo)
 8 paia (todo)


from delta1010 - digital mix chain
13/14 out 1/2 

from delta1010, for routing to analog effects

15/16 out 3/4
 9    out 5
10    out 6
11    out 7
12    out 8

from intel built-in audio - pulseaudio digital mix chain
17/18 
19/20 free

sends:
aux1 pre      free
aux2 pre/post guitar effects  (pre default)
aux3 post     free

notes:

* aux send to digital in (e.g. for reverb/delay) is not really
  necessary as they can be sent digitally.

* aux1 somehow gives feedback trouble on high-gain effects chain
  (self-send not off completely?).  using aux2 in pre mode works fine.


bcr2000

top row: mixer (0-127) midi control
bittons: part mute
bottom 3 rows: synth control (incremental)


TODO:
- sync microbruite to the volcas (all on midi sync?)
- find a good sequencer
- mount all the "knobs" to a movable surface
- set up a good echo/delay digitally
- set up midi for all
- route guitar effects chain through mixer
- focus on non-portable setup first built around delta1010
- later add "easy detach" portability
- find a simple touch screen


Entry: Sequencer
Date: Fri Mar  4 18:38:06 EST 2016

Find a good sequencer, or build one.


Entry: Analog
Date: Fri Mar  4 19:31:29 EST 2016

8 channels should be enough.  All of them have direct out to
delta1010.

I have 4 channels direct 


Entry: Monoprice
Date: Fri Mar  4 20:04:54 EST 2016

- TS Single angle
- TS 


Entry: Effects send
Date: Fri Mar  4 21:06:59 EST 2016

Not sure why this didn't work earlier.  Too noisy?  Let's try again..

The reason was feedback, since this needs to be set pre-fader, and the
self-send on the return channel is too strong. It's doable for most
cases but easy to trigger.


Entry: MIDI
Date: Fri Mar  4 22:37:04 EST 2016

- map all midi devices to some other messages (osc?)
- program bcr2000 for mixerm, mute botton + inc control operation


SYNC:
http://www.sweetwater.com/sweetcare/articles/how-do-i-set-up-my-korg-volca-series-synth-module-to-sync-to-an-external-midi-clock/


Entry: udev
Date: Sat Mar  5 11:02:02 EST 2016

Fixed device names in /etc/net/udev
Next is to find a way to share the device

Using the legacy midi devices (and alsa's rawmidi?) is single-access only.
Two options:
- create a daemon that converts midi to osc
- learn how to use the alsa sequencer

Since I need the "accumulator" anyway, let's do this in erlang (exo).



Entry: Sending clock sync from Erlang
Date: Sat Mar  5 23:08:03 EST 2016

At 120bpm, 2pbs

(* 2 4 24)  192 messages per second.

5ms per message.



Entry: alsa midi
Date: Wed Mar 16 11:49:52 EDT 2016

Looks like it's necessary to use alsa midi interface, as multi-port
devices only show up with a single legacy /dev/midi? port.

Making exo/c_src/midi_in.c to simply map back to raw MIDI in erlang.
Alternatively, pass through the full binary event structs.

Next: figure out how to set tempo, send midi sync, send start/stop to
all clients at once, and configure volca's to sync to midi.


Entry: amidi / aconnect
Date: Wed Mar 16 22:16:43 EDT 2016

tom@zoo:~$ amidi -l
Dir Device    Name
IO  hw:0,0    M Audio Delta 1010 MIDI
IO  hw:3,0,0  USB Midi 4i4o MIDI 1
IO  hw:3,0,1  USB Midi 4i4o MIDI 2
IO  hw:3,0,2  USB Midi 4i4o MIDI 3
IO  hw:3,0,3  USB Midi 4i4o MIDI 4


tom@zoo:~$ aconnect -l
client 0: 'System' [type=kernel]
    0 'Timer           '
    1 'Announce        '
client 14: 'Midi Through' [type=kernel]
    0 'Midi Through Port-0'
client 16: 'M Audio Delta 1010' [type=kernel]
    0 'M Audio Delta 1010 MIDI'
client 28: 'USB Midi 4i4o' [type=kernel]
    0 'USB Midi 4i4o MIDI 1'
    1 'USB Midi 4i4o MIDI 2'
    2 'USB Midi 4i4o MIDI 3'
    3 'USB Midi 4i4o MIDI 4'


So some questions.

- Should I use the sequencer or the raw midi?  Maybe jack midi (which
is on top of raw midi) The oss midi is likely not a good idea.

- There are 4 ports, but only one /dev/midiCD0 device


This http://wiki.linuxaudio.org/faq/start
mentions alsa sequencer should be used for interconnecting applications.
Jack MIDI might just be for recording, then?

No, looks like the reason has to do with high-resolution timing.
250kHz not being enough.

I wonder, is it possible to have the time sync sent out by the sequencer?
http://www.alsa-project.org/~tiwai/alsa-sync.html


Entry: alsa timers
Date: Wed Mar 16 23:32:34 EDT 2016

tom@tp:~$ cat /proc/asound/timers 
G0: system timer : 4000.000us (10000000 ticks)
G3: HR timer : 0.001us (1000000000 ticks)
P0-0-0: PCM playback 0-0-0 : SLAVE
P0-0-1: PCM capture 0-0-1 : SLAVE
P0-3-0: PCM playback 0-3-0 : SLAVE

tom@zoo:~$ cat /proc/asound/timers 
G0: system timer : 4000.000us (10000000 ticks)
P0-0-0: PCM playback 0-0-0 : SLAVE
P0-0-1: PCM capture 0-0-1 : SLAVE
P1-0-0: PCM playback 1-0-0 : SLAVE
P1-0-1: PCM capture 1-0-1 : SLAVE
P1-2-1: PCM capture 1-2-1 : SLAVE
P2-3-0: PCM playback 2-3-0 : SLAVE


Entry: sending out sync
Date: Wed Mar 16 23:33:24 EDT 2016

Is this up-to-date?
http://www.alsa-project.org/~tiwai/alsa-sync.html

core function seems to be: snd_seq_alloc_sync_queue()
which is the only reference i find

I need to look into the alsa sources...  Too much old stale
documentation..

in seq.h:

/** sequencer timer sources */
typedef enum {
	SND_SEQ_TIMER_ALSA = 0,		/* ALSA timer */
	SND_SEQ_TIMER_MIDI_CLOCK = 1,	/* Midi Clock (CLOCK event) */
	SND_SEQ_TIMER_MIDI_TICK = 2	/* Midi Timer Tick (TICK event */
} snd_seq_queue_timer_type_t;
void snd_seq_queue_timer_set_type(snd_seq_queue_timer_t *info, snd_seq_queue_timer_type_t type);


Yeah this is badly documented. I'm annoyed.
Let's look at code from others.

Something to look for
#define SNDRV_SEQ_EVENT_CLOCK		36	/* midi Real Time Clock message */
#define MIDI_CMD_COMMON_CLOCK		0xf8



Entry: hydrogen
Date: Thu Mar 17 00:43:18 EDT 2016

Looks like jack midi is the way to go.

http://www.hydrogen-music.org/hcms/node/1966
http://www.teuton.org/~gabriel/jack_midi_clock/
git clone git://gabe.is-a-geek.org/git/jack_midi_clock.git


Entry: sooperlooper
Date: Thu Mar 17 00:52:27 EDT 2016

http://essej.net/sooperlooper/



Entry: jack midi or alsa sequencer?
Date: Thu Mar 17 00:57:03 EDT 2016

It seems that people are standardizing on jack, and jack midi.
For new things it seems best to not use alsa sequencer.

http://www.teuton.org/~gabriel/jack_midi_clock/
http://wiki.linuxaudio.org/faq/start#qwhat_is_the_difference_between_jack-midi_and_alsa-midi

Since jack is used for audio anyway, it seems best to use it for midi
as well.  Jack can then provide abstraction of alsa sequencer or alsa
hardware.

jack_midi_clock.c uses these calls:

      send_rt_message(port_buf, 0, MIDI_RT_CLOCK);
      send_rt_message(port_buf, next_tick_offset, MIDI_RT_CLOCK);

static void send_rt_message(void* port_buf, jack_nframes_t time, uint8_t rt_msg) {
  uint8_t *buffer;
  buffer = jack_midi_event_reserve(port_buf, time, 1);
  if(buffer) {
    buffer[0] = rt_msg;
  }
}

  if ((mclk_output_port = jack_port_register(j_client, "mclk_out", JACK_DEFAULT_MIDI_TYPE, JackPortIsOutput, 0)) == 0) {


jack_midi_event_reserve()
- can be called from the process() method
- needs sorted input

Overall this seems like a much better approach to handling timer
issues.  Synchronize to the audio sample (block) clock for logical
time base, and have jack handle the event scheduling details.

For other things, alsa seq is probably ok.

One thing to figure out is how usable erlang would be for midi event
processing.

Do I really need alsa sequencers for new code?  For new softsynths,
best to stick with jack.

a2jmidid (separate app) is apparently better than seq and raw
http://home.gna.org/a2jmidid/

the reason to use a2jmidid is that it allows to run jack in -X raw
mode, while still allowing to bridge jack midi ports to (wrapped)
sequencer ports.


Yeah need to play with it.  Coexist. Conclusions:




Entry: audio/midi Routing setup
Date: Thu Mar 17 01:55:41 EDT 2016

MIDI
- Use jack midi for anything that uses jack audio already 
- Use jack midi for hi-rez timing (based off of sample clock) (ex: jack_midi_clock.c)
- Use ordinary alsa seq for non-timing critical bits (e.g. erlang hacking?)
- Create a jack midi interface to erlang (also for better timing).
- Run jack in raw mode, use a2jmidid to connect sequencers to raw ports

AUDIO
- jack
- pulseaudio jack bridge (optional)
- pd (no jack midi tho)
- rai soft synths with jack midi / osc or pd on stdin


Entry: jack midi api
Date: Thu Mar 17 02:19:23 EDT 2016

http://jack-audio-connection-kit.sourcearchive.com/documentation/0.116.1/group__MIDIAPI_g6037a3936f8d2ef063dbbd47d722f660.html
http://www.teuton.org/~gabriel/jack_midi_clock/


Entry: Next
Date: Thu Mar 17 02:25:32 EDT 2016

Try the drum machine sync.



Entry: Jack timebase
Date: Fri Mar 18 16:12:45 EDT 2016

Got it to work in exo.


Entry: poly-rhythm timebase. 
Date: Fri Mar 18 16:15:41 EDT 2016

Discrete is simple.
Can also do on audio for looper recording of analogs.
Main problem here is interference between LFOs and loops.



Entry: jack midi ports
Date: Fri Mar 18 16:55:15 EDT 2016

scan: added port hw:0,0,0 in-hw-0-0-0-M-Audio-Delta-1010-MIDI
scan: added port hw:0,0,0 out-hw-0-0-0-M-Audio-Delta-1010-MIDI
scan: added port hw:3,0,0 in-hw-3-0-0-USB-Midi-4i4o-MIDI-1
scan: added port hw:3,0,1 in-hw-3-0-1-USB-Midi-4i4o-MIDI-2
scan: added port hw:3,0,2 in-hw-3-0-2-USB-Midi-4i4o-MIDI-3
scan: added port hw:3,0,3 in-hw-3-0-3-USB-Midi-4i4o-MIDI-4
scan: added port hw:3,0,0 out-hw-3-0-0-USB-Midi-4i4o-MIDI-1
scan: added port hw:3,0,1 out-hw-3-0-1-USB-Midi-4i4o-MIDI-2
scan: added port hw:3,0,2 out-hw-3-0-2-USB-Midi-4i4o-MIDI-3
scan: added port hw:3,0,3 out-hw-3-0-3-USB-Midi-4i4o-MIDI-4
scan: added port hw:4,0,0 in-hw-4-0-0-MicroBrute-MIDI-1
scan: added port hw:4,0,1 in-hw-4-0-1-MicroBrute-MIDI-2
scan: added port hw:4,0,0 out-hw-4-0-0-MicroBrute-MIDI-1
scan: added port hw:4,0,1 out-hw-4-0-1-MicroBrute-MIDI-2



Entry: separate exo and studio
Date: Sat Mar 19 23:26:00 EDT 2016

I'd like to build this into something dedicated, and handle all
starting/stopping from Erlang as well.

If events need to be exchanged between exo and studio, it would likely
not be such a huge deal..


Entry: MIDI
Date: Sun Mar 20 13:50:23 EDT 2016

- use jack midi: -X raw, only using physical ports
- start it in Erlang, and hook up the stdout monitor to keep track of port names
- together with jackd, start a jack client erlang port that connects to all jack midi ports
- use naming resolution to build a generic, plug and play midi router


Entry: Startup
Date: Sun Mar 20 14:27:28 EDT 2016

Maybe good to start looking into OTP?  I still think that for what I
want to do, OTP is overkill.  I'd rather implement servers at the
function level (init,handle) as opposed to module level, especially
since most of them are so simple.


Entry: M-Audio Delta1010 midi
Date: Sun Mar 20 19:50:34 EDT 2016

Is problematic.  When I connect it, all the others seem to skip
timecodes.  Some echo thing?

Suspicious though that it's the first one so might be something else
also.



Entry: jack changes
Date: Thu Mar 24 11:17:53 EDT 2016

separated midi and control clients so they can use different buffering
schemes.  control: rpc, midi: packet switching, with possible drops.
still not happy with the possible drops (really a design problem) but
for now we're fine.


Entry: erlang sequencer
Date: Thu Mar 24 11:19:54 EDT 2016

next is event sequencing.  trouble is in the "note off" events.

my idea had been to use a process for an event stream, but it's not
clear if that's a good idea.  ordered queues are probably better, but
more clumsy to work with.

yesterday i was thinking about the problem of interface
vs. representation.  in my payed gig i've been dealing a lot with this
problem: to build something that has a model quite different from the
way it is implemented.

in any case it would be a nice experiment to see how far the erlang
scheduler can be trusted with accurate sequencing.

what i really want though, is infinite (floating point) timing
resolution.


a possible solution:

- build a model in erlang that can in principle be translated to
  bare-bones implementation (state machines + priority queue).

- once it works, implement the state machine scheduler



Entry: Settings
Date: Sun Mar 27 21:47:43 EDT 2016

Storage is necessary.  I wonder if it makes sense to put this in a
sqlite database, or to hard-code it in Erlang datastructures.  Once
"learning" is added, the former might make sense.

EDIT: added erl_sqlite3 dependency and database.


Entry: Routing
Date: Thu Apr  7 21:40:30 EDT 2016

Everything is set up.  Next: routing.
Basic tool is serv:broadcaster (fan-out) and receive selection.

Basically, event comes in at port and based on what it is, it needs to
be dispatched to one or more registered processes.

It doesn't seem like a good idea to route everything to every process.
So that gives a way to organize.

The router is a set of {Predicate,Process} rules.
Broadcaster could be extended to that.


Entry: Trigger & Learn
Date: Fri Apr  8 00:38:35 EDT 2016

Triggers are easy on top of routing.
Next: midi learn for rai code numbers.


The interesting part there is to keep the locations invariant.
Inserting forms will violate that.  This was not a problem using the
emacs cursor.


Entry: jack and pulseaudio
Date: Fri Apr  8 19:17:02 EDT 2016

what i want is:

- keep studio launching jack, monitoring its stdout.  no dbus business.
- reserve system out for pulseaudio web browsing, skype etc.. keep pro card for music

additionally:
- have pulseaudio detect a running jack daemon and register as client (not dbus)


# JACK: the dbus solution is not very robust. plus i need more control
# over starting jack.  Have pulse register as client instead (and kill
# pulse when jack starts. clients will restart pulse when needed)

### Automatically connect sink and source if JACK server is present
#.ifexists module-jackdbus-detect.so
#.nofail
#load-module module-jackdbus-detect channels=2
#.fail
#.endif

## apt-get install pulseaudio-module-jack
.ifexists module-jack-source.so
load-module module-jack-source
.endif
.ifexists module-jack-sink.so
load-module module-jack-sink
.endif


Entry: pulse udev
Date: Sat Apr  9 00:39:20 EDT 2016

/lib/udev/rules.d/90-pulseaudio.rules

to disable a card, use udev environment to inflence that rule.
https://jamielinux.com/blog/tell-pulseaudio-to-ignore-a-usb-device-using-udev/

ATTRS{idVendor}=="1852", ATTRS{idProduct}=="5110", ENV{PULSE_IGNORE}="1"

From default.pa:

### Automatically load driver modules depending on the hardware available
.ifexists module-udev-detect.so
load-module module-udev-detect
.else
### Use the static hardware detection module (for systems that lack udev support)
load-module module-detect
.endif




Entry: jackd bug
Date: Tue Apr 19 09:41:46 EDT 2016

https://github.com/jackaudio/jack2/pull/153

2^31-1 Samples (~13.5h at 44.1kHz),

EDIT:
Fix is not in 1.9.10 release, so build from git.
How to turn this into a jackd2 debian package?

Not necessary:
- build in ~/git/jackd2 using standard options
- set ~/bin/jackd.zoo to use /home/tom/git/jack2/build/jackd



Entry: lmms
Date: Sat Nov 19 18:00:25 EST 2016

Not very useful to me atm, but useful as a pattern editor.
How to get pattern from lmms into erlang?

lmms -d hobble.mmpz # gives an xml file

Maybe a good push for making something in Rust



Entry: rust
Date: Sat Nov 19 18:43:12 EST 2016

https://github.com/seriyps/rust-erl-ext



Entry: next
Date: Sun Nov 20 08:27:35 EST 2016

What to do next?  I like the romantic Erlang story, but currently have
no idea on how to put it to use properly.  There is no point of
increment.

What is needed?

- A pattern sequence player / editor

- A sample player / matcher


Maybe if the artistic inspiration is not there, focus on the dry,
technical problems?  The problem has always been management of
phrases as midi notes + synth configs, or recorded samples.

I've always felt the need to have to choose between synths and
samples.  Is that still the case?

Also, reproducibility has been a problem.  But that conflicts with the
lure of the analog knobs..



Entry: FLAC decoder in rust
Date: Thu Dec  1 08:19:31 EST 2016

https://github.com/ruuda/claxon
https://ruudvanasseldonk.com/2016/11/30/zero-cost-abstractions



Entry: UI revisited
Date: Sat Dec 17 17:55:50 EST 2016

The point here is to keep it fun, right?
And allow for some "job well done" gloating afterwards..

What about UI.  I want to build my own widgets in a way that makes
sense, e.g. using constraints or some declarative approach.  As a
language I'd go for either Rust or Haskell.  Former if this has to
ever run on a low-end machine (unlikely).  Latter if it's ok to use a
2010-style laptop which can run reasonable 2D compositing and can host
Haskell.

Really, thinking about synth networks, it might be best to completely
separate UI and sound, so platform would not be such a problem.  The
question would be: is Haskell responsive enough?

Some requirements:
- would have to be frame-synchronous: no tearing
- I'd like to avoid X11



So.. I have all these thinkpads.  They all have:

lspci:
00:02.0 VGA compatible controller: Intel Corporation Core Processor Integrated Graphics Controller (rev 02)

cpuinfo:
(zora, broom)
model name      : Intel(R) Core(TM) i5 CPU       M 520  @ 2.40GHz
(tp)
model name      : Intel(R) Core(TM) i5 CPU       M 540  @ 2.53GHz

glxinfo:
    Device: Mesa DRI Intel(R) Ironlake Mobile  (0x46)

https://en.wikipedia.org/wiki/List_of_Intel_graphics_processing_units#Fifth_generation
https://en.wikipedia.org/wiki/Arrandale
https://en.wikipedia.org/wiki/Intel_HD_and_Iris_Graphics



Entry: pick up?
Date: Mon Jul 31 15:27:49 EDT 2017

Still working, and a bit more Erlang experience.
What next?

- simple wave editor
- STM32F4 + RAI (Axoloti)


But first: organization.

- Going to have zoe as dedicated host for this since it has all the
  hardware wired permanently.  It makes no sense to set this up as an
  LXC container, so maybe delete the "studio" lxc.

- Set up backups.  Looks like this is a new one: zoe_20170731_1533_zoe
  Probably safe to delete old ones.

- To run on laptop, install it locally there as well.  Maybe have a
  dedicated disk for it.  Laptop will use roland UA-30 USB.

- Studio will be always running.  Run it inside of emacs.

- Checked the fasttrack as main 2track recorder.  Seems to work ok.

- Do editing using tramp from core.  Figure out a way to merge the
  subprojects properly.

- Make a web interface?  E.g. drum computer, routing

- Set up ssh into studio image



Entry: Setting up emacs for new project
Date: Mon Jul 31 16:11:58 EDT 2017

- erl ssh access
- distel
- incremental build + load


Entry: ssh
Date: Mon Jul 31 20:24:31 EDT 2017

I really don't want to waste time on this.  It's not working well.
Maybe just use distribution on VPN, since distel needs that anyway.


Entry: A sender and a receiver
Date: Sun Aug 13 21:08:05 EDT 2017

So I want to think about making this easier.

I have a sender, say a midi knob plugged into a PC somewhere in the
distributed network, and I want to use it as an input to some process.

How to tell the knob to send its data?

- Register the pid to the controller's parent
- Have the parent do filtering

how to make this work with "midi learn?"

this only works if all the controls can be left silent, or at least to
filter out those controls that do not yet have an assignment.


where is this actually coming in?
EDIT: arch uses a hub

to receive a port's messages, register a filter for its address to the
midi_hub

what this can't do is midi learn.

hub would need to implement that.



Entry: current jack arch
Date: Sun Aug 13 21:21:28 EDT 2017

jackd, wraps the daemon. listens to stdout for connect events.

jack_control, wraps port process to do things like jack_connect().

jack_midi, wraps port process
has currently 16 in, 16 out which are connected to the physical ports
sends everything to midi hub

midi hub is serv:hub

%% Midi in. Translate to symbolic form.
jack_midi_handle({Port,{data,<<MidiPort,Data/binary>>}}, Port) ->
    lists:foreach(
      fun(Msg) -> serv:hub_send(midi_hub, {{jack,MidiPort},Msg}) end,
      decode(Data)),
    Port;


TODO: hub needs to register processes, so if they die it can remove
them from the list.  It was determined to do filtering at the source
-- that's always a good idea.



Entry: Implementing midi learn, improving hub
Date: Sun Aug 13 21:34:04 EDT 2017

Send message to hub: I want to subscribe a part

- add registry (probably already in newer erl_tools) to avoid stale pids.

- midi hub should use sets as filters, so a filter can easily be
  added.

- midi learn requires "quiet".  otherwise, do it for things that are
  not yet assigned.



Entry: So I had some time to practice GUI work
Date: Tue Sep  5 23:26:45 EDT 2017

Now it's time to make a sound editor!



Entry: Simplify channel codes
Date: Sat Sep  9 16:21:02 EDT 2017

1 white
2 red
3 yellow
4 green
5 blue
6 black
7 grey
8 browngrey


Entry: Next
Date: Sun Dec 10 18:12:39 EST 2017

- set up staapl synth and connect to midi + mixer channel 8
- looper controller
- midi control of 4 synths
- midi learn

