mixer

with direct out connected to delta1010 in
all post-fader
 1 guitar/bass clean
 2 guitar effect chain
 3 microbruite
 4 volca keys
 5 volca bass
 6 volca beats
 7 monitron / paia (todo)
 8 paia (todo)


from delta1010 - digital mix chain
13/14 out 1/2 

from delta1010, for routing to analog effects

15/16 out 3/4
 9    out 5
10    out 6
11    out 7
12    out 8

from intel built-in audio - pulseaudio digital mix chain
17/18 
19/20 free

sends:
aux1 pre      free
aux2 pre/post guitar effects  (pre default)
aux3 post     free

notes:

* aux send to digital in (e.g. for reverb/delay) is not really
  necessary as they can be sent digitally.

* aux1 somehow gives feedback trouble on high-gain effects chain
  (self-send not off completely?).  using aux2 in pre mode works fine.


bcr2000

top row: mixer (0-127) midi control
bittons: part mute
bottom 3 rows: synth control (incremental)


TODO:
- sync microbruite to the volcas (all on midi sync?)
- find a good sequencer
- mount all the "knobs" to a movable surface
- set up a good echo/delay digitally
- set up midi for all
- route guitar effects chain through mixer
- focus on non-portable setup first built around delta1010
- later add "easy detach" portability
- find a simple touch screen


Entry: Sequencer
Date: Fri Mar  4 18:38:06 EST 2016

Find a good sequencer, or build one.


Entry: Analog
Date: Fri Mar  4 19:31:29 EST 2016

8 channels should be enough.  All of them have direct out to
delta1010.

I have 4 channels direct 


Entry: Monoprice
Date: Fri Mar  4 20:04:54 EST 2016

- TS Single angle
- TS 


Entry: Effects send
Date: Fri Mar  4 21:06:59 EST 2016

Not sure why this didn't work earlier.  Too noisy?  Let's try again..

The reason was feedback, since this needs to be set pre-fader, and the
self-send on the return channel is too strong. It's doable for most
cases but easy to trigger.


Entry: MIDI
Date: Fri Mar  4 22:37:04 EST 2016

- map all midi devices to some other messages (osc?)
- program bcr2000 for mixerm, mute botton + inc control operation


SYNC:
http://www.sweetwater.com/sweetcare/articles/how-do-i-set-up-my-korg-volca-series-synth-module-to-sync-to-an-external-midi-clock/


Entry: udev
Date: Sat Mar  5 11:02:02 EST 2016

Fixed device names in /etc/net/udev
Next is to find a way to share the device

Using the legacy midi devices (and alsa's rawmidi?) is single-access only.
Two options:
- create a daemon that converts midi to osc
- learn how to use the alsa sequencer

Since I need the "accumulator" anyway, let's do this in erlang (exo).



Entry: Sending clock sync from Erlang
Date: Sat Mar  5 23:08:03 EST 2016

At 120bpm, 2pbs

(* 2 4 24)  192 messages per second.

5ms per message.



Entry: alsa midi
Date: Wed Mar 16 11:49:52 EDT 2016

Looks like it's necessary to use alsa midi interface, as multi-port
devices only show up with a single legacy /dev/midi? port.

Making exo/c_src/midi_in.c to simply map back to raw MIDI in erlang.
Alternatively, pass through the full binary event structs.

Next: figure out how to set tempo, send midi sync, send start/stop to
all clients at once, and configure volca's to sync to midi.


Entry: amidi / aconnect
Date: Wed Mar 16 22:16:43 EDT 2016

tom@zoo:~$ amidi -l
Dir Device    Name
IO  hw:0,0    M Audio Delta 1010 MIDI
IO  hw:3,0,0  USB Midi 4i4o MIDI 1
IO  hw:3,0,1  USB Midi 4i4o MIDI 2
IO  hw:3,0,2  USB Midi 4i4o MIDI 3
IO  hw:3,0,3  USB Midi 4i4o MIDI 4


tom@zoo:~$ aconnect -l
client 0: 'System' [type=kernel]
    0 'Timer           '
    1 'Announce        '
client 14: 'Midi Through' [type=kernel]
    0 'Midi Through Port-0'
client 16: 'M Audio Delta 1010' [type=kernel]
    0 'M Audio Delta 1010 MIDI'
client 28: 'USB Midi 4i4o' [type=kernel]
    0 'USB Midi 4i4o MIDI 1'
    1 'USB Midi 4i4o MIDI 2'
    2 'USB Midi 4i4o MIDI 3'
    3 'USB Midi 4i4o MIDI 4'


So some questions.

- Should I use the sequencer or the raw midi?  Maybe jack midi (which
is on top of raw midi) The oss midi is likely not a good idea.

- There are 4 ports, but only one /dev/midiCD0 device


This http://wiki.linuxaudio.org/faq/start
mentions alsa sequencer should be used for interconnecting applications.
Jack MIDI might just be for recording, then?

No, looks like the reason has to do with high-resolution timing.
250kHz not being enough.

I wonder, is it possible to have the time sync sent out by the sequencer?
http://www.alsa-project.org/~tiwai/alsa-sync.html


Entry: alsa timers
Date: Wed Mar 16 23:32:34 EDT 2016

tom@tp:~$ cat /proc/asound/timers 
G0: system timer : 4000.000us (10000000 ticks)
G3: HR timer : 0.001us (1000000000 ticks)
P0-0-0: PCM playback 0-0-0 : SLAVE
P0-0-1: PCM capture 0-0-1 : SLAVE
P0-3-0: PCM playback 0-3-0 : SLAVE

tom@zoo:~$ cat /proc/asound/timers 
G0: system timer : 4000.000us (10000000 ticks)
P0-0-0: PCM playback 0-0-0 : SLAVE
P0-0-1: PCM capture 0-0-1 : SLAVE
P1-0-0: PCM playback 1-0-0 : SLAVE
P1-0-1: PCM capture 1-0-1 : SLAVE
P1-2-1: PCM capture 1-2-1 : SLAVE
P2-3-0: PCM playback 2-3-0 : SLAVE


Entry: sending out sync
Date: Wed Mar 16 23:33:24 EDT 2016

Is this up-to-date?
http://www.alsa-project.org/~tiwai/alsa-sync.html

core function seems to be: snd_seq_alloc_sync_queue()
which is the only reference i find

I need to look into the alsa sources...  Too much old stale
documentation..

in seq.h:

/** sequencer timer sources */
typedef enum {
	SND_SEQ_TIMER_ALSA = 0,		/* ALSA timer */
	SND_SEQ_TIMER_MIDI_CLOCK = 1,	/* Midi Clock (CLOCK event) */
	SND_SEQ_TIMER_MIDI_TICK = 2	/* Midi Timer Tick (TICK event */
} snd_seq_queue_timer_type_t;
void snd_seq_queue_timer_set_type(snd_seq_queue_timer_t *info, snd_seq_queue_timer_type_t type);


Yeah this is badly documented. I'm annoyed.
Let's look at code from others.

Something to look for
#define SNDRV_SEQ_EVENT_CLOCK		36	/* midi Real Time Clock message */
#define MIDI_CMD_COMMON_CLOCK		0xf8



Entry: hydrogen
Date: Thu Mar 17 00:43:18 EDT 2016

Looks like jack midi is the way to go.

http://www.hydrogen-music.org/hcms/node/1966
http://www.teuton.org/~gabriel/jack_midi_clock/
git clone git://gabe.is-a-geek.org/git/jack_midi_clock.git


Entry: sooperlooper
Date: Thu Mar 17 00:52:27 EDT 2016

http://essej.net/sooperlooper/



Entry: jack midi or alsa sequencer?
Date: Thu Mar 17 00:57:03 EDT 2016

It seems that people are standardizing on jack, and jack midi.
For new things it seems best to not use alsa sequencer.

http://www.teuton.org/~gabriel/jack_midi_clock/
http://wiki.linuxaudio.org/faq/start#qwhat_is_the_difference_between_jack-midi_and_alsa-midi

Since jack is used for audio anyway, it seems best to use it for midi
as well.  Jack can then provide abstraction of alsa sequencer or alsa
hardware.

jack_midi_clock.c uses these calls:

      send_rt_message(port_buf, 0, MIDI_RT_CLOCK);
      send_rt_message(port_buf, next_tick_offset, MIDI_RT_CLOCK);

static void send_rt_message(void* port_buf, jack_nframes_t time, uint8_t rt_msg) {
  uint8_t *buffer;
  buffer = jack_midi_event_reserve(port_buf, time, 1);
  if(buffer) {
    buffer[0] = rt_msg;
  }
}

  if ((mclk_output_port = jack_port_register(j_client, "mclk_out", JACK_DEFAULT_MIDI_TYPE, JackPortIsOutput, 0)) == 0) {


jack_midi_event_reserve()
- can be called from the process() method
- needs sorted input

Overall this seems like a much better approach to handling timer
issues.  Synchronize to the audio sample (block) clock for logical
time base, and have jack handle the event scheduling details.

For other things, alsa seq is probably ok.

One thing to figure out is how usable erlang would be for midi event
processing.

Do I really need alsa sequencers for new code?  For new softsynths,
best to stick with jack.

a2jmidid (separate app) is apparently better than seq and raw
http://home.gna.org/a2jmidid/

the reason to use a2jmidid is that it allows to run jack in -X raw
mode, while still allowing to bridge jack midi ports to (wrapped)
sequencer ports.


Yeah need to play with it.  Coexist. Conclusions:




Entry: audio/midi Routing setup
Date: Thu Mar 17 01:55:41 EDT 2016

MIDI
- Use jack midi for anything that uses jack audio already 
- Use jack midi for hi-rez timing (based off of sample clock) (ex: jack_midi_clock.c)
- Use ordinary alsa seq for non-timing critical bits (e.g. erlang hacking?)
- Create a jack midi interface to erlang (also for better timing).
- Run jack in raw mode, use a2jmidid to connect sequencers to raw ports

AUDIO
- jack
- pulseaudio jack bridge (optional)
- pd (no jack midi tho)
- rai soft synths with jack midi / osc or pd on stdin


Entry: jack midi api
Date: Thu Mar 17 02:19:23 EDT 2016

http://jack-audio-connection-kit.sourcearchive.com/documentation/0.116.1/group__MIDIAPI_g6037a3936f8d2ef063dbbd47d722f660.html
http://www.teuton.org/~gabriel/jack_midi_clock/


Entry: Next
Date: Thu Mar 17 02:25:32 EDT 2016

Try the drum machine sync.



Entry: Jack timebase
Date: Fri Mar 18 16:12:45 EDT 2016

Got it to work in exo.


Entry: poly-rhythm timebase. 
Date: Fri Mar 18 16:15:41 EDT 2016

Discrete is simple.
Can also do on audio for looper recording of analogs.
Main problem here is interference between LFOs and loops.



Entry: jack midi ports
Date: Fri Mar 18 16:55:15 EDT 2016

scan: added port hw:0,0,0 in-hw-0-0-0-M-Audio-Delta-1010-MIDI
scan: added port hw:0,0,0 out-hw-0-0-0-M-Audio-Delta-1010-MIDI
scan: added port hw:3,0,0 in-hw-3-0-0-USB-Midi-4i4o-MIDI-1
scan: added port hw:3,0,1 in-hw-3-0-1-USB-Midi-4i4o-MIDI-2
scan: added port hw:3,0,2 in-hw-3-0-2-USB-Midi-4i4o-MIDI-3
scan: added port hw:3,0,3 in-hw-3-0-3-USB-Midi-4i4o-MIDI-4
scan: added port hw:3,0,0 out-hw-3-0-0-USB-Midi-4i4o-MIDI-1
scan: added port hw:3,0,1 out-hw-3-0-1-USB-Midi-4i4o-MIDI-2
scan: added port hw:3,0,2 out-hw-3-0-2-USB-Midi-4i4o-MIDI-3
scan: added port hw:3,0,3 out-hw-3-0-3-USB-Midi-4i4o-MIDI-4
scan: added port hw:4,0,0 in-hw-4-0-0-MicroBrute-MIDI-1
scan: added port hw:4,0,1 in-hw-4-0-1-MicroBrute-MIDI-2
scan: added port hw:4,0,0 out-hw-4-0-0-MicroBrute-MIDI-1
scan: added port hw:4,0,1 out-hw-4-0-1-MicroBrute-MIDI-2



Entry: separate exo and studio
Date: Sat Mar 19 23:26:00 EDT 2016

I'd like to build this into something dedicated, and handle all
starting/stopping from Erlang as well.

If events need to be exchanged between exo and studio, it would likely
not be such a huge deal..


Entry: MIDI
Date: Sun Mar 20 13:50:23 EDT 2016

- use jack midi: -X raw, only using physical ports
- start it in Erlang, and hook up the stdout monitor to keep track of port names
- together with jackd, start a jack client erlang port that connects to all jack midi ports
- use naming resolution to build a generic, plug and play midi router


Entry: Startup
Date: Sun Mar 20 14:27:28 EDT 2016

Maybe good to start looking into OTP?  I still think that for what I
want to do, OTP is overkill.  I'd rather implement servers at the
function level (init,handle) as opposed to module level, especially
since most of them are so simple.


Entry: M-Audio Delta1010 midi
Date: Sun Mar 20 19:50:34 EDT 2016

Is problematic.  When I connect it, all the others seem to skip
timecodes.  Some echo thing?

Suspicious though that it's the first one so might be something else
also.



Entry: jack changes
Date: Thu Mar 24 11:17:53 EDT 2016

separated midi and control clients so they can use different buffering
schemes.  control: rpc, midi: packet switching, with possible drops.
still not happy with the possible drops (really a design problem) but
for now we're fine.


Entry: erlang sequencer
Date: Thu Mar 24 11:19:54 EDT 2016

next is event sequencing.  trouble is in the "note off" events.

my idea had been to use a process for an event stream, but it's not
clear if that's a good idea.  ordered queues are probably better, but
more clumsy to work with.

yesterday i was thinking about the problem of interface
vs. representation.  in my payed gig i've been dealing a lot with this
problem: to build something that has a model quite different from the
way it is implemented.

in any case it would be a nice experiment to see how far the erlang
scheduler can be trusted with accurate sequencing.

what i really want though, is infinite (floating point) timing
resolution.


a possible solution:

- build a model in erlang that can in principle be translated to
  bare-bones implementation (state machines + priority queue).

- once it works, implement the state machine scheduler



Entry: Settings
Date: Sun Mar 27 21:47:43 EDT 2016

Storage is necessary.  I wonder if it makes sense to put this in a
sqlite database, or to hard-code it in Erlang datastructures.  Once
"learning" is added, the former might make sense.

EDIT: added erl_sqlite3 dependency and database.


Entry: Routing
Date: Thu Apr  7 21:40:30 EDT 2016

Everything is set up.  Next: routing.
Basic tool is serv:broadcaster (fan-out) and receive selection.

Basically, event comes in at port and based on what it is, it needs to
be dispatched to one or more registered processes.

It doesn't seem like a good idea to route everything to every process.
So that gives a way to organize.

The router is a set of {Predicate,Process} rules.
Broadcaster could be extended to that.


Entry: Trigger & Learn
Date: Fri Apr  8 00:38:35 EDT 2016

Triggers are easy on top of routing.
Next: midi learn for rai code numbers.


The interesting part there is to keep the locations invariant.
Inserting forms will violate that.  This was not a problem using the
emacs cursor.


Entry: jack and pulseaudio
Date: Fri Apr  8 19:17:02 EDT 2016

what i want is:

- keep studio launching jack, monitoring its stdout.  no dbus business.
- reserve system out for pulseaudio web browsing, skype etc.. keep pro card for music

additionally:
- have pulseaudio detect a running jack daemon and register as client (not dbus)


# JACK: the dbus solution is not very robust. plus i need more control
# over starting jack.  Have pulse register as client instead (and kill
# pulse when jack starts. clients will restart pulse when needed)

### Automatically connect sink and source if JACK server is present
#.ifexists module-jackdbus-detect.so
#.nofail
#load-module module-jackdbus-detect channels=2
#.fail
#.endif

## apt-get install pulseaudio-module-jack
.ifexists module-jack-source.so
load-module module-jack-source
.endif
.ifexists module-jack-sink.so
load-module module-jack-sink
.endif


Entry: pulse udev
Date: Sat Apr  9 00:39:20 EDT 2016

/lib/udev/rules.d/90-pulseaudio.rules

to disable a card, use udev environment to inflence that rule.
https://jamielinux.com/blog/tell-pulseaudio-to-ignore-a-usb-device-using-udev/

ATTRS{idVendor}=="1852", ATTRS{idProduct}=="5110", ENV{PULSE_IGNORE}="1"

From default.pa:

### Automatically load driver modules depending on the hardware available
.ifexists module-udev-detect.so
load-module module-udev-detect
.else
### Use the static hardware detection module (for systems that lack udev support)
load-module module-detect
.endif




Entry: jackd bug
Date: Tue Apr 19 09:41:46 EDT 2016

https://github.com/jackaudio/jack2/pull/153

2^31-1 Samples (~13.5h at 44.1kHz),

EDIT:
Fix is not in 1.9.10 release, so build from git.
How to turn this into a jackd2 debian package?

Not necessary:
- build in ~/git/jackd2 using standard options
- set ~/bin/jackd.zoo to use /home/tom/git/jack2/build/jackd



Entry: lmms
Date: Sat Nov 19 18:00:25 EST 2016

Not very useful to me atm, but useful as a pattern editor.
How to get pattern from lmms into erlang?

lmms -d hobble.mmpz # gives an xml file

Maybe a good push for making something in Rust



Entry: rust
Date: Sat Nov 19 18:43:12 EST 2016

https://github.com/seriyps/rust-erl-ext



Entry: next
Date: Sun Nov 20 08:27:35 EST 2016

What to do next?  I like the romantic Erlang story, but currently have
no idea on how to put it to use properly.  There is no point of
increment.

What is needed?

- A pattern sequence player / editor

- A sample player / matcher


Maybe if the artistic inspiration is not there, focus on the dry,
technical problems?  The problem has always been management of
phrases as midi notes + synth configs, or recorded samples.

I've always felt the need to have to choose between synths and
samples.  Is that still the case?

Also, reproducibility has been a problem.  But that conflicts with the
lure of the analog knobs..



Entry: FLAC decoder in rust
Date: Thu Dec  1 08:19:31 EST 2016

https://github.com/ruuda/claxon
https://ruudvanasseldonk.com/2016/11/30/zero-cost-abstractions



Entry: UI revisited
Date: Sat Dec 17 17:55:50 EST 2016

The point here is to keep it fun, right?
And allow for some "job well done" gloating afterwards..

What about UI.  I want to build my own widgets in a way that makes
sense, e.g. using constraints or some declarative approach.  As a
language I'd go for either Rust or Haskell.  Former if this has to
ever run on a low-end machine (unlikely).  Latter if it's ok to use a
2010-style laptop which can run reasonable 2D compositing and can host
Haskell.

Really, thinking about synth networks, it might be best to completely
separate UI and sound, so platform would not be such a problem.  The
question would be: is Haskell responsive enough?

Some requirements:
- would have to be frame-synchronous: no tearing
- I'd like to avoid X11



So.. I have all these thinkpads.  They all have:

lspci:
00:02.0 VGA compatible controller: Intel Corporation Core Processor Integrated Graphics Controller (rev 02)

cpuinfo:
(zora, broom)
model name      : Intel(R) Core(TM) i5 CPU       M 520  @ 2.40GHz
(tp)
model name      : Intel(R) Core(TM) i5 CPU       M 540  @ 2.53GHz

glxinfo:
    Device: Mesa DRI Intel(R) Ironlake Mobile  (0x46)

https://en.wikipedia.org/wiki/List_of_Intel_graphics_processing_units#Fifth_generation
https://en.wikipedia.org/wiki/Arrandale
https://en.wikipedia.org/wiki/Intel_HD_and_Iris_Graphics



Entry: pick up?
Date: Mon Jul 31 15:27:49 EDT 2017

Still working, and a bit more Erlang experience.
What next?

- simple wave editor
- STM32F4 + RAI (Axoloti)


But first: organization.

- Going to have zoe as dedicated host for this since it has all the
  hardware wired permanently.  It makes no sense to set this up as an
  LXC container, so maybe delete the "studio" lxc.

- Set up backups.  Looks like this is a new one: zoe_20170731_1533_zoe
  Probably safe to delete old ones.

- To run on laptop, install it locally there as well.  Maybe have a
  dedicated disk for it.  Laptop will use roland UA-30 USB.

- Studio will be always running.  Run it inside of emacs.

- Checked the fasttrack as main 2track recorder.  Seems to work ok.

- Do editing using tramp from core.  Figure out a way to merge the
  subprojects properly.

- Make a web interface?  E.g. drum computer, routing

- Set up ssh into studio image



Entry: Setting up emacs for new project
Date: Mon Jul 31 16:11:58 EDT 2017

- erl ssh access
- distel
- incremental build + load


Entry: ssh
Date: Mon Jul 31 20:24:31 EDT 2017

I really don't want to waste time on this.  It's not working well.
Maybe just use distribution on VPN, since distel needs that anyway.


Entry: A sender and a receiver
Date: Sun Aug 13 21:08:05 EDT 2017

So I want to think about making this easier.

I have a sender, say a midi knob plugged into a PC somewhere in the
distributed network, and I want to use it as an input to some process.

How to tell the knob to send its data?

- Register the pid to the controller's parent
- Have the parent do filtering

how to make this work with "midi learn?"

this only works if all the controls can be left silent, or at least to
filter out those controls that do not yet have an assignment.


where is this actually coming in?
EDIT: arch uses a hub

to receive a port's messages, register a filter for its address to the
midi_hub

what this can't do is midi learn.

hub would need to implement that.



Entry: current jack arch
Date: Sun Aug 13 21:21:28 EDT 2017

jackd, wraps the daemon. listens to stdout for connect events.

jack_control, wraps port process to do things like jack_connect().

jack_midi, wraps port process
has currently 16 in, 16 out which are connected to the physical ports
sends everything to midi hub

midi hub is serv:hub

%% Midi in. Translate to symbolic form.
jack_midi_handle({Port,{data,<<MidiPort,Data/binary>>}}, Port) ->
    lists:foreach(
      fun(Msg) -> serv:hub_send(midi_hub, {{jack,MidiPort},Msg}) end,
      decode(Data)),
    Port;


TODO: hub needs to register processes, so if they die it can remove
them from the list.  It was determined to do filtering at the source
-- that's always a good idea.



Entry: Implementing midi learn, improving hub
Date: Sun Aug 13 21:34:04 EDT 2017

Send message to hub: I want to subscribe a part

- add registry (probably already in newer erl_tools) to avoid stale pids.

- midi hub should use sets as filters, so a filter can easily be
  added.

- midi learn requires "quiet".  otherwise, do it for things that are
  not yet assigned.



Entry: So I had some time to practice GUI work
Date: Tue Sep  5 23:26:45 EDT 2017

Now it's time to make a sound editor!



Entry: Simplify channel codes
Date: Sat Sep  9 16:21:02 EDT 2017

1 white
2 red
3 yellow
4 green
5 blue
6 black
7 grey
8 browngrey


Entry: Next
Date: Sun Dec 10 18:12:39 EST 2017

- set up staapl synth and connect to midi + mixer channel 8
- looper controller
- midi control of 4 synths
- midi learn


Entry: Midi learn + patch
Date: Sun Dec 10 18:40:25 EST 2017

Simplest way to get this set up is to automate all the ad-hoc binding
that needs to be done.

E.g patch main midi controller to synth and record.




Entry: staapl synth
Date: Sun Dec 10 17:53:42 EST 2017

Just keep it as-is.  It's good enough.  It needs analog filtering, but
it can go into the microbrute.  No extra filters needed.




Entry: Looper
Date: Sun Dec 10 18:01:49 EST 2017

That little USB mixer is the looper.

Knob:   mix-in ratio
Slider: playback volume
Button: record

Ok, so:
{{jack,8},{on,0,60,38}}

Needs to go to some synth.  I need an abstraction for a cable.

A cable is a pid that registers to the midi task, and sends it to
another one.


This is for receiving:

whereis(midi_hub).

serv:hub_add(Hub, Pred, Pid).



This is for sending:


%% Midi out
jack_midi_handle({midi,Mask,Data}, Port) ->
    Bin = ?IF(is_binary(Data), Data, encode(Data)),
    Port ! {self(), {command, <<Mask:32/little, Bin/binary>>}},
    Port.


Which is more low level.

midi_jack doesn't seem to be registered to anything.  actually that's the daemon.

midi needs to be sent through a client.

i need to write down how the processes are set up.

I think the jack daemon is hard-linked to midi_hub.  That is bad
practice.  Fix this to not used registry, but use an application
namespace.

Yeah this needs to be cleaned up a little.

Get dialyzer + typer up then refactor.

But make it work first.  That is busywork.



Ok, now I get it.

To connect midi ports, use a jack client.  Routing through Erlang
maybe has too much delay?

midi:jack_midi(Client,NI,NO,ClockMask).


I believe the idea has always been to allow this to be an "os" for
components that are tighter and can communicate at the jack level.


Ok.  Now get something working.

Lost appetite..  Time to go to bed probably.



Entry: MIDI timecode not coming out
Date: Wed Mar 21 18:54:52 EDT 2018

I forgot how it works.
Send out something on the console to indicate how it works.


jackd_need_client(State) ->
    ...
    ClockMask = db:midiclock_mask(),
    ...

It's set to 14 from db


8 + 4 + 2
3   2   1


connect in-hw-2-0-0-MicroBrute-MIDI-1 studio:midi_in_0
connect in-hw-2-0-1-MicroBrute-MIDI-2 studio:midi_in_0

connect studio:midi_out_0 out-hw-2-0-0-MicroBrute-MIDI-1
connect studio:midi_out_0 out-hw-2-0-1-MicroBrute-MIDI-2
connect studio:midi_out_0 out-hw-5-0-0-WORLDE-easy-control-MIDI-1

connect studio:midi_out_5 out-hw-4-0-0-USB-Midi-4i4o-MIDI-1
connect studio:midi_out_6 out-hw-4-0-1-USB-Midi-4i4o-MIDI-2
connect studio:midi_out_7 out-hw-4-0-2-USB-Midi-4i4o-MIDI-3
connect studio:midi_out_8 out-hw-4-0-3-USB-Midi-4i4o-MIDI-4

connect studio:midi_out_10 out-hw-3-0-0-M-Audio-Delta-1010-MIDI

connect in-hw-3-0-0-M-Audio-Delta-1010-MIDI studio:midi_in_10

connect in-hw-4-0-0-USB-Midi-4i4o-MIDI-1 studio:midi_in_5
connect in-hw-4-0-1-USB-Midi-4i4o-MIDI-2 studio:midi_in_6
connect in-hw-4-0-2-USB-Midi-4i4o-MIDI-3 studio:midi_in_7
connect in-hw-4-0-3-USB-Midi-4i4o-MIDI-4 studio:midi_in_8


connect in-hw-5-0-0-WORLDE-easy-control-MIDI-1 studio:midi_in_0


So if I understand correctly:
studio:midi has 16 midi ports
5,6,7,8 are connected to the analogs, and should have the time code.

sqlite> .dump
PRAGMA foreign_keys=OFF;
BEGIN TRANSACTION;
CREATE TABLE midiport (
       port_id    INTEGER PRIMARY KEY NOT NULL,
       port_name  TEXT    NOT NULL
);
INSERT INTO "midiport" VALUES(1,'BCR2000-MIDI-1');
INSERT INTO "midiport" VALUES(2,'BCR2000-MIDI-2');
INSERT INTO "midiport" VALUES(3,'BCR2000-MIDI-3');
INSERT INTO "midiport" VALUES(5,'USB-Midi-4i4o-MIDI-1');
INSERT INTO "midiport" VALUES(6,'USB-Midi-4i4o-MIDI-2');
INSERT INTO "midiport" VALUES(7,'USB-Midi-4i4o-MIDI-3');
INSERT INTO "midiport" VALUES(8,'USB-Midi-4i4o-MIDI-4');
INSERT INTO "midiport" VALUES(9,'LPK25-MIDI-1');
INSERT INTO "midiport" VALUES(10,'M-Audio-Delta-1010-MIDI');
INSERT INTO "midiport" VALUES(11,'Axiom-25-MIDI-1');
INSERT INTO "midiport" VALUES(12,'Axiom-25-MIDI-2');
INSERT INTO "midiport" VALUES(13,'Axiom-25-MIDI-3');
INSERT INTO "midiport" VALUES(14,'MicroBrute-MIDI-1');
CREATE TABLE midiclock (
       port_name  TEXT    PRIMARY KEY NOT NULL
);
INSERT INTO "midiclock" VALUES('USB-Midi-4i4o-MIDI-1');
INSERT INTO "midiclock" VALUES('USB-Midi-4i4o-MIDI-2');
INSERT INTO "midiclock" VALUES('USB-Midi-4i4o-MIDI-3');
INSERT INTO "midiclock" VALUES('USB-Midi-4i4o-MIDI-4');
INSERT INTO "midiclock" VALUES('MicroBrute-MIDI-1');
CREATE VIEW midiclock_mask as
select sum(1<<port_id) from midiclock left join midiport on midiclock.port_name = midiport.port_name;
COMMIT;


Clock is set to 14, which is wrong.  According to config:

sqlite> select * from midiclock_mask
   ...> ;
16864


I think I might have pulled in erl_tools, which then breaks sql?


Ok, so it's starting the other one.
;;(defun my-start-studio      () (interactive) (my-start-erl-prj "studio"))
(defun my-start-studio      () (interactive) (my-start-erl "studio" "/i/tom/studio/erl.sh"))

I don't even know which is the correct one.

The one on /i/tom/studio has a different database.
Resolved.  Needed to do db_init.sh again.  

Maybe just get rid of studio directory on zoe then?



Entry: Convert to rebar and incorporate in exo
Date: Sat Apr  7 15:41:56 EDT 2018

EDIT: 2019/4/18 this happened somewhere in the past.  See exo log.


Entry: Midi patterns
Date: Thu Apr 18 17:39:01 EDT 2019

So what if I have a pattern. How do I play it back?  Now that I now
how to properly do reloads, this might be a lot easier to use.

EDIT: I completely forgot.  This needs to be discoverable.  At
startup, it needs to play a pattern on one of the synths.

EDIT: Reverse engineering.  jack_midi is not registered.  Get pid from
studio_sup.  That process supports message:

{midi,Mask,Data}

P ! {midi, -1, midi:encode({on, 0, 64, 100})}.

That crashed it.

Probably the -1.  It also takes symbolic midi.

This now works:

f(P),{ok,P}=studio_sup:find(midi_jack).
obj:get(P,midi) ! {midi, -1, {on, 0, 64, 100}}.
obj:get(P,midi) ! {midi, -1, {off, 0, 64, 100}}.

But it seems it is missing a whole lot of infrastructure.


Entry: Sqlite
Date: Thu Apr 18 17:51:14 EDT 2019

So basically, all that can be replaced by code, because it is
integration code.  A module save is going to be just as fast as a DB
save.



Entry: Review?
Date: Thu Apr 18 19:55:21 EDT 2019

This was written when I did not have a whole lot of experience yet
with some Erlang corner cases.  Do a review, and client it up a bit.

EDIT: I'm afraid that the timing won't be good enough.  To do
something good, do it at the C end at Jack frame rate.  Or change the
jackd daemon to Rust to have a less hacky dev experience.



Entry: Synths
Date: Thu Apr 18 21:35:12 EDT 2019

64  bass
128 keys

I can't find the drums though.
Ok they are just under different keys.

So it's clear what this needs: something that can do midi routing,
midi recording and midi playback with perfect timing.  So run it
inside jack, and run the soft synths, midi and sampler all in the same
core.

This is not for Erlang.  What erlang is good for is to connect the
midi to other shit on the network, or vice versa.  Act as a bridge,
but don't let it do timing-sensitive things.


Entry: A recording format.
Date: Thu Apr 18 22:09:29 EDT 2019

It really needs to go just in RAM, so it doesn't matter all that much.
Saving it to disk will need time stamps for midi.  Maybe just midi
files?



Entry: A recorder
Date: Mon Apr 22 11:50:19 EDT 2019

It's clear that doing midi in Erlang is not going to cut it, so do it
in Jack instead.  Extend the current Jack code to do midi, and then
replace the existing C code.

What I want: something that's continuously recording, but can take
snapshots.

Basically, there is no reason not to record continuously these days.
Just use a circular buffer, and create an interface to go back and
find things.

So I already have a format for this.  It just needs to be chunked to
also do audio.  Let's reserve a drive for it.  This can just be USB.

EDIT: 
34e6aa85-8440-4d19-ac76-5646a856443e 500GB Seagate USB2

Record jack in/out and all midi in/out.

Jack client can do the chunking and send a message to erlang.  This is
48kHz * 2 * 8 * 2 or (* 48000 2 8 2) 1.5MByte/sec _+ MIDI.

That should not be an issue.
The disk is 500GB, so about 90 hours:

(/ (* 500.0 1000 1000 1000)
   (* 60 60 (* 48000 2 8 2)))
90.42245370370371

Use a global start/stop knob.
Start a new file as with the video recorder.

Remount r/o on stop.

What is the next step?
- instantiate recorder
- create jack client to tap the busses



Entry: Recorder
Date: Mon Apr 22 13:45:26 EDT 2019

Bulk it up into one second chunks?  Jack with a frame size of 64,
which is a lot of pressure on Erlang without any good reason for it.
Midi can be left as is, but the audio should probably be reduced.
Maybe pick something that can easily resolve 20Hz so FFTs can be used
in place on the data to scan for frequency content.

Say 10Hz is the block rate, that is about 4K sample blocks which is
128K frames for 16x16bit channels.

This is reasonable.  On par with cameras.  Studio could also record a
camera feed.


Entry: TODO
Date: Mon Apr 22 14:13:47 EDT 2019

- jack audio client, bulks up a number of channels into 4K time
  samples, and sends it out to the recorder.

  this can be done inside a single Rust core application that ties
  into Erlang.  the recorder can be Erlang

  i already have this client somewhere, so next step is to put it in
  studio.

- the process that starts the jack daemon and sets up connections can
  just be kept as is for now.  later incorporate in Rust once it
  becomes easy to do.



Entry: Next
Date: Tue Apr 23 15:08:51 EDT 2019

Rust code is currently in exo.  It's fine there for now.  Once context
is active, moving it will be easy.

It starts on the studio node:
exo:start(exo_rs).

exo_rs:call({open,{jack_client,<<"test">>}}).
<0.617.0>: Unknown source port in attempted (dis)connection src_name [rust_jack_sine:sine_out] dst_name [system:playback_1]
{ok,0}

First issue: connecting ports.  I've install qjackctl but it doesn't
see the running jack instance.  EDIT: It works.  I was using patchbay,
not connect..

Wanted:
- Get a list of ports
- Connect command for ports
- A "connect daemon" : restore connections on restart
- Store connections in a db?
- MIDI learn

Basically, I want it to remember how it was last set up, and possibly
restore it as well.  Maybe also use version numbers of code.

This needs some refactoring.  The code is set up in weird ways.  It
would fare better with a flat supervisor structure.

I don't find a good starting point.

Assume the list of ports is known.  Add code to just do a connection?



Entry: Studio c build appears to be broken
Date: Tue Apr 23 18:47:07 EDT 2019

Change it to redo.

Then make it support fast reload, so the C code becomes easy to
change.  For glue code Rust likely will be overkill.  Rust is for
data-heavy applications that need speed and memory efficiency.

EDIT: Redo works and it produces c_src/studio.host.elf 

Next step is to make it use the same upload mechanism as the other
exo binaries.  EDIT: It already works:

<0.30665.2>: update via erlang: {'exo@10.1.3.12',<<"studio.host.elf">>,"/home/tom/bin/studio.elf"}

EDIT: Fixed reloads for control and midi.


Entry: Next?
Date: Wed Apr 24 11:23:12 EDT 2019

I need a host for DSP code that's always on.
It seems best done as a jack application.

There's a choice here: go for C first, or Rust.  I think it's probably
best to have both options available, so make a C host for simple DSP
code that reloads and reconnects according to some state.

Then move the Rust jack code into studio.

Maybe do the latter first acctually, to open the doors and allow
better decisions between these two.

EDIT: How to manage dependencies?  studio will depend on some rust
code.  Maybe the entire looper code can go into studio for now?  It
doesn't really need to be separate.

And just manage dependencies with links.

EDIT: Rust code builds.

EDIT: Rust code is integrated into erlang code and supervisor.

(exo@10.1.3.12)3> {ok,P}=studio_sup:find(studio_rs).
{ok,<0.698.0>}
(exo@10.1.3.12)5> studio_rs:call(P, count).
{ok,1}
(exo@10.1.3.12)6> studio_rs:call(P, count).
{ok,2}


The Rust jack code can now just be moved maybe?
EDIT: Done.  It is part of studio_rs now.



Entry: Recorder
Date: Wed Apr 24 12:55:36 EDT 2019

C or Rust?

Let's assume it's ok to handle the saving in Erlang, then only audio
channels need to be recorded, as the midi client can already dump its
data to the recorder daemon.

Take jack_midi.c as a template.  It's just dumping the data on stdout
in the jack loop.  Is that a good idea?  Mabe a condition variable
together with double buffering is a better idea.

Actually, a semaphore is better suited.

https://www.geeksforgeeks.org/use-posix-semaphores-c/

EDIT: Basic skeleton is coded.  Test it only when integrated.

Next?  Automatically connect client?  Not needed.  For now it can be
done manually.

I think it's all there now to make a recorder.  Create the start/stop
functions.

EDIT: Get rid of the midi hub?  Use the broadcaster instead.

EDIT: Done: serv hub is deleted.



Entry: Buffering
Date: Thu Apr 25 08:08:18 EDT 2019

It's currently not done properly.

1. write() is called inside the realtime thread.  This is not a good
idea.

2. is the update to write_buf variable actually atomic?  Yes it
probably is ok.


Entry: time stamps
Date: Thu Apr 25 08:56:27 EDT 2019

These are going to be rolling anyway, so let's just embrace that and
encode the phase using only 8 bits.  This gives ambiguity of:

(/ 48000.0 (* 64 256))      2.92 Hz  for 8 bit

(/ 48000.0 (* 64 256 256))  0.01 Hz  for 16 bit

Let's leave it at 8 bit for now.  It's probably enough.

(/ 48000.0 64) 750 Hz is the control rate.

Midi is 31250 baud or 3150 bytes/sec, or about 1000 note messages per
second.  The jack rate is in the same ballpark.

Problem is how to synchronize the clocks of the midi and audio
clients?  The trick is to not do this at all maybe?  Use a single
daemon for both audio and midi -- just extend the midi one, with the
following constraints:

- send out midi once per jack frame (64 audio samples) to keep the
  latency low.

- bundle up audio, and send it out in a single block every 4096 audio
  frames.



Entry: Next?
Date: Fri Apr 26 17:12:07 EDT 2019

Unify jack audio and midi.  First clean up the jack_midi client?

What about this: use the semaphore to just send a "ping" to the
low-prioirity thread for each message that needs to be sent out.

Packet size needs to change to {packet,4} (* 8 2 4096)

So do that first.

EDIT: ok I managed to get stuck in some weird corner, likely build
system bug.  I'm too tired to debug this right now..

But the general idea should work: use {packet,4} messages so audio
frames can be sent as well.  One write call for midi, and one for
audio bundled to 4096 samples per channel.

EDIT: Still buggy, but it's already clear that a 132kbyte write is not
going to work from the real-time thread.

It's looks like keeping midi and audio separate might be a better
idea.  But how to synchronize?  Is there a global jack time stamp?

Yes there is.  Read this with a clear head.  There are several
routines.

EDIT: Using this:

jack_nframes_t f = jack_last_frame_time(client);
audio_buf[write_buf].stamp = f / nframes;


Entry: recorder
Date: Fri Apr 26 22:17:59 EDT 2019

So the midi and audio clients are working.  Recording is easy from
this point on.  Start thinking about what to do with the recorded
data.


Entry: Random samples
Date: Sat Apr 27 08:42:24 EDT 2019

So I have a bunch of midi keys accessible now.  Map those to random
samples?


Entry: Looping the recording?
Date: Sat Apr 27 08:57:37 EDT 2019

But first, find a proper way to play back and loop a previous
recording.  Input is the loop length.  It needs crossover at the audio
stitch point.

The main problem is to create a data structure that is easily
accessed.  It would be an index into a mmapped log file.

BTW does mlockall interfere with regular memory mapping?


Entry: Manifold music
Date: Sat Apr 27 09:07:13 EDT 2019

I have 24 knobs in incremental mode.  These could be used to make
local excursions in a 24-dimensional control manifold.  How to make
this idea concrete?


Entry: Recording midi
Date: Sat Apr 27 09:43:01 EDT 2019

So I've added midi clock F8 data.

I'm starting to worry that this is getting a little too verbose.
Probably best to store it in binary, and keep it chunked?  Chunking is
likely not neccesary, but binary would make it easier to handle in
Rust.



Entry: Recorder is up
Date: Sat Apr 27 10:07:39 EDT 2019

What I want is basically to use the wall clock to find a particular
sequence, or some other kind of marker.

I need:

- Winding and start/stop via midi controller
- Some graphical multi-level display


First, maybe solve some issues with the recorder.  Especially deleting
old chunks based on disk free.

EDIT: Not using disk free, but using sum of data and index files to
trigger deletion.



Entry: mlockall
Date: Sat Apr 27 14:05:38 EDT 2019

Should loops be rendered into non-mmapped RAM?

I can't do mlockall.  So the architecture should definitely split the
mmapped disk read process from the real-time sample playback process.



Entry: Jack: multiple clients?
Date: Sat Apr 27 14:07:59 EDT 2019

Should I rely on fine jack client granularity?  It seems the only
reason to use jack is to use already existing applications.  For my
own DSP code I can just as well run it all in one client, or use Pd as
a host.


Entry: Connectivity
Date: Sat Apr 27 14:11:44 EDT 2019

So let's revisit the notification mechanism.  It might be easier now
to :

- get notified when clients (dis)appear
- query port lists
- restore connections from db




Entry: registration callbacks
Date: Sat Apr 27 15:02:57 EDT 2019

These tap points are enough

    ASSERT(0 == jack_set_port_registration_callback(client, port_register, NULL));
    ASSERT(0 == jack_set_port_connect_callback(client, port_connect, NULL));
    ASSERT(0 == jack_set_client_registration_callback(client, client_registration, NULL));

- port_connect studio:midi_out_12 system:midi_playback_14 1

An external application can be used to connect ports, but we can keep
track of connections in the database.


- client_registration studio 1
- port_register studio:midi_out_0 1

Client registration isn't so useful, but port registration can be used
to look up connections in the database and restore them.


I do not see a way to get notifications of midi ports being plugged
in, i.e. USB devices.  Actually, this might work but it would go via
port aliases.

EDIT: ok, got it.  api is just weird.

This should now be placed in a db.

Also, jack_daemon process should serve as a supervisor, restarting its
clients.

Or this could be done using nested supervisors.

EDIT: This is for later.  Getting bored with it.  Maybe solve it at
another time?


Entry: jack events
Date: Sat Apr 27 18:13:01 EDT 2019

It seems to work now:

(exo@10.1.3.12)33> studio_rs:call(studio_rs, {open, {jack_client, <<"rust_jack_sine">>}}).
studio_rs:call(studio_rs, {open, {jack_client, <<"rust_jack_sine">>}}).
{jack_control,"studio_control"}: {client,true,<<"rust_jack_sine">>}
{jack_control,"studio_control"}: {port,true,{<<"rust_jack_sine">>,<<"sine_out">>}}
{jack_control,"studio_control"}: {client,true,<<"connector">>}
{jack_control,"studio_control"}: {connect,true,{<<"rust_jack_sine">>,<<"sine_out">>},{<<"system">>,<<"playback_1">>}}
{jack_control,"studio_control"}: {client,false,<<"connector">>}
{ok,0}
(exo@10.1.3.12)34> studio_rs:call(studio_rs, {close, 0}).
studio_rs:call(studio_rs, {close, 0}).
{jack_control,"studio_control"}: {connect,false,{<<"rust_jack_sine">>,<<"sine_out">>},{<<"system">>,<<"playback_1">>}}
{jack_control,"studio_control"}: {port,false,{<<"rust_jack_sine">>,<<"sine_out">>}}
{jack_control,"studio_control"}: {client,false,<<"rust_jack_sine">>}
{ok,0}

This is the basic code reload infrastructure:
- wrap any DSP / synth code in a jack client
- keep track of connections
- restore connections when ports are created


Entry: Next
Date: Sat Apr 27 20:01:09 EDT 2019

DB support is there.  The rest should be straightforward.  It's time
to start making synth code.



Entry: Gated MIDI recorder
Date: Sat Apr 27 20:43:36 EDT 2019

This is different from the permanent recorder, which is more for
capturing "moments".  The gated recorder is intentional loop creation.

What I need for this is a data structure.  This needs to be something
that is easy to "advance".

It seems more of a rust-like problem.

So next step is to create a Rust Jack client with midi inputs.


A simple structure would be a set of circular buffers, one for each
cycle.  Just rebuild them on each cycle, merging incoming signals.
This avoids the need to work with linked lists.

So two approaches, per period:
- a linked list (C)
- a bouncing buffer (Rust)

In jack, align them to the 64-sample buffer.


To do these in C:
- record midi events in a (growable) array
- record the sequence in a circular list, referring to the events

It's actually more convenient to think of this as a t->[e] map: time
mapping to a set of events that happen at that time.  Recording an
event will create a new list at t if it doesn't exist yet, otherwise
it will append to the list.

Linked lists are hard in Rust, but it seems that unless the circular
"bounce" is used, it will be hard to do this properly.


Note on linked lists in Rust:
https://cglab.ca/~abeinges/blah/too-many-lists/book/README.html


I'm just going to use circular bounce.  This will be straightforward
in C as well.  The core is just a growable vector with iteration and
bouncing based on the record periods.

EDIT: It's pretty much just a delay line: a smaller circular buffer
"rolled" inside a larger circular buffer of allocated space.  When
events are added, the inner circle gets larger.

For audio it is similar, but there the buffer is actually circular.

So what are the primitives?

- peek event (to check timestamp)
- dequeue event
- enqueue event

then, optionally, if enqueue causes overrun, reallocate

Design them as byte or word queues.

EDIT: Implemented the data structure draft in jack_midi.c

EDIT: Filled it in some more.  Basic structure seems to be there.
Gaps need to be filled in and control is not clear yet.


Entry: MIDI control
Date: Sun Apr 28 01:00:54 EDT 2019

Typical problem: how to send some more complex data structures over
MIDI?  Maybe it is time for s-expressions.  Midi can send 0-127 in a
sysex, so ASCII would be good.



Entry: Next on sequencer
Date: Sun Apr 28 08:11:16 EDT 2019

Make the iteration over the "now" events abstract.
EDIT: Got some sign of life.

So it basically works.  But there is a lot of "management shit" that
still needs to be implemented.

- state marshalling
- midi routing matrix

The question is really to sysex or not.  It is not absolutely
necessary, since there can be a more generic pipe between Erlang and
the port program.  And it seems like a bit of a pain.  But once
implemented, it might be useful for other things.

Basically that 7-bit thing is awkward.  Text seems to be the only
non-awkward way to deal with it.

Yeah I don't want to do this with s-expressions.  Use binaries, and
use a bit stream.

https://blogs.bl0rg.net/netzstaub/2008/08/14/encoding-8-bit-data-in-midi-sysex/
7 bytes + byte with msb

Send the top bit byte first.  This avoids the need for adding a length
spec.

EDIT: I put some stub code there, but I need a test routine for these..

So assume the enc/dec problem is soved pending bugs.  The remainder is
then to allow for larger messages to be transferred.  I can't quite do
this kind of work right now.



Entry: Better control
Date: Mon Apr 29 08:40:21 EDT 2019

This needs some synchronization between high and low priority threads.
Maybe try a new architecture?

- low pri input thread
- high pri processing thread
- low pri output thread

This way any state snapshotting can be done in the high pri thread,
and communication delays can be handled in the low pri output thread.

As for the queues: don't do any allocation.  For larger messages, add
some form of round-trip acknowledgement.  This allows performing
transactions over time.

This is possible because the larger messages do not have any
low-latency requirements, i.e. they are state save/restore.

EDIT: Cleaned it up a bit, and made the buffers bigger to allow for
64*8 encoded / 64*7 decoded sysex chunks to be transferred.



Entry: Output thread not necessary?
Date: Mon Apr 29 10:17:11 EDT 2019

For simple midi it seems fine to just send a single write() call.  But
it seems that at some point this will break down when bulkier messages
are sent.

I can just try this to see how it goes.  E.g. fill up with a dummy
sysex message.

It is possible to poll from the real-time thread to see if the
low-priority thread has actually sent out a buffer.  This way some
kind of priority scheduling can be done.  E.g. don't send sysex if the
previous buffer didn't go out yet.

This is actually an interesting problem.

EDIT: I've done some tests, and it doesn't really seem to be a problem
to send out small chunks of data continuously via the process thread.


Entry: write() to an anonymous pipe
Date: Mon Apr 29 11:15:14 EDT 2019

I wonder, what are the guarantees that this will not block?  I.e. I
just want it to keep buffering, assuming that eventually the low
priority thread can do some bulk read to collect a bunch at once.

For now the assumption is that it is ok to do continuous writes from
the real time thread as long as the chunk size is "small".


Entry: sysex tests
Date: Mon Apr 29 14:24:15 EDT 2019

Weird.  Simple function sysex_dec_size, not doing what I think it does.
EDIT: operatore precedence



Entry: Protocol
Date: Mon Apr 29 21:48:45 EDT 2019

This is a pain in the ass really.  Requires a lot of ad hoc messages
with dump & parse.  Actually dump isn't really the issue.  This could
be done in text form actually, or ETF.

For restoring patterns: it might be simpler to use individual set
commands for this.  These can then be added to a "pending" queue,
which is added to the playback queue when it's time.

Maybe do that first.  That would make generated patterns possible.


Basic idea: keep the C code and data structures simple.  Put all data
shuffling at the Erlang side.

That "edit queue" isn't such a bad idea.  It could also be used for
removals.  Perform the queue edit right before playing the event.



Entry: Circular buffers
Date: Tue Apr 30 08:49:54 EDT 2019

It's possible to avoid copying, but not without a lot of effort.  The
point of the copying is to have the write pointer be at a spot where
there is space available without the need for moving any data.
I.e. the constant re-write ensures all operations are constant time,
at an increased cost.  With hot caches I doubt it will be a problem.

EDIT: This seems to work well.


Entry: Queues
Date: Sat May  4 20:30:39 EDT 2019

I find myself in need for more than one type of queue, so maybe
generalize some things such as:

- wrap a void* memory block and operate on void pointers.

- make it growable?

- move the write / grow part to the non-rt thread?

This seems to have a complexity explosion.  Let's just stick to two
implementations of queues.  Or write the implementaiton as a macro.

What about defining an ML-style module as a header file?

EDIT: Yeah that's a nice side track!

EDIT: Yes, I like this.  Move ns_queue to uc_tools.




Entry: Dumping
Date: Sun May  5 13:17:17 EDT 2019

Edits are working.

But I want to do this differently. It seems all a little too
convoluted.

What about providing a mechanism to swap the whole state atomically,
and have the low priority thread process the state?


Entry: Dump as text instead
Date: Sun May  5 14:41:53 EDT 2019

While it works, I think this binary format is going to give issues.

It doesn't take much more effort to just dump as text.  This way the
sysex doesn't need to be decoded.

EDIT: Ok, generalized to ns_dump.h s-expression dump module.

EDIT: Still needs chunking.  How to do that?

EDIT: Done. Chunks are reassembled based on paren balance.

EDIT: Using explicit more/done marker to avoid paren balance count.



Entry: Sequencer on STM32
Date: Sun May  5 16:38:22 EDT 2019

The jack midi sequencer is written with full sepration between core
and editor.  The core will run on an STM32 without malloc.

This opens up an architecture of distributed sequencers, reducing MIDI
bandwidth needs.



Entry: Pool the events
Date: Sun May  5 19:47:12 EDT 2019

Tracks will likely get out of balance (power law), so it makes sense
to pool events.  Though that will break some cache locality, and will
make it impossible to erase tracks separately.  Maybe not then?




Entry: Next?
Date: Sun May  5 21:04:17 EDT 2019

All the hard stuff is implemented.  Add some convenience, such as
changing midi clock tempo, sequence tempo changes.


Entry: Relative time stamps
Date: Sun May  5 21:06:32 EDT 2019

I just realized there is no simple way to speed up the sequences, so
maybe it would be good to represent the event time stamps
fractionally, using some kind of highly composite denominator.

This is for polyrythm.  What do we need?

(* 2 2 2 2 2 2 2
   3 3 3 3 
   5 5 5
   7 7
   11
   13)
9081072000

It might not be enough.  This might need to approximate fractions in a
different way.

It's not actually necessary to have high resolution in the small time
scales, so powers of two will do.  But it is necessary to have a bunch
of prime numbers to make it possible to have exactly locked sequences.


(* 2 2 2 2 2 3 5 7 11 13 17 19 23)
3569485920

I'm looking at it the wrong way.  Subdivision doesn't matter.  It is
only in the way that the period is represented that we need to ensure
perfect locking.

But it is going to be necessary to use relative indexing.

I need to do this when I'm awake..



Entry: Relative event time?
Date: Tue May  7 13:21:55 EDT 2019

This is only necessary in the case that edits are too expensive.  They
might not be.  Otoh loop speed change is something I would like to
have midi-controlled since it is so basic, so let's do relative events.

Once thing I worried about is that high resolution relative events
take up more bits when dumping patches.  But maybe 16 bits is enough?
That will give exact positioning for the more common power-of-two forms.

EDIT: Phase resets are still difficult to do in that they would be
O(N).  Maybe that is really not an issue, but it does show that the
setup might be a little too simple.  Slow phase morphs are possible
though, by changing the period.



Entry: Map all the synths
Date: Tue May  7 20:46:14 EDT 2019

Basically everything is  there now to start making  some pattern music
from Erlang.  Put it all in one module.

Start doing this by making a port/channel/transpose knob set that will
determine where the keyboard midi notes are going.  Then add some
learn functionality that records a tag in a database.



Entry: Connecting midi
Date: Thu May  9 17:53:46 EDT 2019

This should be a single functioon.

I want a list of clients and ports.



Entry: RAI
Date: Fri May 10 13:10:33 EDT 2019

Is connected to exo.
The doodle.rkt is set up as a task on broom.

Changing params will send on the pd messages.

It's now set up such that:
- emacs uses udp send to localhost 12345 on panda
- panda has forwarder to whichever doodle_pulse it finds
- exo:start(doodle_pulse) starts on node
- push_change will issue reload message


I think that this s-expession approach is more convenient.  Keep it.



Entry: Let's do a full set of "standard" effects and synths
Date: Fri May 10 15:51:13 EDT 2019

And compile them to WASM.

EDIT: Judgement is off.  Depressed state.



Entry: Midi controllers
Date: Sat May 11 15:16:25 EDT 2019

Let's see if this works: I want to run the synth on lroom, and plug
the midi controller into tp.

(exo@10.1.3.2)2> {exo_notify,{10,1,3,10}}: ignored: {add,dmmidi,{tp,1}}

Where does this come from?

{exo_notify,{10,1,3,10}}: exo_notify: Data: <<"env /etc/net/udev/notify-exo.sh tp\n">>
{exo_notify,{10,1,3,10}}: ignored: {add,dmmidi,{tp,1}}

It does handle midi, just not in a very transparant way.  What do I
actually want it to do?  Assume a hub-and-spokes model maybe, with zoe
always central hub, and other audio and midi devs referring back to
it?

Now what does it do?

It looks for midi_raw, which normally runs on 29, and sends it the
'add' message.

midi_raw ! {add,midi,{tp,1}}.


Then 29 tries to start an erlang process to access that node.  This
had a bug.  Then it tried to send to midi_raw process, which now has a
different protocol

Got it now.

Let's move midi_raw to zoe where it belongs: on zoe.

Ok, done.

So it goes like this:
- udev notifies exo_notify on 2
- this forwards it to midi_raw
- midi_raw starts a socat process to the node with the device
- and sends midi data on to midi_hub


Next: how does a pulse synth get the data 

EDIT: Simple: it subscribes to midi_hub



Entry: Virtual patch bay
Date: Sun May 12 20:38:35 EDT 2019

Use a breadboard or a patch bay as an input device to a digital
modular synth.

E.g. take a breadboard and have the top layer be outputs and the
bottom layer be inputs.  Send some scanning signal on the top and read
out the bottom.

Thinking about this some more, it seems that a patch matrix would be
more appropriate.  That would be easy to do with a touch screen gui,
e.g. using a tablet or an old phone.

This can also be done in code, similar to the number input.



Entry: Some controller ideas
Date: Sun May 12 20:52:16 EDT 2019

- patch bay (source code, gui or physical "scanning" bay)

- code editing with rotary encoders: one to scan through parameters,
  one to set the value.  this doesn't even need a rotary encoder: two
  sets of keys will be enough.



Entry: RAI
Date: Sun May 12 21:23:30 EDT 2019

Instead of going through udp, it should have a mode where it uses
distel to send it straight to exo.



Entry: Mobile
Date: Tue May 14 10:47:36 EDT 2019

So here's what I want on tp:

- work independently of exo network (mobile)
- optionally jack or pulse
- easycontrol grey knob set up for code param nav


So make it a bit more abstract.

Instead of a single hub, use many hubs that have the same interface.
Just chain them together.  This can be done later.  It's just
procrastination.  Get the synth up first.


Entry: rai synth
Date: Tue May 14 11:27:29 EDT 2019

In main_pd there is mention of a proc instance.  In pulse there is no
such thing.  The synth init code uses this instance information.

I likely don't need the instance, so how to init the proc?

I remember: pulse and jack use static data.  Pd uses dynamic data.

So it looks like the param_reader doe snot support the main gate/freq
inputs.  Those will have to be done separately.

EDIT: I think I understand.  It will need to be special-cased though,
just like it is in Pd.

There are a couple of possibilities.  Maybe raw midi is the most
useful?  I need a default way to map gate, note and velocity to
something.

EDIT: Note on/of via pd style messages.

Next is to get some sound out of it.  It's not doing anything, likely
because of those "controls".  Maybe create a simpler synth first?

EDIT: Ok it works.  But pulse has too high latency to be playable.  I
think the kmook archive has a jack midi implementation.

I actually did get quite far last time.  Pretty much finished it.



Entry: jack/pulse
Date: Tue May 14 18:42:18 EDT 2019

Make the studio daemons part of exo.  That way it is easier to start/stop.

EDIT: There are a couple of architectural issues in how all these
daemons are connected.  The proper solution is to have a supervisor
with dependencies.  Probably some nesting as well.



Entry: jack permission problem?
Date: Wed May 15 12:23:44 EDT 2019

There's a difference between starting it from a tp terminal, and
starting it via ssh.

In the former there are no error messages about permissions, and the
devices show up. 

I don't quite understand what's going on here..  Anyways, for now
there is a workaround: just start it in a terminal.



Entry: Running code standalone on wanda + tp?
Date: Wed May 15 12:29:19 EDT 2019

Basically, every node that runs jack should probably have a midi_hub.
Then when jack comes up, send midi events to all midi hubs in the exo
network.

EDIT: Going forward with this.  Run the simple synth as a jack plugin.

EDIT: Ok synth works.  Voice allocator is a piece of shit though.

EDIT: Solved the "local hub on partition" issue in exo.



Entry: Voice allocator
Date: Thu May 16 14:46:32 EDT 2019

How to create a better voice allocator?
- push all voices on the stack
- to allocate, pop one, mark it as used
- to deallocate, check that it is used and pop push it on the stack


Never dealloc a voice if there is another one that is not used.

Can a monophonic allocator be a special case?  I have one on the PIC
that uses a stack.



Entry: LRU voice allocator
Date: Sun May 19 09:18:16 EDT 2019

The main data structure is a list with the following oprations:
- Take the first N slots (= voice allocation)
- Add to the head (= note on)
- Remove from within the body (= note off)

Only the allocation step needs to be fast, because it is run on each
loop.

EDIT: I think I have something based on queue rotation.  Next is to
integrate it.


EDIT: Again.  There are two obvious next steps:
- accumulators in lta
- voice allocator



Entry: Starting a jack pluging
Date: Sat Nov 16 11:38:59 EST 2019

Two things are currently set up:

        {rai,ProcName}      -> {rai, proc, [ProcName]};
        rai_udp             -> {rai, run_udp, [12345]};

This assumes the port is in ~/bin.

(exo@10.1.3.12)6> f(Proc),{ok,Proc} = rai:proc(doodle_pulse).
f(Proc),{ok,Proc} = rai:proc(doodle_pulse).

So change it to use the default port spawning mechanism?
Not so important atm.

Let's ask some questions.  How can I find out the protocol?  What
messages does the thing support?

The main idea here was to send from emacs.

What actually happens when editing doodle.rkt?

Redo is not rebuilding anything.

EDIT: There is still something wrong with "redo install".  Removing
the .*.install files seems to fix the problem.

It's uploading, but not reloading.  Should be easy to fix but first
make the rai interface go through another mechanism.  Currently it is
sendin UDP frames without properly tagging what file it is from.




Entry: fix midi learn
Date: Sat Nov 16 18:37:48 EST 2019

It's completely obvious now: go into emacs, set point to the value,
hit the learn button, wiggle it and.



Entry: Resume
Date: Mon Apr 13 17:56:41 EDT 2020

I want to get back into writing music software.  I want to do it
without the ego this time.  I think that was the main impediment.

New tricks:
- no_std rust + async
- exo monolytg + incremental system is up
- (soon) webassembly for gui bootstrapping
- erlang epid + distro db

New insights:
- Use Erlang only for "patching", not for transport
- Keep cores simple (state machines)
- Focus on delta1010 DSP effect on ECP5 (better FPGAs will follow)


Entry: fixed function everything
Date: Mon Apr 13 22:22:02 EDT 2020

To make current setup usable, it needs to be made less programmable
first, so I can then loosen it up.


Entry: Lower the "analog barrier"
Date: Mon Apr 13 22:26:09 EDT 2020

- mixer
- envelope

the rest can just be noise


Entry: Ricky Tinez videos
Date: Mon Apr 13 22:30:43 EDT 2020

I like his mindset.  Good way to get to know about recent gear too.


Entry: on FPGA work
Date: Mon Apr 13 22:41:13 EDT 2020

One other thing: it is completely trivial to add processing to a FPGA
setup.  So why not start out with BBB, use the iCE40 board I already
have, and add a bus to the ECP5 boards.

Can I make ADCs in FPGA?



Entry: Motley Crew DSP
Date: Tue Apr 14 08:27:22 EDT 2020

The mixed digital/analog might be simplest to do with cheap ADCs in a
microcontroller.  It doesn't really matter it is 10 or 12 bit if it is
just for a synth voice that still needs to go through envelopes and
filters.



Entry: What is missing in the setup?
Date: Tue Apr 14 12:39:09 EDT 2020

It's not really playable.

Currently it's ok to let zoe be part of it.  Moving to a different
setup is too much work, but new code should be written so it can run
on minimalistic hardware.  E.g. move to C or Rust.

Erlang is mostly there for network management.




Entry: scale finder
Date: Tue Apr 14 21:53:03 EDT 2020

Go back to the idea of log scale with coarse "infinite" adjustment
knobs on the sides.


Entry: something not right
Date: Wed Apr 15 21:52:21 EDT 2020

(exo@10.1.3.12)1> jack_daemon: ALSA lib rawmidi_hw.c:133:(snd_rawmidi_hw_drain) SNDRV_RAWMIDI_IOCTL_DRAIN failed: Input/output error
jack_daemon: ALSA lib rawmidi_hw.c:133:(snd_rawmidi_hw_drain) SNDRV_RAWMIDI_IOCTL_DRAIN failed: Input/output error
jack_daemon: ALSA lib rawmidi_hw.c:133:(snd_rawmidi_hw_drain) SNDRV_RAWMIDI_IOCTL_DRAIN failed: Input/output error
jack_daemon: ALSA lib rawmidi_hw.c:133:(snd_rawmidi_hw_drain) SNDRV_RAWMIDI_IOCTL_DRAIN failed: Input/output error
jack_daemon: ALSA lib rawmidi_hw.c:133:(snd_rawmidi_hw_drain) SNDRV_RAWMIDI_IOCTL_DRAIN failed: Input/output error


Had to disable the midi hub for devices on zoe: they should use jack.
It currently doesn't really check.

Also ran into some issues with the cheapo 4 chan midi box.  Power
cycling helped.

And then studdenly it all works.  My guess: voltage issues somewhere.

Probably best to replace that cheapo with some custom midi circuitry.
Midi out is easy enough, and really one output for the 3 volcas is
good enough.

Also ordered some isolation transformers.  It does help quite a lot to
get the power supply noise out.




Entry: dumb time
Date: Thu Apr 16 15:51:56 EDT 2020

i need something i can use when i'm really dumb.



Entry: Looper
Date: Thu Apr 16 16:27:18 EDT 2020

What would be a good architecture for a looper?  I already have a midi
looper.  Maybe start there and do audio in the same app?



Entry: Recorder
Date: Thu Apr 16 17:29:20 EDT 2020

So I actually have this recorder.  Maybe it's time to actually start
using it and write a frontend?



Entry: Volca sync
Date: Thu Apr 16 17:37:33 EDT 2020

Spec says monaural 3.5mm.
So it's only pulses. Not start/stop.


Entry: next
Date: Thu Apr 16 19:01:33 EDT 2020

Okay today is not the day, but what does this need to be useful?

- Proper recording & playback of audio and midi loops
- Flexible and usable midi routing
- Soft synths
- Soft effects

Pretty much everything!
I should probably take a week to work on it.


Entry: volca hacks
Date: Thu Apr 16 19:04:23 EDT 2020

https://www.synthanatomy.com/2020/03/korg-volca-sample-hack-brings-polyphony-probability-triggering-more.html


Entry: stay idiosyncratic
Date: Thu Apr 16 20:24:18 EDT 2020

there is no point in trying to be everything to everybody.
let it flow.



Entry: Some notes
Date: Thu Apr 16 21:21:24 EDT 2020

Started playing a bit yesterday.  It's clear that the analog setup is
not going to be enough to make tracks.  Esp the drum machine doesn't
have enough control.  It might be good enough to get an initial thing
going, but then it should probably be sampled such that more control
is possible for mixing.

Lessons:

1) use a two-step approach:
- use synth as user interface to make loops
- mix the loops separately

End mixing stage should be completely digital, so I need a controller
just for mixing, eq and other things.


2) don't focus on midi recording.

Recording analog is going to be what enables many channels and
layering.  My analog bandwidth is too limited and should be used
mostly for bussing.

Also from the past it doesn't make sense to keep midi data without all
the other synth parameters.  The sound config will just get lost.  So
do this for fully specified digital only.


3) if we're focused on using the analog gear only for sound design,
what's the best way to lay out the channels?

It's not wired up in a bad way acctualy.  Currently I have:

digital inputs:
1-8: direct out from mixer channels

digital outputs:
1-2: 2x stereo

3-4: 1x stereo bus
5-8: 4x mono bus

This means that effects send from analog channels to the digital
effects can be digital, and all the stereo returns can




Some bounce ideas:

There are two main ways to combine analog and digital:.

analog synth -> digital effect -> recorder, or
digital track -> analog effect -> recorder.




5) full access mixing is going to be important

The easycontrol is fixed pot, so let those be fixed per channel
functions.  Volume for slider and some other function for the top
knob.  Let's keep it simple and fix the number of tracks to 9.

The button on the easycontrol can be used to select a channel
parameter on the br control.  This can be anything, but EQ and effects
send is going to be the most important.

This will need a panel display to show vu meters for channels, current
function for the br.




6) digital channel allocation optimized for bi-directional 2-bus

changes:

spirit/solderstation mixer -> digital  (these are all better than direct out)
- 2: Main mix
- 2: Sub mix
- 2: Solderstation mix (bench analog)
- 1: send 1 (pre)
- 1: send 3 (post)

digital -> spirit mixer
- the main mix is digital.  its output should go via ub mixer to monitors
- 2x stereo busses
- 2x mono busses


what about this:

analog  -> digital: two stereo busses
digital -> analog:  two stereo busses

Using two busses makes it easy to pass the entire "background mix" in
two directions, and still have a "foreground mix" to focus on.

The 2 stereo busses can also be used as 4 mono busses by panning the
channels.




7) Build the final mixer in pd

At least for now, until I have another interface.




Entry: The last 2 channels
Date: Thu Apr 16 23:53:00 EDT 2020

Probably effects sends are going to be most useful.
One is definitely reverb.  This can be the unused one.
The other one could just be duplicate of send to brute.



Entry: Ardour
Date: Thu Apr 16 23:56:47 EDT 2020

Can I actually use ardour as the mixer?  Sure why not.  Let's give it
a try.

I'm not really all that into using existing software, but a
mixer/tracker is probably a good idea.  No need to reinvent that
wheel.

EDIT: Yes this is a good idea.  Ardour is good for plumbing.

That also makes it clear what the next step should be.  Ardour should
probably do timebase.  Can it be looped?

Anyways.  The feel is back again for synth stuff.  The need for a
looper becomes apparent.  Also something that can sync to ardour's
timebase.



Entry: Ardour replacement
Date: Fri Apr 17 09:53:27 EDT 2020

First: is it possible to reuse ardour file format to get config?

.config/ardour5/templates/studiomix-template/

Yes it probably is.  But not for now.

What should the main router do?

1. properly name I/O
2. map readable names to routable names
3. delegate connecting



Entry: Ports
Date: Fri Apr 17 09:57:40 EDT 2020

(exo@10.1.3.12)1> obj:dump(jack_daemon).
obj:dump(jack_daemon).
#{audio => <0.769.0>,control => <0.763.0>,
  hubs => #Fun<exo.need_hubs.1>,midi => <0.768.0>,
  port => #Port<0.1373>,
  {<<"in">>,<<"Axiom-25-MIDI-1">>} =>
      <<"in-hw-6-0-0-Axiom-25-MIDI-1">>,
  {<<"in">>,<<"Axiom-25-MIDI-2">>} =>
      <<"in-hw-6-0-1-Axiom-25-MIDI-2">>,
  {<<"in">>,<<"Axiom-25-MIDI-3">>} =>
      <<"in-hw-6-0-2-Axiom-25-MIDI-3">>,
  {<<"in">>,<<"M-Audio-Delta-1010-MIDI">>} =>
      <<"in-hw-1-0-0-M-Audio-Delta-1010-MIDI">>,
  {<<"in">>,<<"USB-Midi-4i4o-MIDI-1">>} =>
      <<"in-hw-2-0-0-USB-Midi-4i4o-MIDI-1">>,
  {<<"in">>,<<"USB-Midi-4i4o-MIDI-2">>} =>
      <<"in-hw-2-0-1-USB-Midi-4i4o-MIDI-2">>,
  {<<"in">>,<<"USB-Midi-4i4o-MIDI-3">>} =>
      <<"in-hw-2-0-2-USB-Midi-4i4o-MIDI-3">>,
  {<<"in">>,<<"USB-Midi-4i4o-MIDI-4">>} =>
      <<"in-hw-2-0-3-USB-Midi-4i4o-MIDI-4">>,
  {<<"out">>,<<"Axiom-25-MIDI-1">>} =>
      <<"out-hw-6-0-0-Axiom-25-MIDI-1">>,
  {<<"out">>,<<"Axiom-25-MIDI-2">>} =>
      <<"out-hw-6-0-1-Axiom-25-MIDI-2">>,
  {<<"out">>,<<"M-Audio-Delta-1010-MIDI">>} =>
      <<"out-hw-1-0-0-M-Audio-Delta-1010-MIDI">>,
  {<<"out">>,<<"USB-Midi-4i4o-MIDI-1">>} =>
      <<"out-hw-2-0-0-USB-Midi-4i4o-MIDI-1">>,
  {<<"out">>,<<"USB-Midi-4i4o-MIDI-2">>} =>
      <<"out-hw-2-0-1-USB-Midi-4i4o-MIDI-2">>,
  {<<"out">>,<<"USB-Midi-4i4o-MIDI-3">>} =>
      <<"out-hw-2-0-2-USB-Midi-4i4o-MIDI-3">>,
  {<<"out">>,<<"USB-Midi-4i4o-MIDI-4">>} =>
      <<"out-hw-2-0-3-USB-Midi-4i4o-MIDI-4">>}


Small recap about how this works.

1. Jack daemon starts up, Erlang parses output.  This is translated
into an event stream like this:

<0.764.0>: {port,true,"system:midi_playback_14"}
<0.764.0>: {alias,"system:midi_playback_14","out-hw-8-0-0-LPK25-MIDI-1"}
<0.764.0>: {connect,true,"system:midi_capture_1","studio_midi:midi_in_10"}



Entry: Fixing connect
Date: Fri Apr 17 10:46:21 EDT 2020

Exo DB interface changed to support distributed mode
- Reads are still the same, but schemas have some restrictions
- Writes need to go through exo_db:put





Entry: Optimized
Date: Fri Apr 17 13:32:50 EDT 2020

1. delta1010 9+10 spdif out can be used.   i put them in ua-30 input

2. ua-30 only needs power to move that signal to its line out with
   attenuation

3. the ua-30 line out (main mix monitor) can now go into spirit
   2-track in, which allows straight connection.  note that the
   isolation transformer does add some attenuation.

4. this allows the 1202 eurorack to be removed entirely!

5. the ua-30 could be connected to another PC which then provides
   digital sync.  e.g. beaglebone with FPGA.





Entry: sprit SX acting up
Date: Fri Apr 17 15:04:34 EDT 2020

I think it's the yellow right main mix slider.



Entry: jack plugin gui
Date: Fri Apr 17 23:28:56 EDT 2020

How to create plugin guis?
Following youtube video I end up here as example:
https://github.com/calf-studio-gear/calf/tree/master/gui

there are xml files:
https://github.com/calf-studio-gear/calf/blob/master/gui/gui/compressor.xml

LV2 is mentioned:
https://lv2plug.in/

https://tytel.org/helm/



Entry: fix connect
Date: Sat Apr 18 17:01:15 EDT 2020

Start with what I want:
- connect(keys, brute).

This involves a couple of things:

1. Determine if the connection is local to a jack instance.

2. If not, use the epid

3. Else, delegate connecting to jack


I only want to solve 3. atm.  The rest should be a fairly trivial
extension.  But I want to be able to optimize, so let's use the
convention that if the pid's are the same in an epid, then connect is
special-cased to a local connection.



Entry: Names
Date: Sat Apr 18 17:25:11 EDT 2020

To solve connect, solve names.
Why are there 4 kinds of names?

1. main port name, e.g. "system:midi_capture_2"
2. alias "in-hw-2-0-0-USB-Midi-4i4o-MIDI-1"
3. jack_audio port number

I'm going to add another level of user-defined epid names on top of this.

Should those refer to numbers or names?  Probably numbers are going to
be most convenient.  The names are ad-hoc anyway.  Let's just keep it
uniform.

EDIT: Working through the alsa midi connect.  There is a degree of
freedom here

a. use alsa connect to connect the ports directly

b. implement a connect mechanism inside the jack_midi client

The latter requires more code, but could later be added to provide
some more flexible routing or mapping.  So we have to go with the
former for now.

EDIT: It seems alsa naming is not stable.  It looks like I'm doing
some parsing to map

in-hw-10-0-1-BCR2000-MIDI-2

to

BCR2000-MIDI-2

Indeed. Check the "scan:" handling in jack_daemon.erl

So there is no free lunch to look up the hardware ports, but what can
be done is to look them up in the db by using the knowledge of what
ports the studio_midi client is connected to.


Some workaround: studio_db:system_port/2

But this exposes a problem: connections cannot persist if names are
not stable.  So don't save them that way.

Use the functional relation of studio_midi port -> system port instead.

TODO: Remove the connection store/restore from jack and move it to
exo:connect/disconnect.




Entry: mixer
Date: Sun Apr 19 10:09:38 EDT 2020

I do want a smaller digital setup with volume control and main out, so
let's put the mixer back.

EDIT: Ok it is getting convoluted.

1. ua30 output -> ub1202 tape in
2. ub1202: CD/TAP to CTRL ROOM

This then frees up the bus for other things, so connect that back to the spirit.

Additionally, I've set up a path from spirit monitor out to 11/12 on
the ub1202, so at least there is an analog path to the speakers.

I probably should create a diagram for this.



Entry: So what's next?
Date: Sun Apr 19 11:07:21 EDT 2020

I have 'exo:connect' working.
This should probably log.




Entry: Couple of wiring changes
Date: Sun Apr 19 23:17:44 EDT 2020

- UB1202 is available as sub mixer
- The UA30 is wired to rackhub, which gives it audio sync
- rackhub will also be panel for the drum machine



Entry: There might already be many midi/osc control apps in android store
Date: Mon Apr 20 16:44:08 EDT 2020

And I have all those old phones still.



Entry: Time base
Date: Tue Apr 21 17:46:03 EDT 2020

So probably best to pick time base in jack.  How to do that?
First, switch off the other one.

https://community.ardour.org/a3_features_midi_clock

EDIT > Preferences > MIDI > Sync

TimeCode > JACK Trasport/Time Settings > Ardour is JACK TIme Master


Let's turn off the support in studio_midi.



Entry: 909 kick in reactor
Date: Wed Apr 22 17:52:49 EDT 2020

https://www.youtube.com/watch?v=A_AWH3SgM84



Entry: Don't record kick & hh
Date: Wed Apr 22 18:47:41 EDT 2020

This is of course obvious, so why did I not do it?





Entry: waveforms: sampler and logic analyser
Date: Sun Apr 26 16:01:35 EDT 2020

I have two things that are really the same problem: navigating digital
logic and oscilloscope traces, and editing music loops and samples.

I want a fast and simple tool.

Start with ideas from wvvw?

The trick there if I recall was to use the mouse in the same way as in
snd: left button is left selection, right button is right selection.
Time zoom is done using the middle button based on the location of the
mouse pointer.

Then just have a lot of those windows.

I need a substrate for this and I really don't want to use the browser
in a first attempt.

I want to be able to navigate this with just a mouse, and as long as
the mouse is in the window, keys have special meaning.  No chords:
just use the keyboard as buttons.

Let's do this so it will also work on a microcontroller, where
left/right mouse movement is one pot, scroll wheel is another, and
left/right buttons are two dedicated buttons.

Would SDL+Rust be a good first try?



So once it is possible to delineate loops, playing them back is fairly
trivial.

That said, let's take a look at Ricky Tinez' MPC3000 routing setup:

https://www.youtube.com/watch?v=ngFK2YOmuCU

- 10 audio outputs
- drum group (7 pads / channels)
- daw tempo midi in  (ERM multiclock)
- pro 3 synth in reach
- put pads on separate outputs
- don't overcomplicate things


Some notes: since I don't really need separate midi ports, why not put
them all on one channel?  Anyway, veering off.  For now the setup is
ok.  Control is tight enough using jack midi.

But the importance of having both audio and midi in the same client is
becoming important, so maybe that is something to focus on first?
 



Entry: Midi filters
Date: Sun Apr 26 23:51:52 EDT 2020

So I have that connect mechanism.  I can make filters that connect
channels to channels.



Entry: sequencer
Date: Mon Apr 27 00:14:45 EDT 2020

I think I'm done with these dinky sequencers on the volcas.  Let's
build something more centralized.

Maybe that step sequencer... LMMS


Entry: Polyphony
Date: Mon Apr 27 00:26:19 EDT 2020

This could be done manually by chaining the 3 synths to give 5 voices.


Entry: Fix things
Date: Mon Apr 27 16:12:29 EDT 2020

There is plenty of stuff that just needs to be wired up into the new
exo connect/redo mechanisms.




Entry: axoloti I2S interface
Date: Mon Apr 27 17:35:54 EDT 2020

Notes from chat with Johannes.


- I2S : multiple busses
- 3x clock

8MHz -> PLL in audio

- SPI conntroller configurable as I2S  STM32F4
- SAI block  (msb/lsb different)


old axo: no SDram, STM32F407
new axo: F427 (with SDRam controller)


https://www.instructables.com/id/Garduino-Gardening-Arduino/


- Generate ELF for "headless" object.



- start with release:
https://github.com/axoloti
2.0 has ELF

- this one has the ELF stuff
https://github.com/axoloti/axoloti/tree/master/api


cd platform_linux
make



Implement this class:
https://github.com/axoloti/axoloti/blob/master/api/patch_class.h


- enable packet communication debug

axoloti/src/main/java/axoloti/connection/USBBulkConnection_v2.java

dump_tx_headers
dump_rx_headers



Entry: arturia microfreak
Date: Mon Apr 27 22:50:28 EDT 2020

digital: 1 knob algo select, 3 parameters per algo
analog SEM filter

https://www.youtube.com/watch?v=-ZmwOaWNmcs

i can do the digital oscillators in rai.  all the other synths can
probably be modified to take filter inputs.

this is neat

another one:

https://www.youtube.com/watch?v=aRTLlfDRzpU


what to learn from that? rai is _way_ too simple to do all this, so
maybe start building two synths: one that is more classical analog
style (rai), and one that has more structural variance, to be written
in rust.  maybe find a combination?



Entry: filters
Date: Mon Apr 27 23:07:57 EDT 2020

What do I already have here?
- keys,bass: different, but both derived from miniKORG700S 12 dB/octave  (2nd order)
- brute: Steiner-Parker filter
- monotron: MS-10/MS-20 12 dB/oc
- fatman (needs new controller + one unassembled)

https://yusynth.net/Modular/EN/STEINERVCF/index.html
I count 3 caps, but wikipedia says 12dB/octave


https://en.wikipedia.org/wiki/Arturia_MiniBrute


Entry: A synth in rust
Date: Tue Apr 28 01:41:28 EDT 2020

Basically, use an entity component architecture.



Entry: Refocus
Date: Fri May  1 17:07:46 EDT 2020

I want too much.  It's important to first start playing, get in the
grove, and then figure out requirements.

Also the routing is currently not really set up well.  It is very
complex and too manual.  Go back to the midi learn idea.


Entry: Midi learn
Date: Fri May  1 17:09:49 EDT 2020

What is midi learn from the user interface pov?

- a button that enables learn mode
- the source controller (just play or turn)
- something that selects the target

So the problem is really selecting the target.  Basically every target
will need a learn button.



Entry: Change bus setup
Date: Sat May  2 08:56:14 EDT 2020

I don't use stereo track, so let's set up the busses such that they
record mono only.

Also I need to find a way to make recording simpler.

What is missing?
- save/restore of connect across client restarts
- simple loop sampler
- 1-1 port epid naming

1
I'm not sure why I find the connection thing so difficult.  Maybe I
want to do too much at once?

jack_control: {port,true,"20200502:midi_in"}
jack_control: {port,true,"20200502:r95"}
jack_control: {connect,true,"20200502:r95","system:playback_1"}


Let's do some simpler things first.
EDIT: Changed names to "out_1" etc..

So... output port appears.  This should lead to a connect operation.
The question is then: how to make that query "natural".

jack_control: {port,true,"20200502:out_1"}

First, is the name stable?  Yes: it's the only thing to go by.

Second: this needs to survive jack restarts, so the name cannot be a
pid.

Let's start with removing the connect from main_jack.c

Now what should happen when the port comes up?  Who is responsible for
maintaining the connections?

It is important to let sqlite do the scan over the table.  We're
storing a pterm.  The pterm could just have this form:

{jack_port,<<"doodle:midi_in">>}

I can't assume there is only one jack daemon in the system, but for
now it is probably ok.


EDIT: Got something working with some hardcoding.



Entry: Behringer NR300 Noise Reducer
Date: Sat May  2 18:12:21 EDT 2020

I want to mod it to make the attach time much shorter.
Also wtf is mute anyway?  It's inverted?

https://thetoneking.com/behringer-stomp-box-cross-comparison-chart/

It is derived from NS-2 noise suppressor.

attack knob:

left  = 0 Ohm
mid   = 150 ohm
right = 850k Ohm

os in series with R22 4.7k

EDIT: bridging that doesn't do a whole lot...

EDIT: I've wired the distortion chain into the effects loop.

Found schematics.  See library/link/boss-ns2-*

https://www.freestompboxes.org/viewtopic.php?t=11953&p=128917
http://obrazki.elektroda.net/47_1279571553.jpg


Entry: figure out how that patch bay actually works
Date: Mon May  4 14:07:27 EDT 2020

EDIT: Printed out schematic from manual and put it with the boxes.



Entry: code, next
Date: Mon May  4 15:58:43 EDT 2020

Start out with a mixer maybe for the looper?

EDIT: To move this in the Rust direction, it might make more sense to
start working with midi instead.  Maybe translate the existing
recorder?


MIDI:
- think state machine os
- start/stop filter (ardour loops)
- time doubler
- arpeggiator
- filter (e.g filter time from big)

LOOPER:
- record is linear record with wrap-around
- playback will need to fade
- keep originals, possibly cut
- auto line-up? not necessary when midi-synced

AUDIO:
- revive circular recorder + trigger?
- navigator for circular recorder




Entry: The idea is maturing
Date: Tue May  5 19:06:24 EDT 2020

And also tying into things I've learned and that are just now coming
together, such as rust async.  Basically, I want an operating system
for many small state machines.

One important insight is that RAI can't be everything because it
misses a certain flexibility in control flow.  It's fine though.  It
can be a modular synth.

So let's design it like that: machines that send messages.



Entry: Crackles
Date: Fri May 15 12:14:18 EDT 2020

It seems to be the +4/-10 buttons on the delta1010.

I had taken out the Xenyx802.  I've wired it back up, but now it just
goes into channel 8 of the spirit.  That is the "debug" mixer so can
just go wherever.

This frees up input 5/6 on the delta1010.  Those could be effects
sends?  EDIT: Yes.  Jack now has AUX1 and AUX3 strips.

1202 is now free, so I've put the snake there and filled it up with pc
and sprit monitor.



Entry: Tone knobs
Date: Sat May 16 20:01:17 EDT 2020

So find out the pre/post eq thing on both pedals.



Entry: Raymond setup
Date: Tue Oct 13 12:00:41 EDT 2020

- removed zni. zoo now has delta1010, and is main workstation
- set up small speakers at workstation, with 802 mixer
- solder station is now close to other audio mixers (spirit, 1202)

Nothing is wired yet.  Will have to see how that pans out.  Always an
issue if there is not just a ton of room to just let the cables hang.
I can probably do that somewhat, by adding supports to the back of the
slanted panels.


Entry: TD-3-SR
Date: Fri Oct 30 16:35:27 EDT 2020

https://www.youtube.com/watch?v=2l3rd89aXrQ

4 x 8 x 2

- 4 pattern groups:
  - 8 patterns
    - 2 sections

- transpose = pitch + note 


Entry: TD-3 midi
Date: Sun Nov  1 18:20:22 EST 2020

https://303patterns.com/td3-midi.html

It seems quite straightforward.  Maybe an emacs editor for it?




Entry: Pick this up again (Raymond)
Date: Tue Nov  3 19:04:23 EST 2020

Most midi is connected.  Audio for volcas needs some work.

So what can I do with this?  What I want to do is to create some
interfacing to create pattern sequences for the synths, and also to
access the internal pattern sequencer if possible, e.g. for the TD3.

I want to get to something that is "live".  E.g. edit patterns live,
and do effects and synth settings.



Entry: Axo as reverb / delay
Date: Fri Nov  6 10:52:03 EST 2020

Instead of buying yet another box?



Entry: Review the midi daemon
Date: Sat Nov  7 08:39:33 EST 2020

I currently don't really remember how it works.
Start by a simple thing: connect the keyboard to the td3.

EDIT: Something happened with the configuration database.



Entry: Config DB
Date: Sat Nov  7 09:38:08 EST 2020

So what is the point there?  Why can't it just be code?
The reason would be that something is modifying it, e.g. a gui.

But there probably should be a lens that takes a snapshot and turns it
back into code.



Entry: I'm fumbling about...
Date: Sat Nov  7 11:34:11 EST 2020

Maybe let's just give up on these internal sequencers, and build an
integrated one, or a generative one.  Tidalcycles?


Entry: analog setup: feedback
Date: Mon May  9 09:11:09 EDT 2022

Main issue is the high gain feedback, which really needs a switch.
Or maybe a patch cable is enough.

This issue is solved by using feed-through only, but it might be
simpler to dedicate one mixer to feedback and leave the large one at
the end.

That doesn't actually allow feeding instruments into the noise
feedback chain, so keep it as it is.




Entry: new dsp ideas
Date: Mon Aug 22 08:15:07 EDT 2022

I want to do something with cheap 12 bit ADC.
Was thinking something on CM3 but CM4 might be minimum.
Do want floating point.



Entry: audio setup
Date: Wed Aug 24 07:02:44 EDT 2022

delta1010 still seems fine

trying sync to ua30, which seems to work, but can't get it to operate
without pops.

getting very distracted there... somehow got it in my head the sync
setup is important, that there is something to learn there...

anyways
seems music itself isn't happening right now
mostly in tinkering mode...



Entry: tsn
Date: Wed Aug 24 07:12:47 EDT 2022

https://tsn.readthedocs.io/



Entry: sync the other way?
Date: Thu Aug 25 21:00:18 EDT 2022

It didn't occur to me that the delta1010 can take sync in just fine,
so what about sending it out from this then use envy24control?



Entry: still messing with devices
Date: Sat Aug 27 19:54:38 EDT 2022

I ordered another fasttrack pro after finding out 64,2 seems to work
fine with jack+pd on a x230.  That's the ideal portable setup really.

So let's not worry about sync on those.  4 in 4 out is enough as a
local analog node.  I have one now set up to take wet from guitar with
2 back to mixer.

The ordered ftpro can go on the workbench.

The main workstation has spdif audio coming from the delta1010 in the
synth corner.



Entry: emu10k1
Date: Sat Aug 27 23:04:35 EDT 2022

delt1010 crashes the z440
trying with emu10k1
i want to use the machine as a soft synth
so would be nice to have digital out into delta1010 on other machine

https://01.org/linuxgraphics/gfx-docs/drm/sound/cards/emu10k1-jack.html


Entry: just send the fucking packets
Date: Sat Aug 27 23:55:43 EDT 2022

so what about this:
jack or pd sends 64 bytes to compute host
compute host computes
sends 64 packets back
this is done with sequence over udp
the compute node runs io_uring or some other low latency network stack

this might work with pd batch mode blocking on udp reception


Entry: udp latency
Date: Sun Aug 28 00:13:21 EDT 2022

i think this will need to bypass the kernel using dpdk say stick to 64
samples at 48kHz thats (/ 48000.0 64) a 750kHz packet rate.

Say 8 channels float that's (* 4 8 64) 2048 bytes which is already a
jumbo packet of 2048 bytes.






Entry: Revisit
Date: Thu Aug 18 12:54:24 EDT 2022

For sure I'm trying to do too much...
But I do want to keep focusing on integration.
Today's idea is to synchronize audio on two setups.

What I want to do is fairly simple: send audio from one machine to the
other so alsa can sync on it.  This works with the UA-30.

Maybe it's enough to just have analog transport for now?

I'm making this too difficult.
It should just send word clock.





Entry: S/PDIF
Date: Thu Aug 18 13:05:35 EDT 2022

Doing this over Ethernet makes no sense.  It's important to keep the
bit clock going such that it can feed a PLL.

It's biphase mark code

https://en.wikipedia.org/wiki/S/PDIF

From scope picture there the transition time is around 150ns
Or about 6MHz

Better one here:

http://www.crazy-audio.com/tag/oscilloscope/

81ns

12.27MHz.

(/ 12.26 0.048)
255.41666666666666

(* 48000 24 8)
1152000


(* 256 48000)
12288000

(* 32 2 48000) -> 3MBit/sec



https://www.st.com/resource/en/application_note/an5073-receiving-spdif-audio-stream-with-the-stm32f4f7h7-series-stmicroelectronics.pdf

The SPDIFRX peripheral embedded in the STM32 (STM32F4, STM32F7 and
STM32H7 Series, see the applicabe device datasheet) is designed to
receive an S/PDIF flow compliant with the IEC-60958 and IEC-61937
specifications.

https://wiki.st.com/stm32mpu/wiki/SPDIFRX_internal_peripheral


also look at this: timer/counter?

https://hackaday.com/2021/04/04/decoding-s-pdif-with-a-microcontroller-brings-a-few-headaches/
https://jeddelog.com/posts/soft-spdif/


https://www.youtube.com/watch?v=udlK1LQ3f3g
https://bela.io/products/
https://www.electro-smith.com/about-us



for RS485: i have LTC1480 which is up to 2.5MBit/sec

i think i'm just going to need to do ethernet

Measuring what comes out of the delta1010 is 3MHz, 3MBit

(* 32 (* 48000 2)) 3072000 Hz






Entry: JUCE
Date: Thu Aug 18 16:41:38 EDT 2022

https://juce.com/

The leading framework for multi-platform audio applications



Entry: Other ICE1712 cards
Date: Thu Aug 18 19:26:25 EDT 2022

Terratec DMX6fire
STaudio DSP2000

https://www.zzounds.com/item--STODSP2000
https://www.tomshardware.com/reviews/terratec-dmx-6fire-24,410-2.html

https://lore.kernel.org/all/5161A6D3.3060602@gmail.com/T/



Entry: S/PDIF RS485 board
Date: Thu Aug 18 19:43:30 EDT 2022

James is right.  Use off-the-shelf things.

Because if I make a board, I need RS485 in both directions.
It's probably simplest to get a 35ft coax and be done with the distraction.
Later, use nano boards with high speed transceivers for this kind of thing.

EDIT: I bought a $20 cable.
EDIT: That works ok with UA30, but FTPro gives pops.

Also, S/PDIF is AC-coupled so would have been a mess to get that going
really.



Entry: igb 5.10
Date: Thu Sep  1 13:14:17 EDT 2022

updated: zoe, rackhub, mimas


Entry: How does jack connect work?
Date: Fri Sep  2 08:09:11 EDT 2022

It used to connect when container was started.
Does jack see this or not?

I don't find anything obvious.  So assuming this is no longer done
automatically?

I think it will be necessary to figure out the entire flow graph and
define it statically.


Entry: fatman
Date: Mon Dec  5 19:31:06 EST 2022

i put up a new work corner in the basement
the fatman is sitting on the desk

it has a replacement pic board
but i am going to use something else for this
maybe this is actually a good excuse to try rust

it doesn't matter where this is going
a plan is not needed

might be possible to use the eidac circuit to drive this one.




Entry: standardize exo studio startup
Date: Fri Dec 23 08:36:14 EST 2022

issue: -d alsa -X raw is needed for midi in /etc/net/dsp/jack-$HOSTNAME.sh

issue: jack_daemon doesn't start automatically when exo beam starts

issue: config database should auto-create.  see mimas startup log:

Dec 23 08:33:32 oberon exo_vm[2604]: =SUPERVISOR REPORT==== 23-Dec-2022::08:33:32.294315 ===
Dec 23 08:33:32 oberon exo_vm[2604]:     supervisor: {local,exo_sup}
Dec 23 08:33:32 oberon exo_vm[2604]:     errorContext: child_terminated
Dec 23 08:33:32 oberon exo_vm[2604]:     reason: {{nocatch,{sqlite3_errmsg,<<"no such table: midiclock">>}},
Dec 23 08:33:32 oberon exo_vm[2604]:              [{sqlite3,sql,3,
Dec 23 08:33:32 oberon exo_vm[2604]:                        [{file,"/build/erl_tools-exo/src/sqlite3.erl"},
Dec 23 08:33:32 oberon exo_vm[2604]:                         {line,235}]},
Dec 23 08:33:32 oberon exo_vm[2604]:               {studio_db,midiclock_mask,0,
Dec 23 08:33:32 oberon exo_vm[2604]:                          [{file,"/build/studio-exo/src/studio_db.erl"},
Dec 23 08:33:32 oberon exo_vm[2604]:                           {line,68}]},
Dec 23 08:33:32 oberon exo_vm[2604]:               {jack_daemon,start_client,2,
Dec 23 08:33:32 oberon exo_vm[2604]:                            [{file,"/build/studio-exo/src/jack_daemon.erl"},





Entry: studio_db
Date: Fri Dec 23 10:32:40 EST 2022

This needs studio_db:db_init().
It's stored in exo db, which is in ~exo/

This should happen automatically.

There are still a bunch of issues with starting the vm properly.
It seems to have an issue right after reboot.
Then "nixos-rebuild switch" fixes it.




Entry: about this forth synth
Date: Thu Dec 29 09:58:42 EST 2022

I really just want to go back to Staapl and that PIC18 right?
Rust can wait.

I have a lot more clear mind about writing state machines at this time
so why not do that instead, as a macro language on top of Staapl.



Entry: piano, gigasampler
Date: Sat Mar  4 09:52:45 EST 2023

https://www.reddit.com/r/linuxaudio/comments/ospejd/best_piano_available_on_linux/


Entry: more channels
Date: Sat Mar 11 19:19:38 EST 2023

Every analog synth needs its own dedicated digital output to add inserts.
Dont mix dry.  Mix wet returns.
Analog distortion should use patch bays.



Entry: midi processing, erlang, C
Date: Sat Mar 11 19:40:07 EST 2023

Basically, there is Erlang code for routing over Erlang network and
doing setup and management, but I still want state machines to run in
C inside a jackd client and to keep it a bit simpler.

So maybe start reading jack_midi again



Entry: akai fire
Date: Sat Mar 11 20:14:49 EST 2023

https://blog.segger.com/decoding-the-akai-fire-part-1/
https://blog.segger.com/decoding-the-akai-fire-part-2/
https://blog.segger.com/decoding-the-akai-fire-part-3/


Buttons

Input,      Press,    Release
STEP,       90 2C 7F, 80 2C 00
NOTE,       90 2D 7F, 80 2D 00
DRUM,       90 2E 7F, 80 2E 00
PERFORM,    90 2F 7F, 80 2F 00
SHIFT,      90 30 7F, 80 30 00
BANK,       90 1A 7F, 80 1A 00
SOLO 1,     90 24 7F, 80 24 00
SOLO 2,     90 25 7F, 80 25 00
SOLO 3,     90 26 7F, 80 26 00
SOLO 4,     90 27 7F, 80 27 00
ALT,        90 31 7F, 80 31 00
PATTERN,    90 32 7F, 80 32 00
PLAY,       90 33 7F, 80 33 00
STOP,       90 34 7F, 80 34 00
REC,        90 35 7F, 80 35 00
BROWSER,    90 21 7F, 80 21 00
PAT UP,     90 1F 7F, 80 1F 00
PAT DOWN,   90 20 7F, 80 20 00
GRID LEFT,  90 22 7F, 80 22 00
GRID RIGHT, 90 23 7F, 80 23 00

Rotary Controls

Input,     Touch/Press Event, Release Event, Turn event
VOLUME,    90 10 7F,          80 10 00,      B0 10 xx
PAN,       90 11 7F,          80 11 00,      B0 11 xx
FILTER,    90 12 7F,          80 12 00,      B0 12 xx
RESONANCE, 90 13 7F,          80 13 00,      B0 13 xx
SELECT,    90 19 7F,          80 19 00,      B0 76 xx

The xx is relative: 7-bit twos complement so 01, 03, ..., 3F are
clockwise rotations (of varying angular velocity) and 7F, 7E, ..., 40
are counterclockwise rotations.

Pad control

Button, Press,    Release
R1 C1,  90 36 xx, 80 36 00
...
R4 C16, 90 75 xx, 80 75 00

The xx here is the velocity.  Limited velocity-sensitive, but not
very usable.

To illuminate PLAY, send B0 33 xx.  Same for other buttons.  xx is:

Buttons

Red-only       Green-only        Yellow-only       Yellow-red        Yellow-green
PAT BACK       SOLO 1            ALT               STEP              PATTERN
PAT NEXT       SOLO 2            STOP              NOTE              PLAY
BROWSER        SOLO 3                              DRUM
GRID LEFT      SOLO 4                              PERFORM
GRID RIGHT                                         SHIFT    
                                                   LOOP REC
Control values

00  Off       00  Off          00  Off          00  Off          00  Off
01  Dull Red  01  Dull Green   01  Dull Yellow  01  Dull Yellow  01  Dull Yellow
02  High Red  02  High Green   02  High Yellow  02  Dull Red     02  Dull Green
               03  High Yellow  03  High Yellow
               04  High Red     04  High Green



Rectangular LED 1     B0 28 xx     00  Off
Rectangular LED 2     B0 29 xx     01  Dull red
Rectangular LED 3     B0 2A xx     02  Dull green
Rectangular LED 4     B0 2B xx     03  High red
                                   04  High green

four circular red LEDs

Message 	Effect
B0 1B 00 	All LEDs off
B0 1B 01 	Channel LED on only
B0 1B 02 	Mixer LED on only
B0 1B 03 	User 1 LED on only
B0 1B 04 	User 2 LED on only
Then...
B0 1B 10 (00010000) 	All LEDs off
B0 1B 11 (00010001) 	Channel LED on only
B0 1B 12 (00010010) 	Mixer LED on only
B0 1B 13 (00010011) 	Channel and Mixer LED on
B0 1B 14 (00010100) 	User 1 LED on only
...
B0 1B 1F (00011111) 	All LEDs on




04  SysEx Continues which is part of the USB encapsulation
F0  System Exclusive
47  Akai Manufacturer ID (see the MMA site for a list)
7F  The All-Call address
04  SysEx Continues, and I will not show these bytes further
43  Sub-ID byte #1 identifies Fire product
65  Sub-ID byte #2 identifies the command
02  First byte of SysEx payload
...
F7  End of Exclusive


The USB specification says that all SysEx data uses that 04 leading
byte, and the final packet containing the F7 End of Exclusive will be
in a four-byte packet starting 05, 06, or 07.



02 00        - length 7,7 (256 bytes)
00 xx xx xx  - pad index, red, green, blue
01 xx xx xx
02 xx xx xx
03 xx xx xx
04 xx xx xx
...
3F xx xx xx


F0  System Exclusive
47  Akai Manufacturer ID (see the MMA site for a list)
7F  The All-Call address
43  Fire Sub-ID
65  Write Pad Array command
hh  High length byte, bits 7 through 13 of following payload
ll  Low length byte, bits 0 through 7 of following payload
Repeat for pads you want to change {
ii  Pad index, 00 top left through 3F bottom right
rr  Red level, 00 through 7F
gg  Green level, 00 through 7F
bb  Blue level, 00 through 7F
}
F7  End of Exclusive




static const U8 _aBitMutate[8][7] = {
  { 13,  19,  25,  31,  37,  43,  49 },
  {  0,  20,  26,  32,  38,  44,  50 },
  {  1,   7,  27,  33,  39,  45,  51 },
  {  2,   8,  14,  34,  40,  46,  52 },
  {  3,   9,  15,  21,  41,  47,  53 },
  {  4,  10,  16,  22,  28,  48,  54 },
  {  5,  11,  17,  23,  29,  35,  55 },
  {  6,  12,  18,  24,  30,  36,  42 }
};
 

static void _PlotPixel(unsigned X, unsigned Y, unsigned C) {
  unsigned RemapBit;
  //
  if (X < 128 && Y < 64) {
    //
    // Unwind 128x64 arrangement into a 1024x8 arrangement of pixels.
    //
    X += 128 * (Y/8);
    Y %= 8;
    //
    // Remap by tiling 8x7 block of translated pixels.
    //
    RemapBit = _aBitMutate[Y][X % 7];
    if (C > 0) {
      _aTestBitmap2[4 + X/7*8 + RemapBit/7] |= 1u << (RemapBit % 7);
    } else {
      _aTestBitmap2[4 + X/7*8 + RemapBit/7] &= ~(1u << (RemapBit % 7));
    }
  }
}

The OLED write display SysEx

The SysEx that writes the OLED display is as follows:

F0  System Exclusive
47  Akai Manufacturer ID
7F  The All-Call address
43  Fire product
0E  Write OLED command
hh  Bits 7-13 of payload length
ll  Bits 0-6 of payload length
00  Start 8-pixel band of update
07  End 8-pixel band of update (here, 8 bands of 8 pixels, i.e. the whole display)
00  Start colum of update
7F  End column of update
xx  Bitmap data formatted as in _PlotPixel()
F7  End of Exclusive






Entry: live coding
Date: Mon Mar 13 19:40:08 EDT 2023

I want to go back to live coding.

The rai thing was a good start.  I want to combine that with state
machine generation.



Entry: how to get this started again?
Date: Mon Mar 13 19:44:26 EDT 2023

i want the results of this, the pride.

i however do not have the inspiration. there is no intrinsic drive to
get over the threshold. i keep going for low hanging fruit.

EDIT: Alright I have cloned a skeleton for jack midi->audio.  Next is
to revive how to start and connect a synth, then look at the old
processor API and see where that left off, then revive the entire big
netowork thing.


Entry: text-based
Date: Mon Mar 13 22:03:39 EDT 2023

So I am clear about this: i want text-editor interface to music
network, with all parameters auto-assignable and scale tweaking.

As for the analog setup, I just want to connect everything to
everything.  The analogs are for live play.  I do want to build
pieces, so maybe focus on using analog for samples etc, or build a
digitally controlled analog synth.

So maybe time to be very clear about what language to use.  It really
has to be racket.  There is no decent alternative.  That's the only
place where I can mix different semantics.

The backbone would be Erlang, or an Erlang-style network.


Entry: analog
Date: Mon Mar 13 22:15:33 EDT 2023

actually I don't care so much about analog mixing.

so what do I have to connect?

delta1010 in:
- brute
- tb-03
- volca keys
- volca bass
- volca drums
- guitar effects wet (send from behringer mixer)
- guitar / bass / mic clean (via behringer mixer)
- modular / misc analog

- then the 8 outs could go to analog mixer feeding to speaker,
  straight through by default


the second delta1010 is then free to use

EDIT: tried to gang them with the coax and that works fine

Also the envy can be set up to monitor, so there would be no latency
at all.

EDIT: ordered a thinner stereo RCA cable.  Coax is very stiff.
Curious if that will work as well.

So basically I could run a digital mixer on zoe, bring the audio over
spdif to zoo.

EDIT: Once envy24control switches to spdif it can't be put back to
internal until audio interface is opened/closed.



Entry: Voice stealing
Date: Wed Mar 15 21:40:35 EDT 2023

LRU isn't really the solution.  A good voice stealer would remove the
least important note, whatever that means.

https://electronicmusic.fandom.com/wiki/Voice_stealing


Entry: focus on a single synth for a bit
Date: Sun Mar 19 22:31:33 EDT 2023

One desk, one synth, all the rest digital support (pd + plugins).


Entry: Jack auto-connect
Date: Mon Mar 20 08:46:00 EDT 2023

There needs to be a dag stored somewhere such that the client creation
event can create the proper connections.



Entry: modes
Date: Mon Mar 20 17:30:40 EDT 2023

1: every knob is an instrument.  intensity is volume.  color is
  spectral content

2: drum machine



Entry: code reload
Date: Mon Mar 20 17:44:12 EDT 2023

Should I not bother and just reload the jack application?  Or do a
"popless reload" by double-buffering two SO libraries and ldopen?

Wondering... would it be simpler to put everything in Pd instead?
Bypass the whole jack thing for now.  Just make reload work with
dlopen?

No, midi doesn't work well in pd.

So let's stick to jack.  Use the patchbay maybe?

Advantage is that this is a standard application.
https://www.rncbc.org/drupal/node/76

Actually it's already doing this and I spent a lot of time on making
this work in a uniform way.




Entry: chaining
Date: Mon Mar 20 20:15:14 EDT 2023

So soon to have 4 machines that could be chained with spdif or
wordclock.  But let's start simple: zoe and zoo can now be chained
with spdif.  Zoe could host and sub-mix experimental analog that is on
the bench then transport to zoo, and vice versa.

The jack thing is going to need to configure all of this and save it
in Erlang DB.



Entry: 
Date: Wed Mar 22 06:58:47 EDT 2023

exo:start({rai,jack,<<"doodle">>}).

It's looking for 
sh: line 1: /home/tom/rai_uc_tools/doodle.jack.host.elf: No such file or directory

First problem is: how do I split /etc/net code from code that is
compiled on panda?  Also, it's probably best to push code to the
remote hosts so it can be run without NFS.

Maybe that was the idea there?

The core idea is how to allow code updates without nixos-rebuild, but
also allow nixos-rebuild to install defaults?  Well let nixos-rebuild
install the compiler.



Entry: Sync
Date: Fri Mar 24 16:15:15 EDT 2023

The 3 PCs can do their own multitracking and just send the mix out for
bus chaining.  Then later tracks can be combined.

It's time to make it easy to develop this... Set up a loader etc.


Entry: Layla 3G jack
Date: Thu Apr  6 09:24:52 PM EDT 2023

Actually it does work just fine.
Chan 1+2 are duplicated on the headphone out.
Not sure what was going on in the previous attempt.


Entry: Distributed mixer
Date: Thu Apr  6 09:43:15 PM EDT 2023

Now time to get this thing going.

The idea is to not rely on analog mixing any more, but wire all analog
equipment to direct in, and wire the 3 x 8 cards and PCs together.

Control backbone will be Erlang.  Data plane has its own connections
to keep sync.




Entry: microfreak
Date: Thu Apr 13 01:12:49 PM EDT 2023

https://www.youtube.com/watch?v=-ZmwOaWNmcs

- powers via usb
- 160 presets

- basic waves:
  - wave: square to saw
  - timbre: pulse width
  - shape: subosc

- supersaw: wave, mod, detune

- wavetable

- harmonic

- virtual analog

- waveshaper / folder

- 2 op fm

- formant

- chord: type, inversion/transp

- voice: word banks, formants

- modal: inharm, exitation brightness, damping

- 12dB/oct filter

https://www.arturia.com/products/hardware-synths/microfreak/details


Entry: 
Date: Thu Apr 13 02:11:52 PM EDT 2023

voice allocator:
- reuse the same pitch first




Entry: now what do i want?
Date: Fri Apr 14 08:48:49 PM EDT 2023

A single file that can describe all routing in applicative form.
Start by writing this in racket.  I don't want Erlang syntax.

But.. applicative form does have some disadvantages, as inputs to
synths will show up in a weird way.

{jack_audio,1} = microbrute({midi=jack_midi_2})

I guess this is ok.



Entry: next
Date: Fri Apr 14 08:59:09 PM EDT 2023

I guess read all the code again, and trace the startup.


Entry: something is in the way
Date: Sat Apr 15 07:13:24 PM EDT 2023

I just really do not want to read all that code and figure out how it
works. I want to start over with a new idea, something that is
"simple".

But let's not do that.  There was this whole epid thing so just
continue with that.  I think it worked.

First I probably need to continue with the build system to also do C
code.


Entry: trying something on luna
Date: Sun Apr 16 10:08:27 AM EDT 2023

Ok got jack configured.
Messing with sed again then abandoned...
Using fasttrack pro always now.

i keep getting stuck
what is it i actually want to do?

first, figure out why the midi looper is active on the microfreak



Entry: midi looper
Date: Sun Apr 16 01:09:06 PM EDT 2023

~/exo/studio/c_src/jack_midi.c

struct track
track_record_event
track_record
is called when record_mask&(1 << t)

record_mask is set here:

            if (in == 0 &&
                event.size == 3 &&
                msg[0] == 0xB0 && // CC channel 0
                (msg[1] >= 23) && // CC num on Easycontrol 9
                (msg[1] <= 31)) {
                uint32_t t = msg[1]-23;
                if (msg[2]) {
                    record_mask |= (1<<t);
                }
                else {
                    record_mask &= ~(1<<t);
                }
                LOG("record %d %d\n", t, msg[2]);
            }

This should be in the logs because default starts out as 0 and this is
in the path where it is enabled or disabled:

                LOG("record %d %d\n", t, msg[2]);

This is old hardcoded stuff, where easycontrol buttons are used to
enable/disable recording.


Questions / wants:
- Can this be seen in log
- How to rebuild without nix?
- Don't log midi to main log.  It is too verbose.
- Why is microfreak device 0?
- How does the device table work again?


tom@zoe:~$ journalctl |tail -n 10000 | grep record
Apr 16 13:18:39 zoe exo_vm[1435]: record 5 0
Apr 16 13:18:39 zoe exo_vm[1435]: record 5 1
Apr 16 13:18:39 zoe exo_vm[1435]: record 5 2

Track 5 is (+ 23 5) 28

Which is sent indeed, as part of some other cc messages.

The microfreak is sending stuff:

Apr 16 13:22:00 zoe exo_vm[1307]: <0.146.0>: {midi,171,{jack,'exo@zoe.zoo',0},{cc,0,28,2}}

Roadmap:
- Figure out how db works
- Set it up such that erl code can be changed incrementally on zoe
- Then do the same for C code



grep -nrI . -e 'studio_db:'
./jack_control.erl:108:   {C,P} = studio_db:port_pair(CP),
./jack_daemon.erl:134:    N = studio_db:port_id(Name),
./jack_daemon.erl:188:    clock_mask => studio_db:midiclock



Entry: database or not?
Date: Sun Apr 16 08:44:35 PM EDT 2023

What is relevant?
- When is it written?
- Are there many different ways of querying?

Going to put them in the studio file.




Entry: realistically, what next?
Date: Sun Apr 16 08:46:51 PM EDT 2023

i will need to take a break from work, or to work on this in the morning.



Entry: modify one of the patch bays?
Date: Fri Apr 21 09:31:50 AM EDT 2023

for the noise stuff it would be nice to have it modded to use a chain
by default, and maybe some knobs for mixing.

you know this is too much work


EDIT: added patchbay and later pd.  nice!

you know many things i get stuck in "too much work".  maybe just do
one small step.  things are more clear after that. either positive or
negative. just do the step.



Entry: next erlang
Date: Sat Apr 22 08:02:11 AM EDT 2023

- autostart jack and pd, but do this in exo_vm
EDIT: done for jack on zoe, mimas, pedal


Entry: wiring
Date: Sat Apr 22 10:04:20 AM EDT 2023

Monitors are on the Spirit SX

Sub mixers:
- ub1202 (RCA + transformer, no eq)
- layla 1,2 and delta1010 1,2 (TRS ,eq)



Entry: stuck on?
Date: Sat Apr 22 06:53:36 PM EDT 2023

- jack patching
- midi routing / processing  (make a dsl for this)
- always on recorder


Entry: next
Date: Sun Apr 23 07:54:11 AM EDT 2023

the always on recorder is not necessary yet.  just manually start it
every time.

the important parts are midi patcher and some kind of mixer, e.g map
each soft synth to a fixed position on the virtual mixer, then map
midi controls to it.

before being able to do this I need a couple of things, most
importantly is to restore incremental development.

it's also the difficult thing.


Can I make a dependency graph?
It is really the same as I did for the tax db.
Just start.

Loaded dev.erl code.
I don't know where to start from there.


Entry: just did some patching
Date: Sun Apr 23 12:53:41 PM EDT 2023

That worked much better.  Always pretty clear what's next when
actually doing things instead of preparing to do things.



Entry: syncing solder station
Date: Sun Apr 23 01:02:58 PM EDT 2023

Do I want audio to go from main setup to solder station?

Let's just do both.

Alright that's working
Also synced mimas:layla to zoe:delta1010 via word clock

So in theory I should be able to use this now:

https://manpages.ubuntu.com/manpages/trusty/man1/jack.udp.1.html

But I don't really need that.



Entry: use Pd
Date: Mon Apr 24 07:42:58 AM EDT 2023

It is clear though, that I should not make synths for jack, but
instead figure out a way to maybe modify Pd to reload externals, or to
make an external with a special plugin format.  Basically like sp
before, but use double buffering for the ldopen so it can be closed.



Entry: VCA in feedback path
Date: Wed Apr 26 12:14:27 PM EDT 2023

Put a VCA in the noise setup feedback path.  When an oscillator regime
is found, let it "learn" the range so it can play pitches.

That would be a cult hit if I can make that work.

Alright depression lifts and manic ego jumps right out.



Entry: jack and midi
Date: Sun Apr 30 07:31:11 AM EDT 2023

So the idea is that every midi device is identifiable.  I'm just
giving it a number for now.  A plugged device is a combination of
Erlang node and number.



Entry: connect
Date: Sun Apr 30 09:20:01 AM EDT 2023

Next step is to implement epid connect.

If there is a path on the local jack instance, use that.
Otherwise go through the Erlang abstraction.

They should work the same.

Then later, implement "building of network from source" separately.

So first up is to see if epid connect still works.

EDIT: Copied the code over to /etc/net
Next is to:
- Recreate the central emacs proxy
- Look up which jack client has a specific midi device


Alright exo:epid(emacs) and exo:send(emacs,123) are working.
Next up is jack midi ports.

What I really want is to autodetect port locations.

But that is not going to be easy as a first step, so make them
explicit at first.

EDIT: Forget about finding the ports in the jack instance for now.
Stick to zoe, make sure it works there.  Then later maybe add some
dynamic mechanism.

EDIT: Ok simple connect works on zoe.


Entry: jack port lookup
Date: Sun Apr 30 01:21:36 PM EDT 2023

Let jack_control or jack_midi keep track of the connections it makes.
I think there are disconnect notifications as well.

It seems to already do this:

(exo@zoe.zoo)3> obj:dump(jack_midi).                                                                                                                                      
obj:dump(jack_control).                                                                                                                                                   
#{{<<"studio_midi">>,<<"midi_in_17">>} => true,
  {<<"studio_midi">>,<<"midi_out_23">>} => true,
  {<<"studio_midi">>,<<"midi_in_11">>} => true,
  {<<"studio_midi">>,<<"midi_out_20">>} => true,
...}

I don't think that's it, because it's the same on an empty zora
instance.

Alright so read code.


Entry: pd autostart
Date: Sun Apr 30 03:25:23 PM EDT 2023

can i attach gui after?
maybe just use vnc indeed.
https://forum.pdpatchrepo.info/topic/10324/connecting-pd-gui-to-pd/2

let's not worry about this.. the gui should only be for "development".

maybe start pd from jack_daemon?

it can be started from xmonad hook. that's good enough.
EDIT: works fine



Entry: revive pd patches
Date: Mon May  1 09:49:34 PM EDT 2023

My externals such as ad~ don't run.
Maybe that one is just old.




Entry: modular
Date: Sat May  6 12:38:57 PM EDT 2023

Let's start incrementally building up the modular.
First the VCF, then maybe some CV for that.

I want to have some idea of signal levels.

Combination of guitar effects and modular is not going to be simple,
so maybe start with an array of amplifiers?

It's actually fairly hot, 3-4V pp
So doesn't look like that is going to be an issue.

Next step: cables from small to big jack.  Is going to be simplest to
make them RCA.  I have a bunch single ended.

Made cables, tested matrix mixer and breadboard.

Next: test the VCF + STM32F103 board.


Entry: integrators
Date: Sat May  6 05:31:41 PM EDT 2023

I can use those LM13700 to make integrators.


Entry: Playing with analog
Date: Sun May  7 03:16:41 PM EDT 2023

So how do I set this up?

I'd like to solder permanently.  Kinda done with the breadboards.

Stripboard seems like the thing to do.  Then use wires or component
leads + tape.


Entry: feedback machine into vcf
Date: Sun May  7 04:06:12 PM EDT 2023

that's nice

next: i want to automatically index this into loops and percussion
instruments, then somehow "slider through it" to create rhythms.  

generalize this to envelope.  that shouldn't be too hard.

also make that stm32f103 programmable, maybe expose it as sound card
from pd?


Entry: johannes modules
Date: Sun May  7 08:44:34 PM EDT 2023

pakje komt waarschijnlijk morgen aan bij jou

Op de "euro-axo" module staat een test-firmware geflasht voor de
"actieve haptics + 360deg pot", kun je die module eens (euro) poweren
en vertellen wat je ervan vind?

issues:

* de matrix-mixer heeft ~18kHz bandbreedte, ietsje te weinig,
  vuistwaardes zijn blijven staan...

* de max11300 module heeft ietsje te weinig plaats om een euro-power
  flatcable-connector met polarisatie-nok in te pluggen, bij een van
  de euro-power-kabels heb ik dat nokje weggesneden, die past wel.

* de max11300 module heeft pads voor een oled op het frontpaneel, maar
  die zijn niet volledig aangesloten, en niet getest. Zonder
  bedieningsknoppen vooral nuttig voor debug of nano-oscilloscoop
  ofzo.

* de max11300 module heeft plaats voor 6 pots, slechts n
  geassembleerd, die kun je evt nog toevoegen. bvb. Alpha
  RV09AF-40-20K-B100K of Alps RK09K1130A5R

* de bicolor leds volgen niet allemaal de normaal verwachte kleurcode
  als rood=positief groen/blauw=negatief

* de "euro-axo" module heeft een stm32h730, die heeft maar 1 usb
  poort, dus de device+host combo die erop zit is onbruikbaar. De
  device poort (usb-C) zou wel moeten werken. Ik heb hier nog geen
  opstart-code voor gedeeld (eerst even opkuisen...)



Entry: i need vcas
Date: Thu May 11 09:38:28 PM EDT 2023

I think I can do without envelope generators for now.  I need
exponential VCAs.

So do I build them?

Or do I spend the $100 to just get some, and spend the tinker time on
something else?

Linear VCA is cheap though.

Anyway for the digital control using the 12 bit DAC, the exponential
VCA is going to be best.  It sounds pretty good with the filter.

Maybe one that can do both?


What do I want?  Pd-controlled VCAs.
I can probably do that with my EXP DAC.

Looked at neutron. Has just one VCA.


let's build one



Entry: alright let's do it right
Date: Thu May 11 10:08:39 PM EDT 2023

build an actual module format?
getting ambitious again

EDIT: No. Stick to breadboarding one-offs.  Making a schematic is the
next step.



Entry: overthinking it
Date: Thu May 11 10:14:53 PM EDT 2023

Synth-wise, a neutron would probably be a good way to go.
But I really want VCA.

If the voltage varies slow enough, the EXP dac + load resistor might be enough.
Or do a differential pair.
Look at the microbrute again.

It uses BC847BS dual NPN


Or it might be much simpler to go with off-the-shelf exp vca and
program that 12 bit DAC so it hooks up to PD / wordclock.


EDIT: Ordered VCA

For the rest focus on the STM code and the existing circuit.

I created a synth_tools archive for experimentation, so it doesn't
have to sit in uc_tools.

EDIT: VCA arrived, but it doesn't work well with the inverted CV,
which works ok for the ladder filter.


Entry: something simple
Date: Mon May 15 05:30:37 PM EDT 2023

I need to do something. Feeling a bit low.


Entry: Hammerfall DSP Multiface II
Date: Mon May 15 05:38:08 PM EDT 2023

Should just work.
Question is more where to put it.



Entry: midi next
Date: Thu May 18 07:45:45 AM EDT 2023

What do I want?
- Simple midi router config file
- Simple recorder using start/stop buttons
- Live coding for implementing midi transfers
- Communication with PDM synth module

In all this, one of the real issues is that I don't have a STM32F1 midi interface.

So maybe start with that?

EDIT: So I have something working.

tom@luna:/proc/asound$ cat card3/midi0 
MIDI Synth

Output 0
  Tx bytes     : 0
Input 0
  Rx bytes     : 0

Next is to re-integrate that with existing API.  Basically I'm
starting from scratch.



Entry: 3if sysex is working
Date: Sat May 20 05:03:39 PM EDT 2023

next:
- app midi access
- erlang, C jack conn, dev
- sysex jack



Entry: integration with sysex jack
Date: Sun May 21 10:40:52 AM EDT 2023

What I want: create a connection topology, and restore the topology
whenever a device comes up.

Devices have identities in this network.

I need a context switch, some place to start.

Where do I want to end up?

With jack running on luna, I plug in the BP synth, a midi controller,
and the tether app, and have it all just work.



Entry: analog next
Date: Sun May 21 01:06:26 PM EDT 2023

Inverting amplifier.
Control the stm32f103.



Entry: midi epid on plug
Date: Fri May 26 06:31:49 AM EDT 2023

1. Basically when a port comes up and it is part of a begin or
endpoint in a epid connection, that connection should be made.

2. I'm going to want processing.  That would be possible by covariant
or contravariant functors in that connection.  Those can be
implemented in a DSL inside the midi router.

That's it really.  That's a nice incremental path.

Now the problem is: should the plug event cause a redo rebuild, or can
it be a separate FRP mechanism?

The real problem is that redo should be able to contain "embedded
makefiles".


Entry: new setup
Date: Tue Jul  4 05:01:23 PM CEST 2023

laptop and 2 new controllers, both mapping to device 0

Jul 04 11:00:12 narvi exo_vm[1363]: <0.110.0>: {midi,21,{jack,'exo@narvi.zoo',0},{on,0,102,32}}
Jul 04 11:00:12 narvi exo_vm[1363]: <0.110.0>: {midi,26,{jack,'exo@narvi.zoo',0},{off,0,102,0}}
Jul 04 11:00:15 narvi exo_vm[1363]: <0.110.0>: {midi,137,{jack,'exo@narvi.zoo',0},{on,0,53,8}}
Jul 04 11:00:15 narvi exo_vm[1363]: <0.110.0>: {midi,143,{jack,'exo@narvi.zoo',0},{off,0,53,24}}

what i want:
- both get connected to midi processing app
- they control a couple of soft synths
- all config in a single (Erlang) file


make it simple:
- start jack
- start synth
- connect using epid



Entry: jack_synth
Date: Thu Jul  6 08:06:07 PM CEST 2023


studio/c_src/jack_synth.c
-rw-r--r-- 1 tom tom  5112 Mar 26 21:12 jack_synth.host.o

which seems to be linked into the studio binary

going to have to remove that

it's compiled but it's not in the binary
i think that's as far as i got

next: move it to synth_tools
i want a jack synth without erlang baggage first


first client should be a pd netsend
first copy the jack_synth.c to synth_tools



Entry: wrong jack version
Date: Fri Jul  7 10:19:49 AM CEST 2023

had to yak shave build tools, now arriving at something i saw before:

CheckSize error size = 81 Size() = 85
CheckRead error
Unknown request 1801675114
Unknown request 1853453151
Unknown request 26740
...

I think I had a custom jack version somewhere.

First find out which one is tied to exo.

/etc/net/dsp/jack.sh: START=/etc/net/dsp/jack-tp.sh
jackdmp 1.9.19

/etc/net/nixos/pkgs/etc-net defines etc-net-run

That one uses jack2 package, which is not overridden.
Replacing libjack2 with jack2 doesn't work.

The studio package is building and has working clients so at least it
should have the correct build setup.

EDIT: Changed the nixpkgs to current zwizwa branch head and it's fine now.

So maybe overlays is better instead of having both overlays and a
modified nixpkgs?

Anwyays, it's working now


Entry: get the jack graph
Date: Fri Jul  7 11:02:25 AM CEST 2023

How to obtain the current jack graph?  I want to get rid of qjackctl.
Start looking at qjackctl source maybe?

tom@tp:~/git$ git clone https://git.code.sf.net/p/qjackctl/code qjackctl


alright... just RTFM
https://jackaudio.org/api/


    const char **ports = jack_get_ports(client, NULL, NULL, 0);
    for (int i=0; ports[i]; i++) {
        LOG("%d %s\n", i, ports[i]);
    }

when exo_vm is up and jack_synth is also running:

tom@tp:/i/tom/exo/synth_tools/tools$ ./jack_info.dynamic.host.elf
0 system:capture_1
1 system:capture_2
2 system:playback_1
3 system:playback_2
4 system:playback_3
5 system:playback_4
6 jack_synth:midi_in_0
7 jack_synth:audio_out_0

why are there no ports for the studio jack clients?
maybe because midi stuff gets started on demand?

let's plug in a keyboard

ok that was it

tom@tp:/i/tom/exo/synth_tools/tools$ ./jack_info.dynamic.host.elf
0 system:capture_1
1 system:capture_2
2 system:playback_1
3 system:playback_2
4 system:playback_3
5 system:playback_4
6 jack_synth:midi_in_0
7 jack_synth:audio_out_0
8 system:midi_capture_1
9 system:midi_playback_1
10 studio_audio:audio_in_0
11 studio_audio:audio_in_1
12 studio_audio:audio_in_2
13 studio_audio:audio_in_3
14 studio_audio:audio_in_4
15 studio_audio:audio_in_5
16 studio_audio:audio_in_6
17 studio_audio:audio_in_7
18 studio_midi:midi_in_0
19 studio_midi:midi_in_1
20 studio_midi:midi_in_2
21 studio_midi:midi_in_3
22 studio_midi:midi_in_4
23 studio_midi:midi_in_5
24 studio_midi:midi_in_6
25 studio_midi:midi_in_7
26 studio_midi:midi_in_8
27 studio_midi:midi_in_9
28 studio_midi:midi_in_10
29 studio_midi:midi_in_11
30 studio_midi:midi_in_12
31 studio_midi:midi_in_13
32 studio_midi:midi_in_14
33 studio_midi:midi_in_15
34 studio_midi:midi_in_16
35 studio_midi:midi_in_17
36 studio_midi:midi_in_18
37 studio_midi:midi_in_19
38 studio_midi:midi_in_20
39 studio_midi:midi_in_21
40 studio_midi:midi_in_22
41 studio_midi:midi_in_23
42 studio_midi:midi_out_0
43 studio_midi:midi_out_1
44 studio_midi:midi_out_2
45 studio_midi:midi_out_3
46 studio_midi:midi_out_4
47 studio_midi:midi_out_5
48 studio_midi:midi_out_6
49 studio_midi:midi_out_7
50 studio_midi:midi_out_8
51 studio_midi:midi_out_9
52 studio_midi:midi_out_10
53 studio_midi:midi_out_11
54 studio_midi:midi_out_12
55 studio_midi:midi_out_13
56 studio_midi:midi_out_14
57 studio_midi:midi_out_15
58 studio_midi:midi_out_16
59 studio_midi:midi_out_17
60 studio_midi:midi_out_18
61 studio_midi:midi_out_19
62 studio_midi:midi_out_20
63 studio_midi:midi_out_21
64 studio_midi:midi_out_22
65 studio_midi:midi_out_23


alright so these client and port callbacks are already exposed in
jack_control()

follow the breadcrumbs

Alright jack_control.c is already doing that

disconnect:

Jul 07 12:18:19 tp exo_vm[1338]: {port,false,"jack_synth:midi_in_0"}
Jul 07 12:18:19 tp exo_vm[1338]: {port,false,"jack_synth:audio_out_0"}
Jul 07 12:18:19 tp exo_vm[1338]: {port,false,"jack_synth:midi_in_0"}
Jul 07 12:18:19 tp exo_vm[1338]: {port,false,"jack_synth:audio_out_0"}
Jul 07 12:18:19 tp exo_vm[1338]: {client,false,"jack_synth"}

connect:

Jul 07 12:19:07 tp exo_vm[1338]: {client,true,"jack_synth"}
Jul 07 12:19:07 tp exo_vm[1338]: {port,true,"jack_synth:midi_in_0"}
Jul 07 12:19:07 tp exo_vm[1338]: {port,true,"jack_synth:audio_out_0"}



Entry: manage connections
Date: Fri Jul  7 12:19:39 PM CEST 2023

So next step: I definitely want to manage graph data in a high level
language.  There is already an Erlang "place" to do this, so don't
reinvent.  Look at what is actually happening already

What it should do:
- disconnect: nothing
- connect: go over all connections and restore them

The specification of this should be an Erlang data structure that has
a default, but can be loaded at runtime.

Alright, so where do these notifications get handled?

All messages go through Notify, which is set via start_link.  This is
passed in via jack_daemon:start_client/2 where Notify is already part
of the state.  Look at exo.erl in /etc/net which connects it to
exo:jack_notify/1

The port message is handled locallay and put into the State of
jack_control, so basically it keeps track of a database.

Alright so that part still needs to be built.
How to do incremental dev?

Let's develop on tp since that's the one to be used for the synthfest.

To install development tools on a node:

(exo@tp.zoo)9> exo:load_dev().
loading /i/exo/src/dev.erl
loading /i/exo/src/jack_daemon.erl
loading /i/exo/src/jack_control.erl
loading /i/exo/src/studio_cfg.erl
loading /etc/net/nixos/pkgs/exo/src/exo_epid.erl
loading /etc/net/nixos/pkgs/exo/src/exo.erl
loading /i/exo/src/redo.erl

After that:

dev:load() also works.



Now the first thing to know is that when a midi interface is
connected, jack_daemon will scan jack output and call
jack_daemon:handle_connect() which uses studio_cfg:port_id to connect
the physical port to the studio_midi patchbay

What I want to do is simpler: I want a direct connection between midi
controller and softsynth.

Maybe the studio_cfg:port_id/1 function could be changed to also
reflect softsynths?

Anyway I need some uniform way to deal with this.

The main idea is that studio_midi is the interface between Erlang and
the jack midi, so it should be connected to everything.


Entry: a single kind of plug event
Date: Fri Jul  7 01:04:45 PM CEST 2023

How to structure this?

First, the realm is "configuration is code", which means we are always
talking to an Erlang compiler.  A patch can then be an erlang module
with a unique name that is loaded into a running system as part of
exo:load_dev().

First what do I want?
I want a connection from the uma to the softsynth.

Does the epid handle this?

I found these:

epid(midi_clock) -> epid({jack_port, <<"ardour:MIDI Clock out">>});
epid(doodle)     -> epid({jack_port, <<"doodle:midi_in">>});

Be explicit first, then later abstract things in exo_epid.erl

exo:epid({jack_control, {port, out, 22}, 'exo@tp.zoo'}).
exo:epid({jack_control, {jack_port, <<"jack_synth:midi_in_0">>}, 'exo@tp.zoo'}).

exo:connect(
{jack_control, {jack_port, <<"system:midi_capture_4">>}, 'exo@tp.zoo'},
{jack_control, {jack_port, <<"jack_synth:midi_in_0">>}, 'exo@tp.zoo'}
).



What I need is the following:

- Connect every midi port (including softsynths) to the studio_midi
  hub.  These are all "instances".

- Make midi connection work via the epid mechanism.

- "Tighten" the connection to go through jack if the node name is the
  same.


First, make sure that connecting via the daemon works properly.



Entry: what are the rules for midi ports?
Date: Fri Jul  7 01:46:56 PM CEST 2023

- There is a 1-1 map between studio_midi port (single number, in or
  out) and a system port.

- The system port can be looked up from {Dir,PortNb}

(exo@tp.zoo)16> obj:dump(exo:pid(jack_daemon)).
#{audio => <0.189.0>,control => <0.187.0>,
  hubs => fun exo:need_hubs/1,midi => <0.188.0>,
  notify => fun exo:jack_notify/1,port => #Port<0.17>,
  {in,22} => <<"in-hw-1-0-0-UMA25S-MIDI-1">>,
  {out,22} => <<"out-hw-1-0-0-UMA25S-MIDI-1">>}

  From there standard tools work:
  jack_connect in-hw-1-0-0-UMA25S-MIDI-1 jack_synth:midi_in_0



What's the next step here?  Find a way to register soft synth midi
ports.

But that can be postponed.  I first need to have a working synth.
This can either be a jack client (which is already set up) or a
netsent to Pd.

Maybe the netsend is a good idea anyway?  Could also just be another
client.



Entry: interactive development
Date: Fri Jul  7 02:38:30 PM CEST 2023

Is the most important part.

This means that I want to auto-connect already, then later figure out
how to generalize.

Basically when the synth port comes up, connect it to audio.

Let's configure the softsynths to be always on, at least, from config.
The config will go into exo_midi.erl which will get the notify.




Entry: pd live coding
Date: Sun Jul 16 07:09:11 PM CEST 2023

Basically the sp idea from rai, but then done by double buffering
dlopen.



Entry: basic setup
Date: Wed Aug  2 10:19:33 AM CEST 2023

I want:
- jack running
- pd running, connected to jack
- midi forwarder into pd
- individual jack clients

I want this to be one command that runs from dev.erl

So, to start:
1. exo_vm  # on terminal on any machine.
2. exo:load_dev(). %% Erlang
3. dev:audio().    %% Erlang


Roadblocks:

- make vs. redo.  I want this to be trivially the same.  See if the
  uc_tools build still works for synth_tools?



Entry: continue
Date: Thu Aug  3 11:39:30 AM CEST 2023

The synth_tools redo build is working.

Next: start softsynth process, connect it.  Write the whole thing as a
build script.

EDIT: Had to fix some more things to use nixos build tools.
See /etc/net/nixos/pkgs/exo-dev


next:

- start processor
- connect to i/o ports


Entry: synthfest
Date: Fri Aug  4 08:01:00 PM CEST 2023

- start processors, hook to i/o ports
- pd midi or osc (separate client?)
- check pd patches + fix compilation issues


Entry: pd patches
Date: Fri Aug  4 08:30:24 PM CEST 2023

./abstractions/compat/ad~.pd

I need to add thi to the abs path.
Oh I see.  Was just missing.



Entry: pd patches
Date: Fri Aug  4 08:47:46 PM CEST 2023

granulardynwav.pd
logistics_part4.pd
IPEM2002/agc2.pd
3toneharmonicdoublechaos.pd



Entry: connections
Date: Sat Aug  5 08:43:29 AM CEST 2023

Currently exo_midi.erl contains connectivity information.

Can this be encoded in the build system or should I not worry about it?
Can I do it gradually?  I.e. make it work first, then see?

Alright first I need a proxy daemon.
There was already the rai daemon so let's use that.

EDIT: Maybe just abandon this connectivity idea.  It clearly needs a
lot more thought.  Make a midi to netsend client first.

Yeah take the whole erlang thing out of the picture for now.  This
really is for later.


Entry: netsend
Date: Sat Aug  5 10:15:57 AM CEST 2023

Too stupid to get UDP to work.
So do TCP instead.


Entry: names are not stable?
Date: Sat Aug  5 02:17:33 PM CEST 2023

                "jack_netsend:midi_in_0" ->
                    From("in-hw-1-0-0-UMA25S-MIDI-1");
                "jack_netsend:midi_in_1" ->
                    From("in-hw-1-0-0-UMA25S-MIDI-1");


I need a live system to see what this does.

in-hw-1-0-0-FL-STUDIO-FIRE-MIDI-1

So I was able to connect it, but this needs abstraction.


Entry: drum machine
Date: Sat Aug  5 02:51:56 PM CEST 2023

So I have knobs.
What to do with those knobs?

This is not something I can do right away.

Also I really want to split this up in 2 parts: specification and code
generation.  I.e. something using constraints, which then generalizes
or "directionalizes" the event handling code.

Let's start with classical drum machine

Three things are needed:
- input: key toggles drum in pattern data structure
- display: each state change results in update message
- playback: each drum tick updates previous and current colors

It's clear that initially, updates are 1-1: every input results in a single update.

Later this will be different.  So I will likely be writing some kind
of "react" for this.

I want to build this together with a web interface.
Or at least as something that easily translates to web.
Probably will require webassembly.

Anyway.  Stick to a simple representation.


Entry: single voice drum patterns?
Date: Sat Aug  5 03:29:01 PM CEST 2023

Going to do something different.  Use the colors on the FT to indicate
instruments.  Tho this is difficult for simultaneous hits.  Maybe
simultaneous hits could be different instruments?  Which they are,
somehow.  That then also maps to "single voice drums" I wanted to do
with the noise sample inputs.



Entry: next
Date: Mon Aug  7 11:28:42 AM CEST 2023

- i want something playable, not just programmable
- focus on cleaning up, integrating what is already there



Entry: jack daemon onward
Date: Mon Aug  7 03:31:49 PM CEST 2023

Question: does jack daemon know the jack port name or number based on
the annotated name?  I think this is what needs to be recorded.  Find
the point where this information is known.

Aug 07 15:36:47 tp exo_vm[400785]: scan: added port hw:3,0,0 in-hw-3-0-0-FastTrack-Pro-MIDI-1
Aug 07 15:36:47 tp exo_vm[400785]: scan: added port hw:3,0,0 out-hw-3-0-0-FastTrack-Pro-MIDI-1
Aug 07 15:36:47 tp exo_vm[400785]: scan: opened port hw:1,0,0 in-hw-1-0-0-UMA25S-MIDI-1
Aug 07 15:36:47 tp exo_vm[400785]: scan: opened port hw:1,0,0 out-hw-1-0-0-UMA25S-MIDI-1
Aug 07 15:36:47 tp exo_vm[400785]: scan: opened port hw:3,0,0 in-hw-3-0-0-FastTrack-Pro-MIDI-1
Aug 07 15:36:47 tp exo_vm[400785]: scan: opened port hw:3,0,0 out-hw-3-0-0-FastTrack-Pro-MIDI-1


Who keeps track of what?
It got messy.

This is what is there now for daemon and control processes.
Stuff is saved in the maps but not retreived so that is odd.
And there's some missing information as well.

(exo@tp.zoo)16> obj:dump(exo:pid(jack_daemon)).
obj:dump(exo:pid(jack_daemon)).
#{audio => <0.7273.0>,control => <0.7271.0>,
  hubs => fun exo:need_hubs/1,midi => <0.7272.0>,
  notify => fun exo_midi:jack_notify/1,port => #Port<0.138>,
  {in,0} => <<"in-hw-3-0-0-FastTrack-Pro-MIDI-1">>,
  {in,22} => <<"in-hw-1-0-0-UMA25S-MIDI-1">>,
  {out,0} => <<"out-hw-3-0-0-FastTrack-Pro-MIDI-1">>,
  {out,22} => <<"out-hw-1-0-0-UMA25S-MIDI-1">>}


(exo@tp.zoo)19> obj:dump(maps:get(control, obj:dump(exo:pid(jack_daemon)))).
obj:dump(maps:get(control, obj:dump(exo:pid(jack_daemon)))).
#{{<<"studio_midi">>,<<"midi_in_17">>} => true,
  {<<"studio_midi">>,<<"midi_out_23">>} => true,
  {<<"studio_midi">>,<<"midi_in_11">>} => true,
  {<<"studio_midi">>,<<"midi_out_20">>} => true,
  {<<"studio_midi">>,<<"midi_out_18">>} => true,
  port => #Port<0.139>,
  open_port =>
      [{spawn,"/nix/store/zm9k3lp3a6dwlcdbgdqqhvsl36dafnd7-studio-0.0.1/lib/erlang/lib/studio-0.0.1/priv/studio.elf jack_control studio_control"},
       [{packet,1},binary,exit_status]],
  {<<"studio_midi">>,<<"midi_out_17">>} => true,
  {<<"studio_midi">>,<<"midi_out_10">>} => true,
  {<<"studio_midi">>,<<"midi_out_21">>} => true,
  {<<"studio_audio">>,<<"audio_in_5">>} => true,
  {<<"studio_midi">>,<<"midi_out_12">>} => true,
  {<<"studio_audio">>,<<"audio_in_7">>} => true,
  {<<"studio_midi">>,<<"midi_in_4">>} => true,
  {<<"studio_midi">>,<<"midi_in_22">>} => true,
  {<<"studio_midi">>,<<"midi_in_8">>} => true,
  {<<"studio_midi">>,<<"midi_in_10">>} => true,
  {<<"studio_midi">>,<<"midi_in_5">>} => true,
  {<<"studio_midi">>,<<"midi_out_16">>} => true,
  {<<"studio_midi">>,<<"midi_out_19">>} => true,
  {<<"studio_audio">>,<<"audio_in_0">>} => true,
  {<<"studio_midi">>,<<"midi_in_0">>} => true,
  {<<"studio_midi">>,<<"midi_in_12">>} => true,
  {<<"studio_midi">>,<<"midi_out_14">>} => true,
  {<<"studio_midi">>,<<"midi_out_22">>} => true,
  {<<"studio_midi">>,<<"midi_in_18">>} => true,
  {<<"studio_midi">>,<<"midi_in_20">>} => true,
  {<<"studio_midi">>,<<"midi_out_1">>} => true,
  {<<"studio_midi">>,<<"midi_in_15">>} => true,...}


Let's not change anything.  Only add, get it to work, then remove old stuff.

The notify handler I have runs where?

As part of jack_control.


I'm having a hard time to split the two things:
- native jack ports and how to manage native jack connections
- the jack_midi process and jack_control mapping


I want to understand how this works and I first need to understand
what data it keeps.

The jack_daemon state is there to implement RPC call
jack_daemon:system_port() which is called by jack_control:portname()

So the information is there already: the canonical way to refer to
midi controllers is to use the port index on the jack_midi task.

  {in,0} => <<"in-hw-3-0-0-FastTrack-Pro-MIDI-1">>,
  {in,22} => <<"in-hw-1-0-0-UMA25S-MIDI-1">>,
  {out,0} => <<"out-hw-3-0-0-FastTrack-Pro-MIDI-1">>,
  {out,22} => <<"out-hw-1-0-0-UMA25S-MIDI-1">>}

EDIT: Ok got something working.

Is it time to review the spec language?

I mean, the goal was to have something for synthfest.  Next goal is to
have something playable but also to solve all the config issues.

Maybe it is time for types.
Maybe this needs a Haskell spec language.



Entry: next?
Date: Mon Aug  7 04:55:45 PM CEST 2023

Maybe first make auto-reload on rebuild work.
Also set up rebuild via emacs f5

What is needed?

The jack client process needs to be started by erlang.

Beyond that, I think sending a reload notification is probably enough.
I.e. I want to update the running state after recompile, but this
should be best-effort.

What this needs is mostly the emacs keybinding to start a redo build.
Maybe that can be f6.

Do I have a way to go from terminal to redo?

Jeez I'm too tired for this...



Entry: jack ports
Date: Wed Aug  9 09:22:50 AM CEST 2023

Next step: software client ports should also connect to jack_midi.

I don't especially like the studio_midi idea.  Too many unused ports.

What are the constraints and design decisions?

- a client like studio_midi is necessary to have a connection to the
  jack network.  the jack_daemon Erlang process is not connected!  it
  only observes the jackd process and its stdout

- the jack_control daemon is separate to allow flow control and return
  values

- the jack_midi daemon is only for unidirectional midi interfacting
  to/from erlang.  this needs one port per jack port.

- the jack_audio is the same as jack_midi, but for audio, and not yet
  implemented.  should probably be unified with jack_midi.  can be
  ignored.

- the jack_midi contains midi clock distribution


What is missing or not right?

- There are many unused ports.  Is that a real problem though?
- Software client midi port need to be treated as system ports



Entry: refactoring jack_midi
Date: Wed Aug  9 09:44:23 AM CEST 2023

What about this:

midi_out_0 is the midi clock, so could be named as such

each additional port is dedicated to send/receive to a system port or
some jack client.

pd doesn't support jack midi


the midiclock thing could really be a seprate client, because the only
reason that studio_midi needs to be centralized is because it is the
interface to erlang.

roadmap should include something that relies on timing messages

so what is my test?

- some drum machine that relies on timing messages
- an erlang to midi path, e.g. emacs key?
- a midi to erlang path, e.g. emacs knob display?

what is the end goal here?

to make things clear such that in a qjackctl graph it looks clear

the things that create clutter are the studio_audio and studio_midi


can i do it without changes? how important is it to not get lost in
the weeds again?

make small changes.


EDIT: removed the audio daemon.
man this is hard to restart/reload...


Can I split off studio sync client?

Yeah this is too complex.

Let's keep it the way it is but fix it at the level of pord
identifiers.  Add an additional level of indirection maybe?

The studio_midi keeps track of a mapping from port id to internal port
name, which could just be the id, and creates it if needed.

EDIT: I don't want to bathe in this confusion.  It is really too
complicated.  For YEARS I've been messing with this...

Ok here's an idea: stick to the current idea but make all ports lazy.

EDIT: Can't do this without breaking everything.  It's a lot of work.


So damn what do I do?
Keep everything as it is and add software ports to the config.



Entry: software ports
Date: Wed Aug  9 10:50:19 AM CEST 2023

Maybe it's best not to proliferate these midi ports.
But otoh that is exactly what I would like to do.

One advantage of treating hardware and software ports the same is that
it's possible to create some solidity.

No.  Let's proliferate.  It is actually a good abstraction mechanism;
a good guide towards making things that are standard.

What needs to disappear is the jack_midi daemon, to be replaced with:

- separate sync client + sequencer
- separate on-demand erlang bridge

Roadmap:

1. build separate sync and sequencer clients
2. make jack_midi use dynamic ports


Is this necessary?
I think it is because of all the confusion it causes.

It's not that hard to make it work.  It is hard to do the incremental
development and test though, so maybe fix that first?

So smaller step:
- disable the sync
- create a synth_tools sync master

I think it might make sense to let all the studio code depend on
synth_tools, then there can be more built in C.

Ok so move the sync and sequencer into separate clients.

And for the stdio protocol: use midi.

Then make it so that the jack_daemon can start the jack clients.



Entry: starting jack clients
Date: Wed Aug  9 11:21:11 AM CEST 2023

When jack_daemon starts, I want it to start and connect jack clients.
Let's assume there are a lot of these.

Basically I want some kind of network monitor.

This could actually be part of studio.erl

What do I want?

I just want the studio project to have access to default versions of
the jack clients.  So it might be simplest to copy whatever is needed.




Entry: summary
Date: Wed Aug  9 01:38:36 PM CEST 2023


EDIT: Alright I got here:

- synth_tools is now part of /etc/net nixos wrappers, and studio can
  access it

- jack daemon starts erlang wrapper for synth_tools jack clients, by
  default using the /nix/store binaires



TODO:

- add method to reload from a different directory



Entry: connectivity
Date: Wed Aug  9 02:57:01 PM CEST 2023

Alright so the next bit is the connectivity.
I think this isn't much else than reviving the patch thing.
But should it go through redo?

I don't think so.  It's better to look at the patch as something
different: it is a graph of its own, but it is possible to identify
subgraphs and restart them.  That's really all I need:

1. specify the full graph
2. restart parts of it

A part of a graph could be a single C program with connectivity
implemented as C data dependencies.

So, graphs and subgraphs.

What about not implementing that part in Erlang?  It might be useful
outside as well.

Otoh, the backbone glue will be in Erlang so maybe best to implement
the graph handling there as well?

So let's just continue with what is there.

But I think it might be good to not mix the run and build
config... But we'll see. Might be too naive.




The core thing is: restore connectivity after replacing a part.

This is something like:
- disconnect old, recording conenctions 
- kill old
- start new
- connect

The 'record connections' doesn't have to be a local operation.
Information could come from a map.


Entry: fire fl
Date: Wed Aug  9 05:23:04 PM CEST 2023

To get this going I don't need full integration.
Would be nice to also test the midi clock stuff.


Entry: unstable midi names
Date: Wed Aug  9 07:01:35 PM CEST 2023

Aug 09 13:00:48 zora exo_vm[239258]: scan: added port hw:1,0,0 out-hw-1-0-0-FL-STUDIO-FIRE-Jack-1

WTF why is this -Jack-1 ?

So it seems this cannot be trusted....

https://askubuntu.com/questions/1153655/making-connections-in-jack-on-the-command-line


Ok they are different.  tp is running a different kernel

tom@zora:~$ cat /proc/version
Linux version 5.15.29 (nixbld@localhost) (gcc (GCC) 10.3.0, GNU ld (GNU Binutils) 2.35.2) #1-NixOS SMP Wed Mar 16 13:23:47 UTC 2022

root@tp:/etc/net/nixos/pkgs# cat /proc/version 
Linux version 5.4.182-rt71 (nixbld@localhost) (gcc version 10.3.0 (GCC)) #1-NixOS SMP PREEMPT_RT Wed Mar 2 10:41:18 UTC 2022

Must be that because devices are the same.

Aug 09 13:00:48 zora exo_vm[239258]: jackdmp 1.9.19

Aug 09 17:17:25 tp exo_vm[596586]: jackdmp 1.9.19

I don't want to mess with tp so make zora the same.
zora didn't have:

  boot.kernelPackages = pkgs.linuxPackages-rt;

Also explains the underruns.

EDIT: zora rt kernel fixed it



Entry: next
Date: Thu Aug 10 09:54:59 AM CEST 2023

The dataflow language.
First find out why this was done as a redo rule.

First it needs:

        exo_patch            -> {epid_app, start_link, [#{}]};

The exo_patch.erl seems to be a dummy.

I can't reconstruct anything from comments.

What is coming back: the tension between the two dags, where the redo
dag is specified using patterns, and the epid_app through application.

Current ill-informed intuition: redo is more general, so implement
epid_app in terms of redo, which seems to be the case.


A running example is always best.  So let's make sure the epid dag is
always running on each node, and later maybe on the network as a
whole.



Is there something to say _before_ getting into this?  One is to make
sure the DSL can be ported outside of Erlang.  But no, that doesn't
make any sense since the epid mechanism is built from Erlang wrapper
processes.

I guess what I miss is a starting point, so continue reading.

Move to exo.txt


So with the do_patch thing working somewhat, how to use this to store
jack connections?

The actual problem isn't solved: i.e. I want to automatically connect
when a port appears in the jack daemon.

Plugging that into redo might be overkill?
Also creates brittle code.  What if it fails?




Entry: bypass epid_app
Date: Thu Aug 10 07:50:05 PM CEST 2023

It's simpler to use redo and manage a connection as a node that
depends on two other nodes.  This way a bunch of connections can be
managed at once.

An advantage of this is that the build system can always run on the
same machine, but the connected state is "cached".


Entry: synchronous start of a jack client
Date: Thu Aug 10 08:04:13 PM CEST 2023

Basically, wait for all its i/o to be created.

Can I use this directly?

exo_midi:jack_notify({port,true,"system:midi_playback_3"})

Not really, because redo is pull.

I need a wrapper.  Something that implements jack client restart and
waits for all ports to appear, with a 3 second timeout.

Here's what the notifications look like when starting a client:

exo_midi:jack_notify({client,true,"jack_synth-01"})
exo_midi:jack_notify({port,true,"jack_synth-01:midi_in_0"})
exo_midi:jack_notify({port,true,"jack_synth-01:audio_out_0"})

It might be enough to:

1. subscribe to all messages with a unique tag.
2. Wait for these 3 messages
3. unsubscribe
4. flush


The list is easy to generate.  Don't even have to parse.  Can just
generate.

Added some proto code to jack_control.erl

EDIT: Probably easier to send something on task stdio.


Entry: looper
Date: Thu Aug 10 10:12:01 PM CEST 2023

https://www.youtube.com/watch?v=ypuP18k3wGM



Entry: jack daemon restart
Date: Sun Aug 13 12:48:11 PM CEST 2023

I really need a solution for this, so build something today.
EDIT: Didn't get to it.



Entry: next
Date: Mon Aug 14 07:57:20 AM CEST 2023

Maybe instead of building the akai fire interface separately, start
building something that produces sound right away.  Start doing the
looper, which boils down to making a sampler first.

Maybe it is also time to start doing some rust?  Problem is that I got
good enough at C that I don't really need this for simple code (not
many forking paths).




Entry: sampler
Date: Wed Aug 23 11:43:05 PM CEST 2023

start with recording of noise setup, turn it into a shuffler



Entry: Layla3G analog + digital config?
Date: Fri Aug 25 02:10:26 PM EDT 2023

Can I actually run 8 analog and 8 digital at the same time?

I think when reading the driver that it had a comment that this
wouldn't work.

/linux/sound/pci/echoaudio

Maybe this is a good occasion to start messing with the Linux kernel
again.

I think it was this:

        /* The card can manage substreams formed by analog and digital channels
        at the same time, but I prefer to keep analog and digital channels
        separated, because that mixed thing is confusing and useless. So we
        register two PCM devices: */

There is also this:

        /* This card has a Vmixer, that is there is no direct mapping from PCM
        streams to physical outputs. The user can mix the streams as he wishes
        via control interface and it's possible to send any stream to any
        output, thus it makes no sense to keep analog and digital outputs
        separated */

git blame echoaudio.c
dd7b254d8dd3a (Giuliano Pochini     2006-06-28 13:53:41 +0200  950) 

Copyright (C) 2003-2004 Giuliano Pochini <pochini@shiny.it>
Copyright (C) 2020 Mark Hills <mark@xwax.org>

on mimas, asound/cards reports "Layla3G". That string is in
echo3g_dsp.c which is included from echo3g.c:

#include "echo3g_dsp.c"
#include "echoaudio_dsp.c"
#include "echoaudio_3g.c"
#include "echoaudio.c"
#include "midi.c"

It doesn't seem to have ECHOCARD_HAS_VMIXER

So it creates two PCM devices

	/* PCM#0 Analog i/o */
	err = snd_pcm_new(chip->card, "Analog PCM", 0,
			  num_analog_busses_out(chip),
			  num_analog_busses_in(chip), &pcm);

	/* PCM#1 Digital i/o */
	err = snd_pcm_new(chip->card, "Digital PCM", 1,
			  num_digital_busses_out(chip),
			  num_digital_busses_in(chip), &pcm);


tom@mimas:~$ cat /proc/asound/card0/pcm0p/info 
card: 0
device: 0
subdevice: 0
stream: PLAYBACK
id: Analog PCM
name: Layla3G
subname: subdevice #0
class: 0
subclass: 0
subdevices_count: 8
subdevices_avail: 7

(7 is because jack is already running)

tom@mimas:~$ cat /proc/asound/card0/pcm1p/info 
card: 0
device: 1
subdevice: 0
stream: PLAYBACK
id: Digital PCM
name: Layla3G
subname: subdevice #0
class: 0
subclass: 0
subdevices_count: 8
subdevices_avail: 8


So it looks like I'm going to need to either mod the driver, or open
it twice, once with the jack alsa client.  That might be the way to go
because I think I'm going to have to do that again when using multiple
cards:

https://jackaudio.org/faq/multiple_devices.html


https://linuxmusicians.com/viewtopic.php?t=16062
mentions "jack2 audioadapters"

something like this:
https://forum.mod.audio/t/whats-the-best-implementation-for-multiple-usb-interfaces/4656/7
jack_load mod-slave audioadapter -w -a -i "-d hw:1 -p 128 -n 3"

https://www.youtube.com/watch?v=yrcJuBPQ1uY
jack_load <myname> audioadapter -i "-d hw:3 -g406 -i1 -o1 -r48000"

also possible with alsa loopback
https://sysplay.in/blog/linux/2019/06/playing-with-alsa-loopback-devices/


so two things to remember:
- on jack2, jack_load can be used to add an "audioadapter"
- jack_load sets up internal clients (netjack is another one?)
- alsa loopback can be used to plug one app that uses also into jack that way


Entry: jack2 audioadapter (jack_load)
Date: Fri Aug 25 02:56:55 PM EDT 2023

some questions:

- jack, jackdmp, jack2?
- jack_load?

JACK2 aka jackdmp is a C++ version of the JACK low-latency audio
server for multi-processor machines.

tom@luna:~$ readlink -f `which jack_load`
/nix/store/0rxaxxfv5jsqfd7h0qab5s374px756zs-jack2-1.9.19/bin/jack_load

i guess i need the source code somewhere
https://github.com/jackaudio/jack2

man jack_load:
jack_load - JACK toolkit client for loading in-process clients


there is also netjack

i guess i jave some manual reading to do

also see this:
https://github.com/jackaudio/jack-example-tools


Entry: netjack
Date: Fri Aug 25 04:14:26 PM EDT 2023

https://linuxmusicians.com/viewtopic.php?t=1010


Entry: openmixer
Date: Fri Aug 25 04:14:45 PM EDT 2023

https://github.com/Openmixer


Entry: jackpatch, nsmd
Date: Sun Aug 27 05:47:22 AM EDT 2023

https://jackaudio.org/news/



Entry: next
Date: Tue Aug 29 06:42:09 AM EDT 2023

alsa loopback to send pulseaudio to jack on luna


Entry: alsa loopback
Date: Tue Aug 29 06:44:30 AM EDT 2023

modprobe snd-aloop

interesting hint: "aplay -l" can be used to list cards

tom@luna:~$ jack_load pulse audioadapter -i "-d hw:3 -i2 -o2 -r48000"
audioadapter is running.
client name = pulse


now it doesn't show up in pulseaudio
actually it does, it's just not called loopback


alright this is just not transparent enough

probably better to get rid of pulseaudio, or to compile it with jack support

i am spending way too much time on this

hey what if the nixos is not including the jack and alsa loopback
stuff during nix rebuild?

ok i found this:
https://nixos.wiki/wiki/JACK

    hardware.pulseaudio.package = pkgs.pulseaudio.override { jackaudioSupport = true; };

That rebuilds pulse.  So prob good to do it on zoo so it can be cached.

It does need some massaging afterwards.  Basically, read the docs.

First start jack, then do:

pactl load-module module-jack-sink channels=2
pactl load-module module-jack-source channels=2
pacmd set-default-sink jack_out



Ok that works.

So what it needs to do:
- start jack daemon in exo_vm
- run the pactl commands after daemon has started

So the latter should go into Erlang code


Entry: o1v digitial io
Date: Tue Aug 29 01:09:48 PM EDT 2023

cable arrives today
try the audioadapter thing


Entry: digital optical cables arrived
Date: Wed Aug 30 06:31:16 AM EDT 2023


root@mimas:/home/tom# cat /etc/net/dsp/jack-mimas.sh 

#!/bin/sh
export DISPLAY=:0
P=64
exec jackd -R -dalsa -r48000 -p$P -n2 -d hw:Layla3G,0 -X raw -i 8 -o 8 "$@"



jack_load o1v audioadapter -i "-d hw:0,1 -i8 -o8 -r48000"

it hangs



findings:

- if echo is master 48kz and o1v syncs to it, the o1v -> echo digi
  path is flakey. this goes away when echo syncs to o1v. however o1v
  can only do 44.1 internal

- this problem goes away when echo is set to 44.1


so do i just lower the sample frequency to 44.1, or do i find another
sync setup?  it will need to be synced to zni anyway.


anyways. will need to think about it. set some goal first.

one more thing to check: run analog i/o as well



Entry: general setup
Date: Wed Aug 30 07:40:35 AM EDT 2023

1. neerpelt / brunswick setups should be +- the same

2. things need to start automatically at power on


For both, the 16-channel setup is for "hacking".  Basically, that's
where things can be added in the future.

In brunswick, the delta1010 is for the analog synths.







Entry: digi and analog
Date: Wed Aug 30 07:57:34 AM EDT 2023

jack_load o1v audioadapter -i "-d hw:0,0 -i8 -o8 -r44100"
audioadapter is running.
client name = o1v

but jack output does this:
Ringbuffer automatic adaptative mode size = 4096 frames
Audio Interface Description :
Sampling Frequency : 44100, Sample Format : S32_LE, buffering : 1024, nperiod : 2
Software inputs :  8, Software outputs :  8
Hardware inputs :  8, Hardware outputs :  8
ALSA lib conf.c:5514:(parse_args) Unknown parameter 1
ALSA lib conf.c:5685:(snd_config_expand) Parse arguments error: No such file or directory
ALSA lib control.c:1599:(snd_ctl_open_noupdate) Invalid CTL hw:0,0
ALSA lib conf.c:5514:(parse_args) Unknown parameter 1
ALSA lib conf.c:5685:(snd_config_expand) Parse arguments error: No such file or directory
ALSA lib control.c:1599:(snd_ctl_open_noupdate) Invalid CTL hw:0,0
ALSA lib conf.c:5514:(parse_args) Unknown parameter 1
ALSA lib conf.c:5685:(snd_config_expand) Parse arguments error: No such file or directory
ALSA lib control.c:1599:(snd_ctl_open_noupdate) Invalid CTL hw:0,0
../linux/alsa/JackAlsaAdapter.h:551, alsa error -2 : No such file or directory
ALSA lib conf.c:5514:(parse_args) Unknown parameter 1
ALSA lib conf.c:5685:(snd_config_expand) Parse arguments error: No such file or directory
ALSA lib control.c:1599:(snd_ctl_open_noupdate) Invalid CTL hw:0,0


It does seem to appear though.  How to test?
It seems fine from vu meters in echomixer and pd.



Entry: autostart
Date: Wed Aug 30 08:02:17 AM EDT 2023

So make sure this works at boot.

This works:
jack_load system_analog audioadapter -i "-d hw:0,0 -i8 -o8 -r44100"



Entry: zoe delta1010
Date: Wed Aug 30 08:15:03 AM EDT 2023

Currently set to internal 44.1 in envy24control
But that doesn't seem right because jack is running at 48kHz

Next experiment: can i sync envy to zoe delta1010 word clock? That
worked before so should be fine.

The echo digi in doesn't work in that mode: getting glitches in echomixer

Let's switch zoe delta1010 to 44.1k then

Ok that works.

zoo then still syncs to zoe.  not checked if it has audio but prob ok

so looks like this is all good



Entry: jack tools
Date: Wed Aug 30 10:41:15 AM EDT 2023

collection of jack tools and built-in clients in the repo

https://github.com/jackaudio/jack2

Internal clients are in .so ?
https://github.com/jackaudio/jack2/blob/develop/common/JackInternalClient.cpp

https://github.com/jackaudio/jack2/blob/develop/common/netjack.c

https://github.com/jackaudio/jack2/blob/develop/linux/alsa/ice1712.c
ice1712_hw_monitor_toggle()
ice1712_set_input_monitor_mask()

https://github.com/jackaudio/jack2/blob/develop/linux/alsa/hammerfall.c
sync, monitor

so where is audioadapter?
https://github.com/jackaudio/jack2/blob/develop/linux/alsa/JackAlsaAdapter.cpp

is there a way to list internal clients?
root@luna:/nix/store/0rxaxxfv5jsqfd7h0qab5s374px756zs-jack2-1.9.19# find -name '*.so'
./lib/libjack.so
./lib/libjacknet.so
./lib/jack/jack_alsa.so
./lib/jack/jack_firewire.so
./lib/jack/jack_netone.so
./lib/jack/jack_alsarawmidi.so
./lib/jack/jack_net.so
./lib/jack/netmanager.so
./lib/jack/jack_dummy.so
./lib/jack/jack_proxy.so
./lib/jack/jack_loopback.so
./lib/jack/inprocess.so
./lib/jack/netadapter.so
./lib/jack/profiler.so
./lib/jack/audioadapter.so
./lib/libjackserver.so

Aha, jackd --help gives:

Available internals:
      netmanager
      netadapter
      profiler
      audioadapter

Available backends:
      alsa (master)
      firewire (master)
      netone (master)
      alsarawmidi (slave)
      net (master)
      dummy (master)
      proxy (master)
      loopback (slave)

what is netone?

also, is raw the sqame as alsarawmidi?

reading man jackd i find the 'jalv' internal LV2 plugin host client:
https://libreav.org/software/jalv




Entry: netadapter
Date: Wed Aug 30 11:21:33 AM EDT 2023

https://jack-devel.jackaudio.narkive.com/XP3eXD7t/how-to-setup-jack-for-transmission-of-audio-from-embedded-system-to-jack-equipped-audio-workstation

slave:

jack_load netadapter -i '-C 4'

master:

jack_load netmanager



what about --slave-backend ? 

wait this is X.  maybe -X raw is already a slave backend and i can run
jack in midi only mode?


Entry: alsa -Xraw
Date: Wed Aug 30 02:13:00 PM EDT 2023

https://linux-audio-user.linuxaudio.narkive.com/r88hTnOx/lau-is-xalsarawidi-the-same-as-xraw-or-xseq

Capela: when on JACK2, use a2jmidid -e; forget -Xwhatever; you've been
warned, probably way too many times ;)...

Davis: Just a note. You should NEVER use ALSA raw MIDI with JACK
unless you don't care about timing in any way.



I never had any issues.  But let's do what they say.  Might make
things simpler in the end because it does seem this uses a simpler
port naming scheme.

Not for right away, but instead of making some other overhaul.


https://github.com/jackaudio/a2jmidid

nix-shell -p a2jmidid

tom@luna:~$ 
jack_connect \
'a2j:WORLDE easy control [28] (capture): WORLDE easy control MIDI 1' \
'a2j:WORLDE easy control [28] (playback): WORLDE easy control MIDI 1' \

So I probably still need to do some name mangling because that is too
much to do manually.  Also I doubt that the 28 is going to be stable.

tom@luna:~$ jack_lsp
system:capture_1
system:capture_2
system:playback_1
system:playback_2
PulseAudio JACK Sink:front-left
PulseAudio JACK Sink:front-right
PulseAudio JACK Source:front-left
PulseAudio JACK Source:front-right
a2j:Midi Through [14] (capture): Midi Through Port-0
a2j:Midi Through [14] (playback): Midi Through Port-0
a2j:WORLDE easy control [28] (capture): WORLDE easy control MIDI 1
a2j:WORLDE easy control [28] (playback): WORLDE easy control MIDI 1


Entry: new arch
Date: Wed Aug 30 04:32:01 PM EDT 2023

I think I want to get rid of this erlang thing.  It's too complex to
set up.  I also want to be able to run jack without erlang.



Entry: jack without erlang
Date: Thu Aug 31 09:02:31 AM EDT 2023

First make an experiment.  Set up jack on a couple of machines with
the a2jmidid and netjack.  Keep it in Erlang for now (don't break
things) but gradually move more to C so it can run stand-alone.

So what's next?

The jack network thing.



Entry: jack: make it visible
Date: Fri Sep  1 10:36:00 AM EDT 2023

Configuration is still a realy issue.  And that is because I want to
keep things open too much.

Debugging is an issue as well: not always clear if things are set up
properly, and that is also tied into the configuration being a mess.



Entry: moving forward
Date: Sat Sep  2 06:52:37 AM EDT 2023

i'm a bit stuck.

one thing is the recent discovery of the other jack clients which
basically means i have to redo things

so let's just explore it then by building an actual setup.  i want to
get close to something i had before: a step sequencer, and a number of
synths connected through a mixer.

first thing to try here is to set up the drum sync.  i think i tried
this last month, remove it from the erlang client into a new client.

i moved the drum stuff to synth_tools/linux/jack_clock.c

so todo:
- disable -X raw on zoe jackd
- add new a2j client
- connect manually, test beat timing
- automate the connection


Alright, manual connection jack_clock -> korg drum machine works
qjackctl also looks a lot more manageable

It shows up on the a2jmidid stdout:

port created: USB Midi 4i4o [20] (playback): USB Midi 4i4o MIDI 3

But I should see this inside jack as well.

Problem right now is that those messages are getting lost, since I
changed it to "send to emacs".  Maybe as an intermediate step, send it
to disk or network broadcast as well.

Or maybe simpler: allow Erlang console to register.

Or even simpler: send to emacs over network via tp proxy.

See exo log.

Alright now the clients are not starting.

Maybe it is time to just redesign this whole thing.



Entry: midi studio client
Date: Sat Sep  2 08:51:34 AM EDT 2023

That should probably be replaced by a single erlang client that only
does erlang to midi bridging, and can also create ports and
connections on demand.

So let's set it up so that the a2jmidid is started from erlang as well.

Alright it's up

next: remove the jack_midi daemon at start?


Entry: remove jack_midi daemon
Date: Sat Sep  2 10:05:09 AM EDT 2023

Let's just not start this any more, see how it goes.

Let's recreate the erlang interface right away.  synth_tools jack_erl

EDIT: What needs to happen first is daemon restart.



Entry: adhd intermezzo
Date: Sat Sep  2 11:04:42 AM EDT 2023

Field bus for audio, sample switched.

Basically a single daisychain cable, where each device has a slot.
Tight microcontroller timing, uart interface.

A single channel is (* 2 10 44100)  882 kbps

10Mbit is probably doable with RS485

(/ 10000 882.0)

That's only 11 channels.

This doesn't look like a good idea.
Best way seems to be to use legacy audio cards.

So forget



Entry: use o1v + echo as pd + analog interface
Date: Sat Sep  2 11:09:10 AM EDT 2023

That's a huge amount of bandwith.  Not going to fill that up any time
soon.

Get rid of the hyperion / m-audio setup.  The idea was to have a
portable setup.  That's not going to work with the feedback setup, so
build a separate portable setup in a suitcase.



Entry: portable setup
Date: Sat Sep  2 11:11:24 AM EDT 2023

M-Audio + behringer mixer.

M-Audio is effects processor fed from behringer's send and an extra
direct input.

Behringer USB is recorder output.

Adding hyperion would make it stand-alone.  It needs power anyway.



Entry: i need to get somewhere, find some place to start
Date: Wed Sep  6 06:54:26 AM EDT 2023

Yeah there's nothing.

Was looking at qjackctl patchbay again.  I think I don't want to use
this.  I want to definitely manage jack connections globally, together
with other daemon interactions on different PCs.

So maybe just acknowledge that this is harder than it seems, and wait
until my mental state is better to tackle it?

Until then I can do manual connections, or use the point that's
already there.

Also, connections are relations, so maybe best to put it in a database
after all.

This is what it looks like:

host,src_client,src_port,dst_client,dst_port

I first need to know what the number is in:

a2j:WORLDE easy control [28] (playback): WORLDE easy control MIDI 1



Entry: a2jmidid
Date: Wed Sep  6 07:34:26 AM EDT 2023

Port names like this:

a2j:WORLDE easy control [28] (playback): WORLDE easy control MIDI 1

Come from: a2jmidid/port.c

  if (make_unique)
  {
    ret = snprintf(
      port_ptr->name,
      g_max_jack_port_name_size,
      "%s [%d] (%s): [%d] %s",
      snd_seq_client_info_get_name(client_info_ptr),
      snd_seq_client_info_get_client(client_info_ptr),
      type == A2J_PORT_CAPTURE ? "capture": "playback",
      snd_seq_port_info_get_port(port_info_ptr),
      snd_seq_port_info_get_name(port_info_ptr));
  }
  else
  {
    ret = snprintf(
      port_ptr->name,
      g_max_jack_port_name_size,
      "%s (%s): %s",
      snd_seq_client_info_get_name(client_info_ptr),
      type == A2J_PORT_CAPTURE ? "capture": "playback",
      snd_seq_port_info_get_name(port_info_ptr));
  }


So what is make_unique ?
It's called like this:

  a2j_port_fill_name(port, type, client_info_ptr, info, !g_disable_port_uniqueness);

In main():

      case 'u':
        g_disable_port_uniqueness = true;
        break;

So there is an option for this.
Glad I looked!

From the man page:

NOTES 

  ALSA does not guarantee client names to by unique. I.e. it is
  possible to have two apps that create two clients with same ALSA
  client name.  JACK however requires port names to be unique. To
  ensure this uniqueness, a2jmidid will add the unique numeric ALSA
  client ID to the JACK port name.  However this behaviour is known to
  be problematic when restoring connections using simplistic tools
  like aj-snapshot and jack_connect.  In order to make them work, the
  -u option can be used. This option will cause a2jmidid to omit the
  numeric ALSA Client ID from JACK port names.  In this mode, ALSA
  client name uniqueness must be guaranteed externally.


So a make_unique example is:
a2j:M Audio Delta 1010 [24] (playback): M Audio Delta 1010 MIDI

Without:
a2j:M Audio Delta 1010 (playback): M Audio Delta 1010 MIDI

Ok so keep that as the default.



Entry: persistent jack connections need to go into a database
Date: Wed Sep  6 07:52:47 AM EDT 2023

Let's make it so it can be snapshotted.  This makes it possible to use
qjackctl to set things up.

Adapted jack_lsp to this:

tom@zoe:/i/tom/exo/synth_tools/linux$ ./jack_snapshot.dynamic.host.elf
jack_synth,audio_out_0,system,playback_1
jack_synth,audio_out_0,system,playback_2
jack_clock,out,a2j,USB Midi 4i4o (playback): USB Midi 4i4o MIDI 3



Entry: next
Date: Wed Sep  6 08:50:51 AM EDT 2023

Ok that's a step in the right direction.

It should be wrapped in a database so it can be plugged into the event
code.  But that feels like not something for now maybe.



Entry: database
Date: Thu Sep  7 05:40:24 AM EDT 2023

The event we're responding to is new port creation (and maybe later
deletion).

So this means for each port, find the connections it is involved in.

There are two kinds here: involved as input or as output.

Database seems best to hold relations like this, and turn them into
functions mapping from the new port to the other ports it is connected
to.


The next question is how to implement it.  Use a stateful database, or
put everything in csv.

Let's keep it in csv first, see how that goes.  Most connections would
be permanent anyway, at least in the beginning.

Ok so the csv read is working, and I have the relevant select
statement as well.

So what next?

It is the design decision to use a database or not.

So let's short-circuit that: yes, use a database.  Each node has one.
Even if it is only to cache things that are discovered dynamically.

This needs to go into the /etc/net exo.erl

So currently there is exo:db_local().
Where is it stored?

EDIT: Got it

So how should it go from here?
qjackctl -> jack_snapshot -> csv -> db

How to do the last step?


Entry: I am really done with this mess
Date: Thu Sep  7 02:31:35 PM EDT 2023

Build a single client that does all filtering.



Entry: are connections code?
Date: Thu Sep  7 02:51:48 PM EDT 2023

Here's the reason to not put jack connections in redo: it's not
directional.

But no, that is not the way to look at it.  Already been here.  It's
fine whenever the connection depends on the 2 client ports.

But that road doesn't work well because it needs synchronization
between restart mechanism and redo, and that is a can of worms.

So is it ok to leave connections as being "not code" ?

Why am I even stuck on this?

Overanalyzing.

It might be enough to do the following: let restart depend on
connection db being up-to date, and rules being inserted into
connections db.  There are many ways around it probably.


Also, I am prematurely optimizing.  It's probably ok to attempt to
reconnect everything instead of filtering.  Anyway, let's stick to the
db because that will have topology data in a form that is easily
accessible.


Maybe it is time to cut this short and just do it.

What I want to do mostly is to put the .csv in /etc/net git and make
sure it gets imported when the exo_vm starts up.



Entry: just fucking do it
Date: Fri Sep  8 08:38:35 AM EDT 2023

Put together what works.  Make sure it is function, then later find a
way to optimize.

1. Dump to csv per host, store in /etc/net
2. Pick up that csv in the init script
3. Test result in erlang

(exo@deimos.zoo)3> sqlite3:sql(DB,[<<"select * from jack">>]).
[[[<<"system">>,<<"capture_1">>,
   <<"PulseAudio JACK Source">>,<<"front-left">>],
  [<<"system">>,<<"capture_2">>,<<"PulseAudio JACK Source">>,
   <<"front-right">>],
  [<<"PulseAudio JACK Sink">>,<<"front-left">>,<<"system">>,
   <<"playback_1">>],
  [<<"PulseAudio JACK Sink">>,<<"front-right">>,<<"system">>,
   <<"playback_2">>],
  [<<"src_client">>,<<"src_port">>,<<"dst_client">>,
   <<"dst_port">>],
  [<<"system">>,<<"capture_1">>,<<"PulseAudio JACK Source">>,
   <<"front-left">>],
  [<<"system">>,<<"capture_2">>,<<"PulseAudio JACK Source">>,
   <<"front-right">>],
  [<<"PulseAudio JACK Sink">>,<<"front-left">>,<<"system">>,
   <<"playback_1">>],
  [<<"PulseAudio JACK Sink">>,<<"front-right">>,<<"system">>,
   <<"playback_2">>]]]


Alright I got zoe to autoconnect



Entry: next
Date: Fri Sep  8 11:58:30 AM EDT 2023

Ok so time to start making permanent connections.

One thing is a dedicated midi processor for the whole studio.
Basically I do not really need to split machines up into separate jack
clients.  This can be pretty much arbitrary.

Only for things that are released this will be important.


Entry: bug
Date: Sat Sep  9 08:03:20 AM EDT 2023

I now have jack clients running twice: once started by jack_daemon,
and once as an exo client.

What I want to do is to make sure I can easily edit a client's code
and restart it.  This needs to be built into jack_daemon I think.

No what needs to happen is to bring this under exo control, and make
sure that all jack code refers to client code symbolically.

I want to just throw it all out, but no: keep it running.  Gradually
change it, throwing things out that are no longer needed, such as the
scan stuff.



so, roadmap:

1. remove old erlang and C code that is no longer needed in the
   current a2jmidid setup to simplify next steps

2. make jack_daemon clients part of exo processes so they can be
   easily restarted

3. restore epid using a new C client



So jack_midi.c is no longer needed.  I moved it to synth_tools/linux
Now move jack_control as well.

This means the whole c part can be removed from studio.


EDIT: Alright I'm getting notifications, it seems to be working.


Entry: debugging
Date: Sat Sep  9 09:34:18 AM EDT 2023

Why is it starting jack_clock twice?

exo@tp.zoo: child_mfa: jack_daemon
exo@tp.zoo: exo:start_child(jack_daemon): registeredsd
exo@tp.zoo: /etc/net/dsp/jack.sh: START=/etc/net/dsp/jack-tp.sh
exo@tp.zoo: no message buffer overruns
exo@tp.zoo: no message buffer overruns
exo@tp.zoo: no message buffer overruns
exo@tp.zoo: jackdmp 1.9.19
exo@tp.zoo: Copyright 2001-2005 Paul Davis and others.
exo@tp.zoo: Copyright 2004-2016 Grame.
exo@tp.zoo: Copyright 2016-2021 Filipe Coelho.
exo@tp.zoo: jackdmp comes with ABSOLUTELY NO WARRANTY
exo@tp.zoo: This is free software, and you are welcome to redistribute it
exo@tp.zoo: under certain conditions; see the file COPYING for details
exo@tp.zoo: JACK server starting in realtime mode with priority 10
exo@tp.zoo: self-connect-mode is "Don't restrict self connect requests"
exo@tp.zoo: creating alsa driver ... hw:PCH|hw:PCH|1024|3|44100|0|0|nomon|swmeter|-|32bit
exo@tp.zoo: configuring for 44100Hz, period = 1024 frames (23.2 ms), buffer = 3 periods
exo@tp.zoo: ALSA: final selected sample format for capture: 32bit integer little-endian
exo@tp.zoo: ALSA: use 3 periods for capture
exo@tp.zoo: ALSA: final selected sample format for playback: 32bit integer little-endian
exo@tp.zoo: ALSA: use 3 periods for playback
exo@tp.zoo: start: [{spawn,"/nix/store/mmwlrxnff07z2dqmgbkl744n271fgdxk-synth_tools/linux/jack_control.dynamic.host.elf jack_control"},
        [{packet,1},binary,exit_status]]
exo@tp.zoo: child_mfa: {jack_client,<<"jack_clock">>}
exo@tp.zoo: Cmd = "jack_clock.dynamic.host.elf"
exo@tp.zoo: child_mfa: {jack_client,<<"jack_erl">>}
exo@tp.zoo: Cmd = "jack_erl.dynamic.host.elf"
exo@tp.zoo: child_mfa: {jack_client,<<"jack_synth">>}
exo@tp.zoo: Cmd = "jack_synth.dynamic.host.elf"
exo@tp.zoo: CmdLine: /nix/store/mmwlrxnff07z2dqmgbkl744n271fgdxk-synth_tools/linux/jack_clock.dynamic.host.elf
exo@tp.zoo: CmdLine: /nix/store/mmwlrxnff07z2dqmgbkl744n271fgdxk-synth_tools/linux/jack_erl.dynamic.host.elf
exo@tp.zoo: CmdLine: /nix/store/mmwlrxnff07z2dqmgbkl744n271fgdxk-synth_tools/linux/jack_synth.dynamic.host.elf
exo@tp.zoo: exo_port: open_port({spawn,"/nix/store/mmwlrxnff07z2dqmgbkl744n271fgdxk-synth_tools/linux/jack_clock.dynamic.host.elf"},[use_stdio,binary,exit_status,{packet,4}])
exo@tp.zoo: exo_port: open_port({spawn,"/nix/store/mmwlrxnff07z2dqmgbkl744n271fgdxk-synth_tools/linux/jack_erl.dynamic.host.elf"},[use_stdio,binary,exit_status,{packet,4}])
exo@tp.zoo: exo_port: open_port({spawn,"/nix/store/mmwlrxnff07z2dqmgbkl744n271fgdxk-synth_tools/linux/jack_synth.dynamic.host.elf"},[use_stdio,binary,exit_status,{packet,4}])
exo@tp.zoo: JACK MIDI <-> ALSA sequencer MIDI bridge, version 9 built on Wed Dec 31 19:00:00 1969
exo@tp.zoo: Copyright 2006,2007 Dmitry S. Baikov
exo@tp.zoo: Copyright 2007,2008,2009,2011,2012 Nedko Arnaudov
exo@tp.zoo: 
exo@tp.zoo: Bridge starting...
exo@tp.zoo: Using JACK server 'default'
exo@tp.zoo: Hardware ports will be exported.
exo@tp.zoo: exo_midi:jack_notify({client,reg,"jack_clock"})
exo@tp.zoo: Connection failure: Connection refused
exo@tp.zoo: pa_context_connect() failed: Connection refused
exo@tp.zoo: Connection failure: Connection refused
exo@tp.zoo: pa_context_connect() failed: Connection refused
exo@tp.zoo: exo_midi:jack_notify({client,reg,"jack_clock-01"})
exo@tp.zoo: exo_midi:jack_notify({client,reg,"jack_synth"})
exo@tp.zoo: exo_midi:jack_notify({port,reg,in,"jack_clock:in"})
exo@tp.zoo: exo_midi:jack_notify({port,reg,out,"jack_clock:out"})
exo@tp.zoo: exo_midi:jack_notify({client,reg,"a2j"})
exo@tp.zoo: exo_midi:jack_notify({port,reg,in,"jack_clock-01:in"})
exo@tp.zoo: exo_midi:jack_notify({port,reg,out,"jack_clock-01:out"})
exo@tp.zoo: Bridge started
exo@tp.zoo: Press ctrl-c to stop the bridge
exo@tp.zoo: exo_midi:jack_notify({port,reg,in,"jack_synth:midi_in_0"})
exo@tp.zoo: port created: Midi Through (capture): Midi Through Port-0
exo@tp.zoo: port created: Midi Through (playback): Midi Through Port-0
exo@tp.zoo: exo_midi:jack_notify({port,reg,out,"jack_synth:audio_out_0"})
exo@tp.zoo: exo_midi:jack_notify({port,reg,out,"a2j:Midi Through (capture): Midi Through Port-0"})
exo@tp.zoo: exo_midi:jack_notify({port,reg,in,"a2j:Midi Through (playback): Midi Through Port-0"})


My guess is that client kill, start needs to be sequenced so jackd
sees the kill before the new register.

EDIT: No it was just a duplicate name, jack_erl still had jack_clock
name from cloning the code.


Entry: try the restart
Date: Sat Sep  9 10:38:35 AM EDT 2023

So it works now.
Next: Let's actually try a restart.


Entry: restart
Date: Sun Sep 10 06:25:43 AM EDT 2023

Two things: build the elf, change the directory in restart.

Got the rule working, but the stop,start sequence doesn't seem to be
correct yet wrt jack daemon.


Entry: wiring is physical-like
Date: Mon Sep 11 09:54:28 AM EDT 2023

Think in terms of physical wires, because that is going to be the base
of all connections.  This also means that each node has its own wiring
setup, and the global wiring setup is a collection of nodes.


Entry: things to try
Date: Mon Sep 11 09:55:49 AM EDT 2023

Does midi work over jack network connections?

Ok how do i test this?



Entry: one big patch
Date: Mon Sep 11 10:11:46 AM EDT 2023

Maybe the next step should be to use Haskell to create the big patch
abstraction that has everything, then compile that to a collection of:

1. jack instances on physical hosts, exposing physical ports and CPU

2. per jack client network

3. connections "inside" a jack client or "behind" a hardware port,
   e.g. Pd, some C code on host, or uC code

How do I manage this?

It is about processing graphs and subgraphs, i.e. a compiler problem.
So the thing to learn is to learn to work with graphs.

They are directional graphs combined with some form of delay element.



Entry: jack_net
Date: Mon Sep 11 11:30:38 AM EDT 2023

netmanager, netadapter

zoe:
jack_load netmanager


Sep 11 11:32:48 zoe exo_vm[13029]: exo_midi:jack_notify({client,reg,"jack_load"})
Sep 11 11:32:48 zoe exo_vm[13029]: exo_midi:jack_notify({client,reg,"netmanager"})
Sep 11 11:32:48 zoe exo_vm[13029]: Starting Jack NetManager
Sep 11 11:32:48 zoe exo_vm[13029]: Listening on '225.3.19.154:19000'
Sep 11 11:32:48 zoe exo_vm[13029]: exo_midi:jack_notify({client,unreg,"jack_load"})

mimas:
jack_load netadapter -i '-C 4'

Sep 11 11:35:12 zoe exo_vm[13029]: Sending parameters to mimas...
Sep 11 11:35:12 zoe exo_vm[13029]: exo_midi:jack_notify({client,reg,"mimas"})
Sep 11 11:35:12 zoe exo_vm[13029]: Syncing with latency = 0
Sep 11 11:35:12 zoe exo_vm[13029]: exo_midi:jack_notify({port,reg,in,"mimas:to_slave_1"})
Sep 11 11:35:12 zoe exo_vm[13029]: Syncing with latency = 1
Sep 11 11:35:12 zoe exo_vm[13029]: New NetMaster started
Sep 11 11:35:12 zoe exo_vm[13029]: **************** Network parameters ****************
Sep 11 11:35:12 zoe exo_vm[13029]: Name : mimas
Sep 11 11:35:12 zoe exo_vm[13029]: Protocol revision : 8
Sep 11 11:35:12 zoe exo_vm[13029]: MTU : 1500
Sep 11 11:35:12 zoe exo_vm[13029]: Master name : zoe
Sep 11 11:35:12 zoe exo_vm[13029]: Slave name : mimas
Sep 11 11:35:12 zoe exo_vm[13029]: ID : 1
Sep 11 11:35:12 zoe exo_vm[13029]: Transport Sync : no
Sep 11 11:35:12 zoe exo_vm[13029]: Send channels (audio - midi) : 4 - 0
Sep 11 11:35:12 zoe exo_vm[13029]: Return channels (audio - midi) : 2 - 0
Sep 11 11:35:12 zoe exo_vm[13029]: Sample rate : 44100 frames per second
Sep 11 11:35:12 zoe exo_vm[13029]: Period size : 64 frames per period
Sep 11 11:35:12 zoe exo_vm[13029]: exo_midi:jack_notify({port,reg,in,"mimas:to_slave_2"})
Sep 11 11:35:12 zoe exo_vm[13029]: Network latency : 2 cycles
Sep 11 11:35:12 zoe exo_vm[13029]: SampleEncoder : Float
Sep 11 11:35:12 zoe exo_vm[13029]: Slave mode : sync
Sep 11 11:35:12 zoe exo_vm[13029]: ****************************************************
Sep 11 11:35:12 zoe exo_vm[13029]: Waiting for a slave...
Sep 11 11:35:12 zoe exo_vm[13029]: exo_midi:jack_notify({port,reg,in,"mimas:to_slave_3"})
Sep 11 11:35:12 zoe exo_vm[13029]: exo_midi:jack_notify({port,reg,in,"mimas:to_slave_4"})
Sep 11 11:35:12 zoe exo_vm[13029]: exo_midi:jack_notify({port,reg,out,"mimas:from_slave_1"})
Sep 11 11:35:12 zoe exo_vm[13029]: exo_midi:jack_notify({port,reg,out,"mimas:from_slave_2"})

Sep 11 11:35:12 mimas exo_vm[102652]: exo_midi:jack_notify({client,reg,"jack_load"})
Sep 11 11:35:12 mimas exo_vm[102652]: exo_midi:jack_notify({client,reg,"netadapter"})
Sep 11 11:35:12 mimas exo_vm[102652]: Ringbuffer automatic adaptative mode size = 4096 frames
Sep 11 11:35:12 mimas exo_vm[102652]: exo_midi:jack_notify({port,reg,in,"netadapter:playback_1"})
Sep 11 11:35:12 mimas exo_vm[102652]: NetAdapter started in sync mode without Master's transport sync.
Sep 11 11:35:12 mimas exo_vm[102652]: exo_midi:jack_notify({port,reg,in,"netadapter:playback_2"})
Sep 11 11:35:12 mimas exo_vm[102652]: Waiting for a master...
Sep 11 11:35:12 mimas exo_vm[102652]: exo_midi:jack_notify({port,reg,out,"netadapter:capture_1"})
Sep 11 11:35:12 mimas exo_vm[102652]: exo_midi:jack_notify({port,reg,out,"netadapter:capture_2"})
Sep 11 11:35:12 mimas exo_vm[102652]: Initializing connection with zoe...
Sep 11 11:35:12 mimas exo_vm[102652]: **************** Network parameters ****************
Sep 11 11:35:12 mimas exo_vm[102652]: Name : mimas
Sep 11 11:35:12 mimas exo_vm[102652]: Protocol revision : 8
Sep 11 11:35:12 mimas exo_vm[102652]: MTU : 1500
Sep 11 11:35:12 mimas exo_vm[102652]: Master name : zoe
Sep 11 11:35:12 mimas exo_vm[102652]: Slave name : mimas
Sep 11 11:35:12 mimas exo_vm[102652]: exo_midi:jack_notify({port,reg,out,"netadapter:capture_3"})
Sep 11 11:35:12 mimas exo_vm[102652]: ID : 1
Sep 11 11:35:12 mimas exo_vm[102652]: Transport Sync : no
Sep 11 11:35:12 mimas exo_vm[102652]: Send channels (audio - midi) : 4 - 0
Sep 11 11:35:12 mimas exo_vm[102652]: Return channels (audio - midi) : 2 - 0
Sep 11 11:35:12 mimas exo_vm[102652]: Sample rate : 44100 frames per second
Sep 11 11:35:12 mimas exo_vm[102652]: Period size : 64 frames per period
Sep 11 11:35:12 mimas exo_vm[102652]: exo_midi:jack_notify({port,reg,out,"netadapter:capture_4"})
Sep 11 11:35:12 mimas exo_vm[102652]: Network latency : 2 cycles
Sep 11 11:35:12 mimas exo_vm[102652]: SampleEncoder : Float
Sep 11 11:35:12 mimas exo_vm[102652]: Slave mode : sync
Sep 11 11:35:12 mimas exo_vm[102652]: ****************************************************
Sep 11 11:35:12 mimas exo_vm[102652]: exo_midi:jack_notify({client,unreg,"jack_load"})


How to enable midi ports?  The '-i' option doesn't seem to work.



Entry: new layout
Date: Mon Sep 11 01:43:31 PM EDT 2023

zoe is for analog synths, midi controllers and maybe digital synths/pd
- it has direct in for all the synths + maybe also wire up the feedback thing

mimas 
- digital mixer for ad-hoc things
- extra analog tap points for modular setup
- extra pd

zoo
- development station with possible transport to mimas, synced to zoe
- extra pd



I do want to take the fastrack pro + m93p out of the picture, and also
the behringer mixer.  Things will get too complicated.

EDIT: Replaced fastrack pro with connection to layla mimas.  This does
get rid of the mixer knob but I might be able to compensate.  Also
replaced the USB behringer mixer wiht the 1202 analog.




Entry: next
Date: Mon Sep 11 03:28:21 PM EDT 2023

using pd is not necessary
can just do jack clients

this makes the whole network a mesh of inter-jack (netmanager,
netadapeter), jack, and intra-jack (modules making up a jack client).



Entry: what jack clients do i need?
Date: Mon Sep 11 03:39:53 PM EDT 2023

On zoe (and mimas):
- recorder
- mixer + effects rack
- midi sequencer

Separately, a drum machine / sample mangler, tying into the recorder.

Mimas has 64g memory.

I want to do this as an eDSL in Haskell using GADTs.  First on a
"coarse grain" scale, where it glues together C programs, then also
build the interals of those.



Entry: jack netadapter midi
Date: Wed Sep 13 07:25:25 AM EDT 2023

Midi seems to be disabled by default.

So just work around that for now.  All midi is connected to zoe, and
should be bridged separately.

I'm wondering if it makes sense to just get rid of zoe altogether,
because I have a bunch of i/o now.  Maybe I'm making this way too
complicated.

I'm building this distributed system but what I really want is
something centralized.  The thing is that 16 i/o is more than enough
for what I want to do, until I start doing more analog.


Sommary:
- mimas is for soft synths, Pd, recording
- zoe is for midi, synth input, maybe some effects

Does mimas need midi?
Yes, for synth control.


I need a different mindset.  More like "hardware has arbitrary
limitations, just work with that".  Instead of trying to do everything
in a general way.

Basically, the "setup" is fixed.  Don't remove anything.  Only add.
This is just for playing.  Doesn't need to go out.  It is a staging
area.

This is going to be difficult to resist or internalize.

Basically: the jack daemons are a tool.  Configuration doesn't need to
be pretty.


Entry: emu10k1
Date: Wed Sep 13 07:47:17 AM EDT 2023

It would be useful mostly for its effects processor, since it has low
latency i/o (i think).

A similar thing would be possible on the layla dsp as well maybe?  But
doesn't seem that firmware is open.

For later.




Entry: erl midi
Date: Wed Sep 13 08:20:21 AM EDT 2023

That seems to be the obvious next step.

Also regarding absence of jack midi, maybe just do Pd protocol, since
Pd doesn't really have a working midi setup atm either.

Let's do Pd first.  That can already embed midi.  Then make the erl
protocol work on top of that.

Maybe this should just do TCP.

I think maybe I want to have Pd start control also managed by Erlang.
Then there could be a dedicated channel set up that connects the local
Erlang to a Pd instance.  Would make it easier to start up distributed
stuff as well



Entry: erl Pd
Date: Wed Sep 13 08:40:11 AM EDT 2023

So do Pd first.  If there is access to a display, start it with a gui,
otherwise without.

I'm not really thinking this through.

I would like to put this behind the same interface as the other jack
clients, where the binary takes the {packet,4} protocol.  So that will
need some kind of wrapper.

Or, make a different wrapper for jack clients that do not support
{packet,4}.

Man I get tired of this glue code.

But it would be worth it to have Pd bridged properly.  Probably should
do TCP so it can go in an out of Erlang.

So what do I want here?

- Wrapper binary that accepts {packet,4}.
- Starts Pd with control patch containing netreceive
- Connects to TCP

Can this be done in Erlang?


Dammit I found busywork again...

socat is not properly killing Pd
probably it ignores signal

so what is socat actually doing?
grepping for kill in *.c brings up:
tom@luna:/i/tom/git/socat$ grep -re kill *.c
sycls.c:   Debug2("kill("F_pid", %d)", pid, sig);
sycls.c:   retval = kill(pid, sig);
sycls.c:   Debug1("kill() -> %d", retval);
xioclose.c:	       Msg2(errno==ESRCH?E_INFO:E_WARN, "kill(%d, SIGTERM): %s",
xioinitialize.c:   we do not want the program to be killed by the first tcp-l sub process, it's
xioinitialize.c:   better if it survives all sub processes. Thus, it must not be killed when
xioinitialize.c:static int xio_nokill(xiofile_t *sock) {
xioinitialize.c:      if ((result = xio_nokill((xiofile_t *)sock->dual.stream[0])) != 0)
xioinitialize.c:      result = xio_nokill((xiofile_t *)sock->dual.stream[1]);
xioinitialize.c:      result2 = xio_nokill(sock1);
xioopts.c:	IF_TERMIOS("crtkill",	&opt_echoke)
xioopts.c:	IF_TERMIOS("kill",	&opt_vkill)
xioopts.c:	IF_TERMIOS("vkill",	&opt_vkill)
xio-progcall.c:      /* exec:...,pty did not kill child process under some circumstances */
xioshutdown.c:static pid_t socat_kill_pid;	/* here we pass the pid to be killed in sighandler */
xioshutdown.c:static void signal_kill_pid(int dummy) {
xioshutdown.c:   Notice("SIGALRM while waiting for wo child process to die, killing it now");
xioshutdown.c:   Kill(socat_kill_pid, SIGTERM);
xioshutdown.c:	    therefore we have to do the kill in the signal handler */
xioshutdown.c:	    act.sa_handler = signal_kill_pid;
xioshutdown.c:	 socat_kill_pid = sock->stream.para.exec.pid;
xiosignal.c:	    Warn2("kill("F_pid", %d): %m",
xio-termios.c:const struct optdesc opt_vkill    = { "vkill",  "kill",  OPT_VKILL,    GROUP_TERMIOS, PH_FD, TYPE_BYTE, OFUNC_TERMIOS_CHAR, VKILL };

probably enabling Notice() would give some more information



Another way is to make an external that reads stdin.

socat -d -d -d - EXEC:pd.local

2023/09/13 09:53:26 socat[186835] I transferred 1 bytes from 0 to 5
2023/09/13 09:53:28 socat[186835] N socket 1 (fd 0) is at EOF
2023/09/13 09:53:28 socat[186835] I shutdown(5, 1)
2023/09/13 09:53:29 socat[186835] I poll timed out (no data within 0.500000 seconds)
2023/09/13 09:53:29 socat[186835] I shutdown(5, 2)
2023/09/13 09:53:29 socat[186835] N exiting with status 0

sycls.c:
Info2("shutdown(%d, %d)", fd, how);


You know I'm just going to make a manager for this, instead of socat.
Maybe something can be learned.



Making a wrapper C program.
Getting stuck at Pd not parsing data correctly. WTF.

EDIT: Used wireshark to follow TCP stream. It was sending the nul
string terminator.



Entry: midi clock sync
Date: Thu Sep 14 06:26:27 AM EDT 2023

If the sound cards are synchronized, then any drum machines can have
their own local sync.

The time base is on zoe.  So let's see if it is possible to get the
time base on mimas syncrhonized.

Simplest way to do this is to put these things on scope.  Make two bp
boards with sync.

Actually it's enough to trigger bursts on the midi clock.



Entry: Go back to "every knob an ip address"
Date: Thu Sep 14 06:30:27 AM EDT 2023

Is that currently possible?

I still want a list of knobs to map to a list of destinations.  Really
this is midi learn.



Entry: How to get out of the impasse?
Date: Thu Sep 14 06:36:00 AM EDT 2023

What's the next thing to build?

I want to start making beats, so the sampler/sequencer is most important.



Entry: sampler
Date: Thu Sep 14 06:39:20 AM EDT 2023

One issue with looper is slave mode.

For events this is not such a big deal, so it looks like it's going to
be necessary to make the loops auto-segment?

So maybe start there.

Or otherwise, the looper is the time base.  That would be much
simpler.  Then it can add groove as well.

So yeah I'm going to need groove.

So let's focus on groove.

It would be nice if multiple clients could re-use the sample library,
so maybe write that as a service?

This can be done in Erlang.  Mimas can hold the library and do the
processing.  It has plenty of memory.  The processing can probably be
done in a high level language since it will be background, so do it in
Haskell?

Or let's use Rust's multi-threading.

So the sample service solves "prepare me a flat sample".  This can
then be written to disk and mmapped.



Example:

- sample lib prepares a flat sample and a groove structure

- clock.c uses that to play it back on its audio channel, deriving
  midi clock from it

- then extend it with groove



Entry: back to what i want
Date: Thu Sep 14 07:02:17 AM EDT 2023

Really just a simple way to play back loops.
Representation could just be rendered, i.e. flat files.
Which also makes it easy to import them into pd, tabread4.

So if I focus on building the sampler in Pd, and then do all the
infrastructure around that to build the samples, it should be fine.

So first, I need a sync betwen Pd and midi.

EDIT: Secondly, this is not a recorder.  How to make a recorder?





Entry: is redo really necessary?
Date: Thu Sep 14 08:04:46 AM EDT 2023

E.g. for i.erl manual startup it's probably enough to use exo:need/1.



Entry: Solve the Pd midi thing
Date: Thu Sep 14 11:28:03 AM EDT 2023

Sync + midi controllers (knobs).

Yeah let's just completely forget about Pd midi.
Solve it in the "frontend".



Entry: TD-03 midi implementation
Date: Thu Sep 14 12:33:55 PM EDT 2023

https://303patterns.com/td3-midi.html

What do I want?  A load/save utility.  Something that creates a jack
port, connects to the TD-03 and loads/saves the current pattern.



Entry: bad view
Date: Thu Sep 14 09:34:01 PM EDT 2023

Maybe what is happening now is dispelling the illusion that any of
this is easy.  Sure there is a lot of low hanging fruit, but what I'm
trying to do is not that.


Entry: pick something
Date: Fri Sep 15 08:43:52 AM EDT 2023

Keep coming back to this: I need to pick something and stick to
it. then fix whatever secondary problem pops up.


Entry: sync pd to drum machines
Date: Fri Sep 15 08:44:56 AM EDT 2023

Why was this such a problem?
Because there is no midi.

What about just making a midi to audio bridge.

You know it can actually be solved by making Pd master, but relying in
things being master is a bad idea in this distributed setup, so start
with slave first.

Most reliable is probably to use jack audio.

EDIT: Alright I have a squarewave jack out.  Should be enough for now.




Entry: i need new blood
Date: Fri Sep 15 10:46:05 AM EDT 2023

Something else to break this impasse because I am really stuck.

Maybe it's time to continue with RTIC?
Maybe it's time to do RTIC in C?

I think I need to build an actual scheduler in C.


Entry: korg sync
Date: Fri Sep 15 11:34:03 AM EDT 2023

5V, 276 ms period

(/ 1 0.276) 3.623188405797101 Hz

(/ 140 60.0)  2.33 Hz is 140bpm


Things I need to test this:

- a simple way to set bpm.  maybe use the netsend back?  I really want
  a monolith, this is ridiculous.



Trying again with actual 140 bpm

232ms

(* (/ 48 44.1) (/ 1.0 0.232) 30)

4.310344827586206





Entry: TODO
Date: Fri Sep 15 11:54:54 AM EDT 2023

- clock should use actual sample rate
- send start/stop message via midi, test on volcas
- use dedicated controller for start/stop (m-audio)
- send tempo message, maybe also midi?
- double timebase for volcas




Entry: abstract away jack completely?
Date: Fri Sep 15 01:04:44 PM EDT 2023

The thing is that I want to connect everything to everything, and
having to cross implementation borders is a huge impediment,
especially when there are loops involved.

Maybe the central part should just be pd.


I don't seem to be able to make up my mind...


What about this: deriving the midi clock as audio from the midi pulses
does create a lot of jitter, so it might be best to do it the other
way around.  Let the base waveform for the clock be audio.

EDIT: Works

I'm happy with it.



Entry: start from erlang (and midi)
Date: Fri Sep 15 03:17:41 PM EDT 2023

I want this to work:

i:clock() ! start.



Entry: midi and Pd
Date: Sat Sep 16 08:16:14 AM EDT 2023

So Pd clock is working.  What I miss mostly is a bridge from Pd to the
synths.  How to get midi out?

It seems best not to use MIDI in Pd at all, just continue with the
Erlang or FUDI/netsend.

So let's just try this.  I need:

1. a way to set clock tempo from Pd and midi, so it can be used musically
2. sequencing for the midi equipment


Entry: just continue
Date: Sat Sep 16 11:29:42 AM EDT 2023

Prime objective is always to work towards a usable live improv setup.


Entry: start/stop
Date: Sun Sep 17 06:28:59 AM EDT 2023

Do the basic thing: make sure that
- start/stop button on midi controller works
- i:clock() ! {midi,<<16:FA>>} works

side project:
- midi logger
- jack/erl bridge
- maybe restore epid?


EDIT: Alright, start/stop is working via Erlang.

Not sure why it didn't work via midi controller, but that's easy
enough to figure out.

So next: actual setup with sample player from Pd?


Entry: next: midi monolyth
Date: Sun Sep 17 08:02:48 AM EDT 2023

Midi routing/filtering is an annoying issue, so it should be done in a
monolyth to avoid a lot of duplication and "where do i put this?"
problems.



Entry: get digital audio into a microcontroller
Date: Sun Sep 17 09:39:06 AM EDT 2023

I have plenty of s/pdif outputs.  It might be a good idea to use the
stm32f peripheral to sync to that, instead of trying to work with word
clock and a separate data channel.

How does the input work?  The delta1010 uses an rs485 receiver I think.


( EDIT: Another distraction. Stay on target. )




Entry: midi hub
Date: Sun Sep 17 11:15:35 AM EDT 2023

I have the C skeleton.

Maybe add pd and clock to the monolith as well.
I guess this should evolve naturally.
Find an internal composition mechanism first.

Ok so ideas are starting to come.
Just some resistance to actually doing something.

I'm going to need a way to handle the idea of "mixer".

On hardware setups these can be hardware mixers.

On luna + laptops, these will be midi controllers and likely jack
clients.

Should hub an mixer be the same process?  Probably not.




Entry: sync
Date: Sun Sep 17 01:15:24 PM EDT 2023

The word clock pulse is 0V-5V



Entry: what next?
Date: Sun Sep 17 01:16:38 PM EDT 2023

- synth for bass & bd generation
- mixer with worlde control

build both at the same time.  only need a mixer once there are two sources!


i just want to do weird shit, disguised as techno


next step: make sure start is propagating to pd

EDIT: alright, got it.  just did the simple thing.



Entry: start/stop
Date: Mon Sep 18 05:31:23 AM EDT 2023

Basically, harp on a bit on sync.  If sample clocks are locked then it
is not necessary to send a clock signal, only the half period.


Entry: too much variability
Date: Mon Sep 18 05:39:02 AM EDT 2023

The issues are:

- pd doesn't support jack midi, so i have to go via netsend, and i
  don't know if i can trust that to send sync messages

- one way around it is to not send clock at all to pd, and do all
  sequencing in a jack midi thread

Ok I got something.

But it might still be simplest to just use start/stop and a 16th note
tick, then let Pd do its own sequencing e.g. for polyrythms.  Maybe
also take a listen to see how tight it is?



Entry: distributed mixer
Date: Mon Sep 18 06:47:19 AM EDT 2023

Maybe it's good to not rely on multiple channel out and a monolythic
mixer, but to distribute the mix/filter controls with messages, and
accumulate onto mixer bus early.

Basically, all jack clients have a main stereo out, and each of these
outputs has the usual mixer strip functionality attached: filter, pan.

The effects send then needs to be done differently.  That does need a
separate output.


The principle here is a form of loop fusion/deforestation, moving
operations into the inner loop, instead of splatting them out into
temporary buffers.  Internal channels are cheap, external channels are
harder to deal with.


If I use the accumulation approach then it is easy to chain computers
via spdif, without the need for jack netsend.  This would make it easy
to put the development desk into a performance.  Final mix could stil
be sent via net, as delay is not so important for recording.






Entry: pd clock stuff
Date: Mon Sep 18 07:00:25 AM EDT 2023

So basic idea is to use CC c n v to encode arbitrary events from hub.c -> pd
I think this is enough to actually get started making techno.
Next up: build some patches, and solve the mixer issue.

So in Pd:
- chan 0: single ended events
- chan 1: mixer, 127 channels, 127 levels



Entry: Think about effects
Date: Mon Sep 18 07:09:56 AM EDT 2023

The only global effect is reverb, which is also post-fader.

That can be solved by a single reverb effect and multiple inputs with
input filters.

All the other effects should probably be contained in the instruments
themselves.  This is also how it works in practice.



Entry: This is what I wanted
Date: Mon Sep 18 08:25:34 AM EDT 2023

I now have some C code for midi processing that can easily reload in a
running system.



Entry: hub.c Erlang out
Date: Mon Sep 18 10:00:58 AM EDT 2023

Next is a way to bring MIDI events back into Erlang.

Was looking in jack_midi.c but it's not as I expect.
Have to actually read it.

EDIT: Ok it just used a write in the jack thread.


Entry: next
Date: Mon Sep 18 06:53:49 PM EDT 2023

Maybe it is time for some music now?

I think the infra is mostly there, except for the distributed mixer
but it seems that can be built incrementally.

Also, maybe it is time to consolidate around the yamaha?  Basically,
eliminate zoe?  I think I have enough i/o to rewire everything.

Maybe move the spirit to the other rack?

Anyway, let's stick to what is there now.  Having a feeling I'm going
to move to a software mixer anyway, or maybe ardour.



Entry: shiny new toy syndrome
Date: Mon Sep 18 06:58:38 PM EDT 2023

Time to admit that I don't really have a plan.
So let's enjoy not having a plan for a while.


Entry: issue with midi clock out
Date: Mon Sep 18 08:02:30 PM EDT 2023

it's as if it is dropping bytes to the 4i4o

ok it seems it is time to build something else, or get a midi through box


Entry: next
Date: Tue Sep 19 06:17:15 AM EDT 2023

Started bidding on a midi thru box to attempt to solve the clock issue
and retire the 4x midi out.

Maybe time to first focus on the digital drum machine.

Do I collect a todo list and get depressed, or do I focus on ideas
that just come up.  I guess I already have payed work to practice
structured approach and working through resentment.  This is a hobby,
really, so only fun stuff and things that are really clear.

I think I want to do a mixer next.  Build a Pd patch with 9 channels
and use the easycontrol to control it:

- bas & bass drum synth
- sampled loops
- reverb

Then in a second iteration, create the akai fire step sequencer.



Entry: snapshotting
Date: Tue Sep 19 06:40:16 AM EDT 2023

How do to this better?

Snapshot should capture the current state, but should not touch any
connections that are stored for clients that are not active.

How to implement?

Transaction:
- Delete all connections that have both clients active
- Add all current connections

But it really might be simpler to catch the user actions directly into
the database, and then just snapshot that to /etc/net

I do want the .csv files, but while the db is there, better to use it
directly.  The "root" doesn't really matter in practice.  It's easy
enough to rebuild state once it gets lost, or on a new host.



Entry: First step is bass + bassdrum and mixer
Date: Tue Sep 19 06:58:06 AM EDT 2023

...

Idea for controller movement: instead of recording knob motion, try to
do it with "envelope kinds".




Entry: Is there too much gear?
Date: Tue Sep 19 03:47:11 PM EDT 2023

Probably.  The zoe is not really necessary.

I keep getting stuck on no inspiration, or that the next step is again
rewiring something.  There isn't really a line that runs through this.


Entry: Analog synth
Date: Tue Sep 19 03:54:49 PM EDT 2023

Split it up.

The delta1010 can do +4dB line level, which probably works well with
the modular.

https://en.wikipedia.org/wiki/Line_level
+4dBu  Vpp 3.472
-10dBV Vpp 0.894


There is going to be a new box arriving that can host both delta
cards.  Or just keep it the way it is now: one delta1010 in the play
room and one in the dev room.

But move the synths to the digital mixer.



Entry: what do the synths want to do?
Date: Tue Sep 19 04:10:42 PM EDT 2023

The modular wants to be born.
Use a delta1010 as interface.

Standardize on 3.5mm jacks.  Buy this:
https://www.ebay.com/itm/383289728307
But first make sure that the stereo adapters are ok.
Should be fine.

Leave it spit between zoe and zoo.


The other synths want easy effects, so connect them to the o1v.


So don't do this yet.  Because it is again just busywork.

Except for the o1v...  But wait until the midi thru box arrives, see
how it feels by then.


The O1v makes sense because it saves a step of analog cabling: no
direct out is needed, because that can go straight to the adat port.

So maybe just go ahead and set this up.




Entry: rewired
Date: Tue Sep 19 08:01:34 PM EDT 2023

Split ayudio into two parts:
- o1v adat<->mimas connected to analog synths
- zoe<->delta10 set up with modular, pedals and spirit mixer

Midi is still on zoe.

next: 4 x midi thru box on delta10 midi out for 3 volcas + o1v mixer.


Entry: Change the sync
Date: Tue Sep 19 09:04:55 PM EDT 2023

layla is now master, 44.1
-> adat -> o1v
-> spdif -> delta1010 @ zoe
-> spdif -> delta1010 @ zoo



Entry: Ethernet
Date: Fri Sep 22 09:04:25 PM EDT 2023

Ik lost track of that.  I was thinking about how to do more embedded
things, while thinking about USB which is hopeless really.  But
Ethernet works well on PC and embedded.

EDIT: The obvious next step here is Rust on that higher end STM board.



Entry: starting up second card client
Date: Sat Sep 23 08:25:19 AM EDT 2023

It's not -X.  That is only for midi.

Maybe use --internal-session-file or -C ?

Ok that works.  Syntax is different:

tom@mimas:/etc/net/dsp$ cat internal-layla3g 
load system_analog audioadapter -d hw:Layla3G,0 -i8 -o8 -r44100



Entry: Seem to have some startup issues still
Date: Sat Sep 23 09:41:12 AM EDT 2023

Not clear what goes wrong.  Weird thing is that setting the volume of
the pd test audio patch made it behave badly.  Mabye a cable issue?
Load should be the same.

Let's reboot and see if it starts up properly now.

It seems ok now.

But the envy24control is still needed manually to sync to the spdif.

Alright so next step is to look at the source and distill a tool.



Entry: envy24control
Date: Sat Sep 23 10:37:09 AM EDT 2023

envy24control.c defines 
GtkWidget *hw_master_clock_spdif_radio;

which has:

	gtk_signal_connect(GTK_OBJECT(radiobutton), "toggled",
			  (GtkSignalFunc)internal_clock_toggled, 
			  (gpointer)"SPDIF");


internal_clock_toggled() is in hardware.c

	} else if (!strcmp(what, "SPDIF")) {
		internal_clock_set(13);




moving along...

there is a config file:
  config_filename=g_strdup_printf("%s/%s", g_get_user_config_dir(), "envy24control");

So maybe use that instead?



tom@zoe:/i/tom/exo/synth_tools/linux$ ./envy24.dynamic.host.elf
found hw:1
internal_clock = 13



Entry: i.jack environment
Date: Sat Sep 23 01:45:06 PM EDT 2023

There are currently two different environemnts.  One is the exo_vm,
the other is etc-net-run.  They should probably just be the same.



Entry: removing impediments
Date: Sun Sep 24 07:39:11 AM EDT 2023

at the embedded level, some impediments:

- syncing to an spdif stream
- sending data over ethernet
- driver for the 12 channel envelope/lfo
- the big stm, anything
- older axoloti board

clearly some focus is needed here
it seems that stm32f103 is the simplest next step


Entry: volca midi
Date: Sun Sep 24 07:46:04 AM EDT 2023

I think the keys uses 3 channels for polyphony, so maybe start there.
First find out if that is actually true.
No dufus that is not how polyphony works.

https://en.wikipedia.org/wiki/Volca_Keys
All controls are digital


https://drolez.com/blog/music/korg-volca-keys-global-settings.php
1. MEMORY + power
2. keys 1-16 correspond to midi channels
3. REC=save / PLAY=cancel


Current channels
1: keys
2: bass (changed from 1)
10: drum




Entry: next: db
Date: Sun Sep 24 08:33:34 AM EDT 2023

Do as mentioned earlier.
- Remove all connections for currently active devices
- Add all current connections

That's just SQL. Switch into that.



Entry: so what's next?
Date: Sun Oct  1 06:14:33 AM EDT 2023

There is now firmware control over modular signals.

Would be nice to have midi control, but I am not clear about what
exactly that should be.

From the other side: USB midi should already just work.  I mostly need
to wire that up.  The other midi needs some electronic work first.

So maybe focus on USB first.

Then it is probably DSL time.

Before doing USB, make sure that it is possible to reload an
application without restarting the uc.  E.g. turn off the interrupt,
reload, restart.  I can test that on the bench setup first.

Ok so workflow-wise: work on two circuits, one (the PDM) on the bench,
and the PIXI in the modular.



Entry: getting distracted
Date: Sun Oct  1 10:59:21 AM EDT 2023

What do I want?

1. midi control of the PIXI
2. easy way to update code without replugging

Where am I stuck?
The tether_bl readout does not respond.

EDIT: /dev/midi access does not work when jack is running, so make
this work in jack.



Entry: jack debug server
Date: Sun Oct  1 11:21:23 AM EDT 2023

So I needed a server anyway, so let's just build it in jack.

Recap on sysex: first byte after start byte is manufacturer.
Everything after that is converted to 8-bit and pushed to 3if as a
stream.

So this really talks directly to 3if.

The jack debug server should then open a TCP port with just the 3if
protocol.

EDIT: What about just putting this in the hub?  That way all control
is from Erlang.  Do I need this to do anything other than Erlang?

Yeah today is not the day though.  I feel there are too many things
that need to be decided.  What I wanted to do was to simply play with
this...


Entry: next
Date: Mon Oct  2 06:29:22 AM EDT 2023

The jack server.
I think I will put it in hub.

So next step there is to do write some Erlang code to talk to devices.

Context-switch into Erlang and add a serializer/deserializer for sysex
to the hub.


Entry: take a step back
Date: Mon Oct  2 06:33:46 AM EDT 2023

I still feel I am mostly building infrastructure for infrastructure's
sake.  Is this so?

The debugger would be useful.  I really can't do anything until that
works properly so yes I do need that.  But does it have to be weird
again?

What about just making a TCP midi bridge instead and use the existing
code?

So where does that go?

Seems simplest to make it go into jack_client.erl

No this should be separate.

The hub currently already has multiple midi ports.


Entry: midi tethering design
Date: Mon Oct  2 07:24:56 AM EDT 2023

Make it work with /dev/midiX as it already does. This will make it
possible to work with a simplified (non-integrated) setup.

Create a bridge that emulates /dev/midiX on TCP.

This should probably be a separate Erlang process, that can then
connect to jack_client.erl running hub.


EDIT: Clarity is not there.  I need to touch too many things.

I'm stuck.  All paths I can see are too complicated.

What surprises me is that I do not enjoy getting into Erlang again.
What is that about?

Also a depression thing?  Like I've spent so much time on this but it
is not really living up to what I expected.

Maybe take a hint here: don't do this in Erlang.
There might be an alsa loopback thing that solves this.
Or just do a plain TCP to jack bridge.
Yeah let's do that instead.

I think the underlying thing here is that I am very tired of
dynamically typed languages.  I'm tired of making stupid mistakes that
require debugging time.

Anways, the issue with a bridge application is that midi needs to be
parsed on input.

So I am not going to escape that part.  It should probably be unified
across all synth_tools code.


Entry: standardize the midi parser
Date: Mon Oct  2 08:15:35 AM EDT 2023

This will need to run on the uc as well, so write it as something that
can run from ISR.

There is already code that does this for USB.

Just write it for the uc first.  I can do this with the delta1010 on
the bench.


Entry: stack
Date: Mon Oct  2 08:17:28 AM EDT 2023

The stack is getting deep, here's a trace:

- tether_bl_midi.c changes to talk to 3if
- database setup for connect
- studio_midi.c stdio to jack bridge
- generalized code for TCP parser daemon
- isr uart midi parser on uc
- hardware midi setup (opto reference circuit)
- find old midi cable


Most of this is not really necessary yet.  But let's identify the
parts that really need to run on the uc.

It would be good to have an opto reference circuit anyway.

Let's abandon the hardware stuff for now.  It feels like a
distraction.  Focus on the midi parser code.

Actually there was code for this already in akay_fire.c

Alright now I am thinking the code should really just be built into
tether_bl_midi.c

Maybe time to let this sit for a while since I cannot make up my mind.

EDIT: I'm going to integrate jack into tether_bl_midi.c



Entry: Two pipe system
Date: Mon Oct  2 09:22:50 AM EDT 2023

I think I want to try something else:
- pipe to and from main jack thread
- a poll in the jack thread

EDIT: Ok I have some skeleton set up.  Still missing some pieces.
Maybe time to run in packet mode?

Because, really, I am not going to run this on anything other than
Linux so why bother with segmenting...


Entry: debugging
Date: Mon Oct  2 11:45:12 AM EDT 2023

tom@luna:/i/exo/synth_tools/linux$ ./tether_bl_midi.dynamic.host.elf /dev/midi3 info
info
 f0 12 02 05 05 58 28 00 08 f7
 f0 12 02 02 09 04 f7
 f0 12 06 05 05 10 3d 00 08 f7
 f0 12 02 02 09 04 f7
 f0 12 02 05 06 57 31 00 08 f7
 f0 12 02 01 07 f7


tom@luna:/i/exo/synth_tools/linux$ ./tether_bl_midi.dynamic.host.elf test info
info
 f0 12 02 05 05 58 28 00 08 f7
 f0 12 02 02 09 04 f7
../uc_tools/linux/mod_tether_3if.c: 166: ASSERT FAIL: s->buf[0] == chunk

That is odd.
Because same data goes in/out.

Put it down for a bit...

EDIT: Ok out buffer did not flush.

Works now, but is slow.  It seems that this jack sysex thing is not
such a great idea if RPC is involved.

Anyway, it works.  Let's not get distracted further.

Next thing is to make some kind of console server or a GDB stub.


Entry: Symbol table
Date: Mon Oct  2 12:59:12 PM EDT 2023

Something easily accessible from C.


Entry: Make a Forth
Date: Mon Oct  2 01:08:50 PM EDT 2023

That will guarantee joy.
But maybe best to first get the gdbstub up.
Build the forth as part of the monitor.

EDIT: Alright I got a bit further with the gdbstub. Fixed a bug in the
registers read command.  Next is firmware load.

EDIT: Seems to be corruption still.



(gdb) p/x app_.dac_vals 
$71 = {0x2fd, 0x2fd, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff, 0xffff, 0x0, 0x0, 0x0, 0x0}

req:m20002414,18
W: (05) 84 14 24 00 20
R: (01) 00
20002414 128
W: (02) 88 80
R: (80) fd 02 fd 02 fd 02 fd 02 fd 02 fd 02 fd 02 fd 02 fd 02 fd 02 fd 02 fd 02 ff ff ff ff ff ff ff ff ff ff ff ff 00 00 00 00 00 00 00 00 00 00 00 00 80 00 00 00 54 24 00 20 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00
rpl:+$fd02fd02ffffffffffffffffffffffff0000000000000000#e8


The readout does seem good: 2 vals that should be the same.

fd 02 fd 02 fd 02 fd 02 
fd 02 fd 02 fd 02 fd 02 
fd 02 fd 02 fd 02 fd 02

So probably cache.

Ok was just cache indeed.


Entry: next
Date: Wed Oct  4 06:56:33 AM EDT 2023

I think it's time for a midi sequencer first, then do midi control of
the noise setup via the pixi.

I started on this already, so let's resume.
What I want is some kind of tracker.
http://miditracker.org/

I do not want to learn another program though, or create another
dependency.

I think I want this in language form.

Can't really focus atm...

I need something I can DO.
What can I do?


Entry: midi is so fucking convenient
Date: Wed Oct  4 09:08:46 AM EDT 2023

So let's continue building hub.c as a plugin mechanism.
It's basically going to be the DAW substitute.

And focus on just recording, no editing.
E.g. parameter automation.

I think my abstraction of the problem is too simplistic.
I keep wanting to dodge it.
So maybe continue with the gdbstub work first.

Yeah to get anywhere I need to switch to music mindset.
Maybe do Antti's sequence?



Entry: different workflow
Date: Wed Oct  4 01:12:25 PM EDT 2023

Revisit the reset strategy.

So device reset now works properly with the 5ms PA12<-0 hack.
Jack will reconnect.
The tether app and connected gdb will not notice a reset.

This is actually quite nice.

So I could do this:
- monitor command to restart the chip to bootloader only
- load app via gdb
- monitor command to start app

Only that the pixo board does not have this boot1 switch.

So it's necessary to implement stop.

The "stop" only needs to disable interrupts.  Enough to be able to
Flash and reset.  A hardware reset is probably still a good idea to
make sure the firmware can boot from reset.  So maybe that can be done
generically?


Entry: Just use STLink?
Date: Thu Oct  5 10:58:37 AM EDT 2023

Maybe this is all not necessary?

The main reason to use the USB monitor + gdbstub is to have a way to
access it when there is no alternative.

But, with the USB reset working now, I can just use the stlink.

So let's just do that then.

1. Basic Flashing setup is STLINK, with reset connected properly and
USB reset hack

2. App control is via MIDI + Sysex for some 3if debugging
functionality



( What I think is going on here, is that my brain got a bit warped by
writing these multi-controller applications.  This is not that!  So
don't overcomplicate it.  These old habbits are hard to shake, but
maybe good to do something simple actually. )



Entry: Three sequences
Date: Fri Oct  6 12:53:50 PM EDT 2023

So I have one filter, two VCAs

Let the pixi:
- sync to midi clock & start/stop
- play the sequence
- create a pattern editor on the akai


Entry: localized pattern sequencers
Date: Fri Oct  6 12:54:46 PM EDT 2023

I think the idea of creating a centralized pattern sequencer is just
not a good one.  Not for what I want to do.  So build them into the
devices.


Entry: I want to make art installations
Date: Fri Oct  6 04:19:29 PM EDT 2023

I want to go back to the noise audio and visual.
This means, OpenGL.



Entry: qjackctl
Date: Sat Oct  7 11:24:51 AM EDT 2023

I need an alternative that can display connections on terminal or from
Erlang exo.  Aim for headless.



Entry: pixi.c interrupts
Date: Sat Oct  7 11:43:07 AM EDT 2023

Let's use this firmware to build a basic midi-controlled synth
controller firmware.



Entry: midi electrical
Date: Sat Oct  7 11:55:44 AM EDT 2023


Next up is midi UART in.

At the transmit end:
5V - 220 - (4)
TX       - (5)

I can probably make this work without opto for now.

Just needs a 5V tolerant RX.

But would also be good to have a reference circuit.

Found 6N136

1 NC         8 C PHOTO (VCC)
2 A LED      7 B NPN
3 C LED      6 C NPN
4 NC         5 E NPN (GND)


https://forum.arduino.cc/t/article-arduino-trick-using-a-low-gain-opto-isolator-for-midi/188812

https://lookmumnocomputer.discourse.group/t/6n136-instead-of-6n137-in-midi-circuit/4576


Actually the 6N136 I have are SMD.
Not going to mess with that.

Which RX is 5V tolerant?

Aha. I did find a pack of CNY17-1

Ok it seems to work.
However I do read that these are not fast enough for MIDI.


http://personal.kent.edu/~sbirch/Music_Production/MP-II/MIDI/midi_physical_layer.htm


Turn-off time.

The I_F is   5V through 440Ohm

(/ 5000.0 440) 11 mA

The 20mA turnoff of CNY17-1 is 18uS
The CNY17-2 at 10mA is 23us.

A 31.25kBaud bit is (/ 1000 31.25) 32us

Maybe this is a bit slow indeed.
I do see quite a difference between 2 different devices though.

Let's try to find some other optos.
6N138 is what I find everywhere.

Actuall it looks the same as the old one.  And the delay is
symmetrical with the 1k resistor.

The 0xF8 byte is a 4 bit dip, so should be (* 4 32) 128us, and i
measure 132us, so not quite symmetrical but 4us in a 32us bit is
probably ok.


Entry: what next?
Date: Sat Oct  7 02:20:10 PM EDT 2023

I need start/stop to start sequencing a pattern.

EDIT: This "everything is a sequencer" does seem to be a good
approach.  Especially since I'm really only interested in loops at
this point.




Entry: index?
Date: Sat Oct  7 05:26:41 PM EDT 2023

If I want to do polyrhythm, the phase needs to reflect this.
Maybe keep a couple of phases?

Maybe split patterns and rhythms.



Entry: 2 VCAs
Date: Sat Oct  7 08:58:17 PM EDT 2023

I want to do this the following way:
- figure out which 2 volume knobs make most sense
- replace them with VCAs

Thinking that maybe the level will be a bit too low?

Maybe just try... not clear how to get started.

EDIT: The thing I want to do is to contain it, make it smaller, less
of a global hack.

Analysis paralysis...


Entry: sequencer
Date: Sun Oct  8 09:16:33 AM EDT 2023

Let's stick to what is possible: I have 3 CV signals I can use.

What is the problem that is in the way?

- Setpoints: midi controller to map onto CV signal + transfer
  functions.

- Where to perform the transfer function mapping

- How to represent patterns

- How to represent time/loops.

- State feedback (e.g. console app)


About this RTT thing: It doesn't need to be midi or text.  It can be
the {packet,4} + 2-byte prefix protocol.


So it's clear that the final solution to this will look simple, but to
find it I have to travel a path.  There is no clear next step that
isn't clouded in doubt.



Entry: Let's dream about this other kind of synth
Date: Sun Oct  8 10:41:26 AM EDT 2023

Basically I want to use just digital I/O and maybe some analog
switches to create a noise box.

I think I already had established a way to "mute" a signal, by
drowning it out.

Another possibility is to use the analog inputs as switches to +/-
3v3.



Entry: simple things that just need doing
Date: Sun Oct  8 11:02:49 AM EDT 2023

- clean / dump the connection databases
- decide main controller and map play/stop keys


Entry: map pd and jack
Date: Mon Oct  9 07:43:21 AM EDT 2023

How to map the current jack connectivity to a patch?
It's not going to work well because jack has named ports.
I do need a way to easier manage these...
Can I map it to source?


Entry: gui restarts
Date: Mon Oct  9 07:48:53 AM EDT 2023

How to integrate this better with xmonad?

What I want: specific windows should go to same workspace/location.


Entry: fix the db
Date: Mon Oct  9 07:52:27 AM EDT 2023

When a connection is made: add it.
When a connection is removed (except on shutdown), remove it.




Entry: super dumb pitch detector
Date: Mon Oct  9 07:10:26 PM EDT 2023

Assume squarewave in.  Map every edge to an audio grain + use
subdivision.  This can be done in Pd.

1. Use edges as events: this should keep pitch locked

2. Map the edge density to timbre



Entry: drums for the br2000
Date: Mon Oct  9 09:36:43 PM EDT 2023

make 8 x 3 drums
and top 8 be parameters

only mixes

instead of "volume", use intensity
e.g. longer decay etc.

make a large selection of random sounds
and very simple patterns

this could be samples also



Entry: midi routing
Date: Tue Oct 10 08:55:44 AM EDT 2023

I want a language for midi routing that translates to efficient C.  I
think this is now the most important problem.  Fix the stuff that is
already in hub.c


Entry: Pd extern
Date: Thu Oct 12 12:53:45 PM EDT 2023

...

i also want a wave viewer and a scope
so maybe revive wvvw?


Entry: next
Date: Thu Oct 12 02:27:58 PM EDT 2023

i have all this space
make a step
do the Pd thing

EDIT: doing the Pd thing

Does indeed feel better.  And yes I got annoyed and confused.



Entry: wave viewer
Date: Sat Oct 14 12:21:50 PM EDT 2023

It has been coming up a couple of times.  Would also be nice to
implement the always-on recorder again.  Currently main out is on zoe,
so maybe put it there.  Can I just restore the old code?







Entry: 
Date: Tue Oct 17 06:50:00 PM EDT 2023

Connecting keystation to microbrute in qjackctl.

Oct 17 18:47:46 zoe exo_vm[1266]: exo_midi:jack_notify({client,reg,"qjackctl"})
Oct 17 18:47:59 zoe exo_vm[2101]: assert_write: write(1,0x7f148e74da00,-118) == -1, errno=14, strerror="Bad address"
Oct 17 18:47:59 zoe exo_vm[1266]: =SUPERVISOR REPORT==== 17-Oct-2023::18:47:59.165393 ===
Oct 17 18:47:59 zoe exo_vm[1266]:     supervisor: {local,exo_sup}
Oct 17 18:47:59 zoe exo_vm[1266]:     errorContext: child_terminated
Oct 17 18:47:59 zoe exo_vm[1266]:     reason: {exit_status,1}
Oct 17 18:47:59 zoe exo_vm[1266]:     offender: [{pid,<0.322.0>},
Oct 17 18:47:59 zoe exo_vm[1266]:                {id,jack_daemon},
Oct 17 18:47:59 zoe exo_vm[1266]:                {mfargs,{exo,start_child,[jack_daemon]}},
Oct 17 18:47:59 zoe exo_vm[1266]:                {restart_type,permanent},
Oct 17 18:47:59 zoe exo_vm[1266]:                {significant,false},
Oct 17 18:47:59 zoe exo_vm[1266]:                {shutdown,brutal_kill},
Oct 17 18:47:59 zoe exo_vm[1266]:                {child_type,worker}]
Oct 17 18:47:59 zoe exo_vm[1266]: =SUPERVISOR REPORT==== 17-Oct-2023::18:47:59.165678 ===
Oct 17 18:47:59 zoe exo_vm[1266]:     supervisor: {local,exo_sup}
Oct 17 18:47:59 zoe exo_vm[1266]:     errorContext: shutdown
Oct 17 18:47:59 zoe exo_vm[1266]:     reason: reached_max_restart_intensity
Oct 17 18:47:59 zoe exo_vm[1266]:     offender: [{pid,<0.322.0>},
Oct 17 18:47:59 zoe exo_vm[1266]:                {id,jack_daemon},
Oct 17 18:47:59 zoe exo_vm[1266]:                {mfargs,{exo,start_child,[jack_daemon]}},
Oct 17 18:47:59 zoe exo_vm[1266]:                {restart_type,permanent},
Oct 17 18:47:59 zoe exo_vm[1266]:                {significant,false},
Oct 17 18:47:59 zoe exo_vm[1266]:                {shutdown,brutal_kill},
Oct 17 18:47:59 zoe exo_vm[1266]:                {child_type,worker}]


This goes with a crash in qjackctl (from systemd journal)
Stack trace of thread 1611:
#0  0x00007f9a90f4fbda raise (libc.so.6 + 0x3bbda)
#1  0x00007f9a90f3a533 abort (libc.so.6 + 0x26533)
#2  0x00007f9a914b4c73 _ZNK14QMessageLogger5fatalEPKcz (libQt5Core.so.5 + 0x99c73)
#3  0x00007f9a91aebe5c _ZN22QGuiApplicationPrivate25createPlatformIntegrationEv (libQt5Gui.so.5 + 0x125e5c)
#4  0x00007f9a91aec300 _ZN22QGuiApplicationPrivate21createEventDispatcherEv (libQt5Gui.so.5 + 0x126300)
#5  0x00007f9a916eb495 _ZN23QCoreApplicationPrivate4initEv (libQt5Core.so.5 + 0x2d0495)
#6  0x00007f9a91aef26f _ZN22QGuiApplicationPrivate4initEv (libQt5Gui.so.5 + 0x12926f)
#7  0x00007f9a92591c29 _ZN19QApplicationPrivate4initEv (libQt5Widgets.so.5 + 0x176c29)
#8  0x0000000000441f8b _ZN19qjackctlApplicationC2ERiPPc (.qjackctl-wrapped + 0x41f8b)
#9  0x0000000000439959 main (.qjackctl-wrapped + 0x39959)
#10 0x00007f9a90f3b790 __libc_start_main (libc.so.6 + 0x27790)
#11 0x0000000000439daa _start (.qjackctl-wrapped + 0x39daa)

Some generic stupid questions:
- Why can't I immediately see what process crashes at the Erlang side


I can actually see that:
{id,jack_daemon}

Two questions:
1. it seems the jack daemon itself crashes
2. who is this:  zoe exo_vm[1742]: assert_write: write(1,0x7f8141f80a00,-118) == -1, errno=14, strerror="Bad address"

Just starting a2j and jack separately does not trigger any issue.

The error is weird.
The address and size are junk.
I do want to know who is who...



Entry: something else happened here
Date: Wed Oct 18 01:30:28 PM EDT 2023

Oct 18 13:29:34 zoe exo_vm[1251]: Unknown request 4294967295
Oct 18 13:29:34 zoe exo_vm[1251]: CheckSize error size = 0 Size() = 12
Oct 18 13:29:34 zoe exo_vm[1251]: CheckRead error

this is indicative of a jack version mismatch

after rebuild that is not happening any more
but i still get the crash

Let's find out first which process this is.

Oct 18 13:45:00 zoe exo_vm[8898]: assert_write: write(1,0x7fb1171c6a00,-118) == -1, errno=14, strerror="Bad address"

tom@zoe:~$ cat ps.snapshot |grep 8898
tom         8898  0.0  1.4 183300 116768 ?       SLsl 13:41   0:00 /nix/store/a0ndljxn056h3l3z3wns93am238cyh77-synth_tools/linux/jack_control.dynamic.host.elf jack_control


I'm thinking this triggered just now because the string length!
That char here is signed, should be uint8_t

#define SEND(fmt, ...) {\
        char buf[256];                                                 \
        buf[0] = snprintf(buf+1, sizeof(buf)-1,fmt, __VA_ARGS__);      \
        assert_write(1, (void*)buf, buf[0] + 1);                       \
    }


It's not properly rebuilding it.

Need to fix the underlying problems:

- why is it not rebuilding properly?

- how come i can't see what it is actually building? i do need this
  visual feedback to see if my system is actually working properly.

Ha!
This is the one exception that doesn't reload.
WTF don't make exceptions!



Entry: db updates
Date: Wed Oct 18 05:40:53 PM EDT 2023

How to record a delete?

First, what happens when a processor gets killed / resetarted?

Oct 18 17:43:18 luna exo_vm[88273]: exo_midi:jack_notify({connect,false,"system:capture_2","pure_data:input1"})
Oct 18 17:43:18 luna exo_vm[88273]: exo_midi:jack_notify({connect,false,"pure_data:output0","system:playback_1"})
Oct 18 17:43:18 luna exo_vm[88273]: exo_midi:jack_notify({connect,false,"pure_data:output1","system:playback_2"})
Oct 18 17:43:18 luna exo_vm[88273]: exo_midi:jack_notify({port,unreg,in,"pure_data:input0"})
Oct 18 17:43:18 luna exo_vm[88273]: exo_midi:jack_notify({port,unreg,in,"pure_data:input1"})
Oct 18 17:43:18 luna exo_vm[88273]: exo_midi:jack_notify({port,unreg,in,"pure_data:input2"})
Oct 18 17:43:18 luna exo_vm[88273]: exo_midi:jack_notify({port,unreg,in,"pure_data:input3"})
Oct 18 17:43:18 luna exo_vm[88273]: exo_midi:jack_notify({port,unreg,in,"pure_data:input4"})

So it seems that unreg comes right after the disconnect.  What I want
to catch is a connect,false that is not immediately followed by a port,unreg

I can't think of a way to do this other than using timing.

I think I'm going to need to make a patcher.
Also qjackctl is awkward to use remotely.
So let's get on with it.

Summary:
- don't do timing based solutions. makes it too complicated and error prone
- try to record the actions of the patcher itself, e.g. maybe patch qjackctl?
- write a (universal) patcher, define patches in source files


Entry: It's high time to solve the applicative vs. dataflow issue
Date: Wed Oct 18 05:56:55 PM EDT 2023

The only benefit of dataflow is automatic summing/merging, which might
be a good idea or not depending on context.  Think about this some
more.


Entry: mod_drum.c
Date: Thu Oct 19 11:24:37 AM EDT 2023

Basic idea is to use a software timer to do the sequencing.  This
seems most flexible for algorithmic playback.

What I want is a sequence of CV values to send to the VCA to control
the noise box, so write that in a test first.


Entry: sequencer
Date: Fri Oct 20 08:06:50 AM EDT 2023

The drum sequencer:

- spawn a sequence

- map a CC to set the value of the sequence to edit it in real time

- to not put too much pressure on the timer storage, only store one
  next event for each task.  when executed, this schedules the next
  event

EDIT: Sequencer code made it into the PIXI firmware.  Next up is
probably playing that sequence then?



Entry: step sequencer
Date: Sat Oct 21 08:51:25 AM EDT 2023

Added step sequencer generic state machine on top of the software
timer.  This opens up the following:

Run the sequencer:
- inside the stm
- inside hub.c

The latter might be better.

The core machines are built for ease of implementation, so it makes
sense to write a layer on top of it, e.g. a compiler.




Entry: compiler
Date: Sat Oct 21 09:07:39 AM EDT 2023

Move back to Erlang.

The thing is: I am going to keep relying on Erlang for managing
distributed always-on in-place-editable systems.  I really like that
idea.  So let's make the compiler work, and let's make it play nice
with dialyzer.  I.e. use the language is such a way that dialyzer is
good enough as a type checker.

Alpaca seems to have halted development.

The exo Erlang system is also the only place with a global view to all
dataflow setups.

Ok it's clear: stick with Erlang.
Let's revive the old compiler.

The first real issue is to deal with "app vs. connect"


Entry: app vs connect
Date: Sat Oct 21 10:20:48 AM EDT 2023

App can already do fanout.

The issue is the "automatic merge", which exposes the need for a
list/array operator right away: a summer in the case of audio, and an
event merger in the case of midi.


Entry: revive the music DSL
Date: Sat Oct 21 08:04:53 PM EDT 2023

It should be lisp syntax so it is easy to navigate in emacs.
With a mode that can "tweak" numerical constants by +/-.

kp-add / kp-subtract are separate from +/- on main keyboard.


Entry: next: drum machine
Date: Sat Oct 21 10:46:46 PM EDT 2023

There is a sequencer now, so visualising and controlling it with the
drum controller should be within reach.



Entry: continuing on stm synth core
Date: Sun Oct 22 08:46:42 AM EDT 2023

Things I want:

1. USB midi clock

2. Internal midi clock

Both need software interrupts into the midi task.
This is a bit of work to put the queues in place etc.



Entry: nice
Date: Sun Oct 22 07:28:50 PM EDT 2023

Clocking works.  Patched in the VCA and made some noise.
This is neat really. Thinking about buying more VCA.
But let it sit for a bit.

Doepfer A-130-8 Octal Linear VCA $89
https://www.ebay.com/itm/124308876739

But prob ok to just stick with this for now.  Maybe get a neutron.


What next?
- Find a way to program a pattern with midi controllers
- start/stop doesn't sync properly
- LCD display
- more pots
- CV midi control



Entry: what next for pixi?
Date: Mon Oct 23 08:55:52 AM EDT 2023

- second VCA
- fix start/stop issue
- more midi controls


Entry: that huge mixer
Date: Mon Oct 23 07:29:01 PM EDT 2023

I would like to do something with it.  Create some kind of dedicated
circuit.




Entry: idea: go back to the pulse synth
Date: Fri Oct 27 07:43:16 PM EDT 2023

all outputs are digital, generated from timers.  e.g. just PWM outs.

inputs:
- schmitt triggers, generating EXTI events, changing states.
- ADC

those in and outs are then connected using analog circuitry that is
not digitally controlled, e.g. just pots connected to hi/lo pass filters.

the "mod matrix" is essentially high-Z pwm outputs

basically, "max out the f103"

ideas:
- use SPI clock in to set SPI playback rate of Flash waveform
- use open drain for mixing
- don't use 5V tolerance to keep it simple
- don't mix SPI with ADC inputs, use one dedicated SPI slave
- is it really that useful to have multiple channels for pwm?  doesn't seem so, except for LFO

pin map:

See Table 5. STM32F103x8 data sheet, 48 pin.

Use pins available on blue pill.
Leave one MIDI port and USB port free.

LEFT (reserved)

PA9  MIDI OUT
PA10 MIDI IN

PA11 USB+
PA12 USB-

PA15 NC (JTAG)
PB3  NC
PB4  NC

RIGHT (reserved)
PC13 LED


LEFT (synth)

PB12   EXTI?
PB13   SPI CLK
PB14   SPI MISO
PB15   SPI MOSI
PA8    PWM1,1

RIGHT (synth)

PB11   EXTI?
PB10   EXTI?

PB1,0-A7,6 PWM3,4-1 or ADC (A7,6)
PA5    ADC
PA4    ADC
PA3-0  ADC or PWM2 PWM 1-4
PC15   EXTI?
PC14   EXTI?

So that gives 3 independent PWMs





todo:

- start with a good digital buffer to get rid of CPU noise.  do this
  before going to belgium


All these tap points can go into the larger mixer.

( Alright I think manic mode is over. )



Entry: synchronous PWMs
Date: Fri Oct 27 08:51:00 PM EDT 2023

Does it make sense to make an CV controller where the frequency is
synchronous to the main pitch?

That actually makes a lot of sense.

Mapping for BP:


PB12     EXTI?
PB13-15  SPI noise / sample

PA8      PWM1,1 subosc

PB11,10  EXTI?

PB1,0-A7,6 PWM3,4-1

PA5,4    ADC
PA3-0    ADC or PWM2 PWM 1-4
PC15,14  EXTI?


This gives two oscillators with synchronous, PWM control, one square
PWM and one noise, with some inputs.



Entry: is there any merit?
Date: Fri Oct 27 09:01:40 PM EDT 2023

The idea is to be able to do distortion and filtering.  Distortion is
just schmitt triggering.  Filtering can probably be done using the PWM
control.

Let's look at the mixer idea.  There are 6 sends, which would go to 6
ADC inputs to be used as modulation source.

How many outputs are there?
Let's just use USB for control and get rid of the uart.

27

Minus 6 ananlog in.

21 channels.
That's a lot

There are 20 sliders

So that's really a perfect match.

I need 20 buffers then.

Maybe start a bit smaller.  This is quite ambitious.
I do have that matrix mixer.
But the filtering is essential.



Entry: use a bank of SVFs
Date: Fri Oct 27 09:25:47 PM EDT 2023

Plus gain.  Those will give reasonably wide frequency control, then do
the feedback matrix digitally inside the controller.

So a bank of SVFs and schmitt triggers and a mixer.

What about this: make it pure analog first.  Then make it patchable by
replacing some of the schmitt triggers with either dig->dig or an->dig
ports on the uC.



Entry: how to make this actual
Date: Fri Oct 27 09:42:22 PM EDT 2023

Build it as a modular.  Create a couple of SVF modules and an STM on
the board that was intended for it.



Entry: spirit mixer
Date: Fri Oct 27 09:50:33 PM EDT 2023

it already has 7 outputs: main(2), bus(2), send(3)


Entry: make this thing playable
Date: Sat Oct 28 08:40:00 AM EDT 2023

What I am trying to store is 2 patterns with CV values.
Why not just use keyboard input and record it?



Entry: hard to understand
Date: Fri Nov 10 03:40:00 PM CET 2023

Where is the .pd start file specified?
It is running /i/tom/pd/exo.pd


Entry: synthfest checklist
Date: Fri Nov 10 03:49:38 PM CET 2023

- extension cord to USB2 hub goes in yellow outlet
- fasttrack pro goes in left front USB3 direct, no hub


Entry: next
Date: Fri Nov 10 07:22:29 PM CET 2023

Ok so do the fucking loop sampler.

So what is the next step?
The pad makes most sense as a sample trigger.

Simplify:
- don't use the easycontrol at all
- and why not? don't use the drum thing either


Entry: novation
Date: Fri Nov 10 07:58:19 PM CET 2023

What can I do with just the novation?

Build a song one track at a time.

There are 8 tracks, with volume corresponding to the sliders.

Button under the track is mute.

The pots are one fixed expression parameter per track.  E.g. lowpass.

The rotary encoders are 7 parameters per instrument.
So i do want to make sure that sends out relative.

First thing: midi log.
Basically this should be centralized in the hub.


TODO:
- easily accessible midi event log in hub.c


Entry: this really needs conceptual simplification
Date: Fri Nov 10 08:31:18 PM CET 2023

It all got a bit out of hand...

What I want:

- Everything controllable by commands in i.erl
  This should be a hard constraint.

- tp + novation + ftpro (keep it simple, make sure it works for
  synthfest setup)



Entry: sampler
Date: Fri Nov 10 10:02:00 PM CET 2023

Buld it inside Pd
First make a table loader.

The problem is really the data structures.
So think about that first.

Spend a couple of hours just thinking, imagining how to navigate the structures.

Separate the offline and online structures.
The only part could maybe just be a sample player.

What is the thing that ultimately sits behind a volume slider?
Is it a pd patch?

Can I unify?

If I unify, Pd object seems to be the simplest approach.


But I also want a language to manipulate everything.
That should probably be a lisp, like RAI.  There is revivable support code, emacs etc.

Every component of the system should be editable, so keep doing that.

The basic interface to the store is another language.



So there are really 2 components:
- the store
- the player

While the player is running, i want to be able to manipulate the store.

The store is essentially just a collection of files that is edited in-place.

It really needs to be erlang.

If I want a lisp on erlang I can use LFE.



Entry: more crashes at startup on tethys
Date: Sat Nov 11 11:44:19 AM CET 2023

hub.c dumped core

#0  0x00007f1bb5394e57 kill (libc.so.6 + 0x3be57)
#1  0x0000000000401416 main (clock.dynamic.host.elf + 0x1416)
#2  0x00007f1bb5380790 __libc_start_main (libc.so.6 + 0x27790)
#3  0x000000000040162a _start (clock.dynamic.host.elf + 0x162a)

There are 3 that failed in assert:

Nov 11 11:43:37 tethys exo_vm[79401]: linux/clock.c: 154: ASSERT FAIL: client

Because:

Nov 11 11:43:37 tethys exo_vm[79403]: jack server is not running or cannot be started

It runs now.  Likely because jack was already running.


Entry: pd as proxy?
Date: Sat Nov 11 12:50:35 PM CET 2023

Does it make sense to encode all jack midi connections in Pd?
I really need the uniformity, but I don't think that will really work well.


Entry: i am lost again
Date: Sat Nov 11 12:53:53 PM CET 2023

So Pd runs on tethys.  Let's switch back to tp.
Now I want pd to open on a dedicated display.
Is that possible?

I keep finding these arbitrary points of contention...


Entry: next
Date: Sun Nov 12 09:14:32 AM CET 2023

so indeed, simplification is the way

so what next?
i think the connection db
that currently works but is very awkward to use

anyway, just skip that part. it works.
focus on the novation

next is hub debug
EDIT: that can just be to_erl

next up: make sure the controller data ends up in pd.



Entry: further simplifications
Date: Sun Nov 12 10:23:29 AM CET 2023

The reasons to use jack ports:
- Because I have to, e.g. Pd, a2j
- To split off software that is exposed externally
- To use multiprocessing

For any other music making business, it might be simplest to let Pd
do the hosting.


Entry: libpd
Date: Sun Nov 12 10:26:06 AM CET 2023

Just headless?


Entry: plugdata
Date: Sun Nov 12 10:29:54 AM CET 2023

Pd wrapped as a JUCE plugin.


Entry: actual setup
Date: Sun Nov 12 10:30:43 AM CET 2023

Laptop
FTPro
Remote25

hub.c will process Remote25 input

some knobs are bad

what do i need?
a way to map the CCs to Pd send
I don't want to use routing.

Or do I?

I guess that is the question: use name-based routing or use visual routing.

What would be ideal?
To be able to midi learn.

That might not be necessary.

The unit is the channel / generator.  Per generator there are 2
buttons, 1 slider, 1 knob dedicated, and 7 relative knobs/buttons for
currently selected channel.

So it really just needs 4 + 7 relative addresses.  Probably easy
enough to use visual routing.

Let's just map it to midi.

I would like to figure out first if the rotaries can be incremental.

I can probably fake this.  It's easy enough to see what direction
something is going.  This can then be mapped back to incremental.

So the transformation will be this:

ctrl <chan> <nb> <val>
            0: vol
            1: mute
            2: expr
            3: accent?

buttons are set to momentary


            
Entry: mapping / routing ok
Date: Sun Nov 12 06:38:07 PM CET 2023

Now how to do this at the pd end?

Maybe have a single performance patch that routes and instantiates 8
track patches?

Or just instantiate everything, and have a selection of routing
patches.

I don't know... build something that works.

Before any of that, I want to run Pd on a remote display.  Would
probably be simplest to use raw X instead of ssh.


Entry: summary
Date: Mon Nov 13 10:13:16 AM CET 2023

Routing works.  The next step is to build midi controlled instruments
and sequencers.

To sidestep the instrument question, it's probably best to use samples
at first.

Start/stop is still a pain.  Not just one problem it seems.  Just
things not working properly.  Some clarity would help.

The main problem is that what I want to do is inherently hard: gluing
shit that doesn't have the necessary semantics...



Entry: next
Date: Mon Nov 13 01:43:32 PM CET 2023

Started filling in some things.  It's clear I just need to do a step
then see what's next after.  Can't really plan this.

Next thing I need is a scale adjust.  Map midi 0-127 to some useful
number scale.

EDIT: So took a couple of hours to figure out the x display tcp thing,
but it works now.




Entry: recorder
Date: Mon Nov 13 05:51:49 PM CET 2023

Start out by playing the beat, which starts on t=0 and the last note
is endx.  This gives the time base.

Record everything else on top of that.

So let track 0 be the base rhythm.  Everything else is snapped to the
grid.



sequence:

- enable record
- store each keypress / release event
- disable record
- delete last keypress, use as loop point
- set tempo based on this information



Entry: recorder in erlang?
Date: Tue Nov 14 11:22:45 AM CET 2023

Since I'll be doing some processing, it might be good to keep that
part in Erlang, and keep only the playback code in C.

Problem is overview...

Yes since this is about data, it should be handled somewhere that the
data can easily be manipulated and stored.  That would probably mean
sqlite.

Is it enough to use standard timecode?
Say 30fps frame rate, resolution is 33ms

Seems a bit low.

midi is about 1 command per millisecond.

I think I want an ad-hoc protocol between hub.c and erlang side.

EDIT: Got it to the point:
{record,Msg} where Msg is

start
stop
{on,1308416,0,29,48}
{off,1316160,0,29,71}

{on|off,Timestamp,Track,Note,Vel}

The timestamp is number of samples since record.

So what's next?

Record something and put it in an erlang expect test.
Would be nice to get that going again.

Interface for that would be through exo_vm script.

Two things need to happen:
- A way to upload a pattern to the hub.c pattern sequencer
- Editing the Erlang form of the pattern


test_studio_seq:record().
[start,
 {on,21248,0,36,19},
 {off,29312,0,36,56},
 {on,36480,0,37,22},
 {off,41792,0,37,8},
 {on,51072,0,42,40},
 {off,56448,0,42,36},
 {on,62976,0,36,61},
 {off,68864,0,36,61},
 stop]

EDIT: I think i'm going to use the stop as a loop point instead.
EDIT: No that's just really awkward.  Use the last note.

It's necessary to hear it

What about this:
- Turn off record, at the first next note, play the pattern.



Entry: random shit going wrong
Date: Tue Nov 14 02:52:04 PM CET 2023

debugging is still hard
now totally unexplained, no sound.

restarted it, switched config to 44.1kHz
now i get something distorted

and now it seems to run ok

this is weird...



Entry: replug everything
Date: Tue Nov 14 03:14:27 PM CET 2023

I want to get to a point where I can unplug the audio interface and
everything shuts down, and i replug it and everything starts up again.



Entry: pattern
Date: Tue Nov 14 03:24:14 PM CET 2023

Take a break...  Going the right way.



Entry: next
Date: Tue Nov 14 05:23:54 PM CET 2023

I think I know what I want.  First note after record sets the loop
point.

No.  Use the record button to loop.

I think this might be simpler to do as a C state machine.


Entry: next
Date: Tue Nov 14 07:56:36 PM CET 2023

Another way to do it is to play it twice.
That way averaging can be used also.

I like that idea.  Keeps it more uniform.

So it seems I'll be writing a loop processor.  A thing that takes
loops and processes them.


Entry: a split loop
Date: Tue Nov 14 11:51:55 PM CET 2023

(exo@tp.zoo)32> test_studio_seq:t().
test_studio_seq:t().
{466,
 [{0,{0,on,36,19}},
  {105,{0,off,36,56}},
  {212,{0,on,37,22}},
  {299,{0,off,37,8}}]}

That's basically it.

From this,
1. the sequencer's timing can be set, assuming say 1/2 bar loops, and
2. this can then be rebased to midi grid: 24 ticks per quarter note



One thing is clear: relative time encoding is a pain.  So just pay the
price of an extra subtraction and keep the pattern flat?

EDIT: That conflicts with the ability to insert void events if the
time difference exceeds the timer range.  So keep it like this in the
implementation.

Sidetrack: where is the "iterate state over a list" thing?

Edit: simpler to just use zip and list tail/drop etc...

I think this would work:

(exo@tp.zoo)68> test_studio_seq:t().
test_studio_seq:t().
#{pattern =>
      [{{event,{0,on,36,19}},{delay,105}},
       {{event,{0,off,36,56}},{delay,107}},
       {{event,{0,on,37,22}},{delay,87}},
       {{event,{0,off,37,8}},{delay,167}}],
  seq =>
      {466,
       [{0,{0,on,36,19}},
        {105,{0,off,36,56}},
        {212,{0,on,37,22}},
        {299,{0,off,37,8}}]}}


So the next thing here is to change the pattern sequencer in hub.c to
allow for encoding of these events.

Next:
- rebase on top of midi clock instead of absolute
- add representation of events + port encoding to hub.c


Entry: ports and channels
Date: Wed Nov 15 12:05:19 PM CET 2023

The distinction is just implementation so should probably be hidden as
much as possible, but I already have a tension between port names and
port numbers.

So maybe tackle that first.

Or not.  It can be hardcoded for now.

What is important though is to set up an interface for the sequencer.
This could use TAG_U32


Entry: storage model for midi sequence
Date: Wed Nov 15 12:11:14 PM CET 2023

I want to be able to run this on an f103 so keep it simple.

Currently the pattern step just has 16 bits for an event.

struct pattern_step {
    /* Do event, then wait for delay ticks. */
    uint16_t event;
    uint16_t delay;
};

It seems best to use a separate allocator for events, e.g. a free
stack.



Entry: sequencer memory allocation
Date: Wed Nov 15 01:14:04 PM CET 2023

It seems best to use a single pool of events shared by multiple
patterns.  Each step then contains a pointer to the next event.  Those
can then just be linked in a loop.

EDIT: Alright I have a step pool.

Now, is it necessary to have a sequence pool?  Or can this just go
into the timer directly?

E.g. timer event could point to the step index, which can then just
loop around.



Entry: sequencer pattern state
Date: Wed Nov 15 02:28:34 PM CET 2023

I think I just made a big change.  The sequencer tasks do not have
(variable) state, only the global sequencer context.  The patterns
should be enough to make this work really.  So let's move that to its
conclusion.

Alright changed the base representation.  Everything is indexed (no
pointers), and the application provides the event dispatch function.

Next: how to create/edit patterns?

The start of the pattern is registered separately, so it's always
possible to edit it from there.

EDIT: Patterns now have:
- start (resume at last->next)
- drop (delete all events from a pattern)
- add (add a single event at the end of a pattern)

So what next?
- on record->off post-process the recording into a pattern cycle
- convert it to binary command
- implement binary command interface (TAG_U32?)

So it seems the first thing is that command interface.

Let's not re-invent the TAG_U32 thing.  A lot of thought went into it,
and it solves an actual problem, so just reuse.



Entry: loop config
Date: Wed Nov 15 05:09:17 PM CET 2023

press record
press play to announce the number of notes = n
play the n notes followed by the last one

pattern will start looping

so this is only for the initial pattern
all the rest of the recording will be against the other time base

then it's also clear that if play is pressed at all when record is on


Entry: record mmc?
Date: Wed Nov 15 05:19:30 PM CET 2023

remote 25 can be set to mmc
how does that effect record?



Entry: what to fix before leaving?
Date: Thu Nov 16 10:48:30 AM CET 2023

the recorder would be nice.  not sure if that can be done already.
maybe just context switch into different hardware.



Entry: recorder rebase
Date: Thu Nov 16 03:09:00 PM CET 2023

EDIT: Ok was straightforward


Entry: tag_u32
Date: Thu Nov 16 04:46:12 PM CET 2023

That's the next thing on the list.
Started putting a handler in hub.c

EDIT: I think I have something that should be able to list a
directory.  So next is to add the Erlang support for this.

Probably tag_u32:dir/1 is the place to start.

tag_u32:dir(i:hub()).

That hangs.
But it's a start.

Move forward a bit.  I get a TAG_U32 packet back in jack_client.erl
Looking at lab_board.erl which has a handler calling:
tag_u32:req_u32_reply(Tag, Rest, BTail);

How does that function know where things go?

The call works like this:

call(Pid, Path, Bin) ->
    %% FIXME: Later, use only resolved paths.
    NPath = resolve(Pid, Path),
    %% log:info("tag_u32:call ~p~n", [{Path,Bin}]),
    obj:call(Pid, {req_u32, NPath, Bin}, 2000).

If Pid doesn't know about req_u32 what then?

Ok so jack_client has the tag_u32 mixing.

Ok so I don't actually need to handle it then?
The mixin should be handling the TAG_U32

EDIT: There was a catch-all before the mixing handler.
Seems to work now:

(exo@tp.zoo)100> tag_u32:dir(i:hub()).
tag_u32:dir(i:hub()).
{[{testcmd,cmd}],#{}}

Entry: the actual tag_u32 calls
Date: Thu Nov 16 08:44:32 PM CET 2023

- clear pattern
- add event to pattern
- set tempo


Entry: calls in place
Date: Fri Nov 17 09:23:17 AM CET 2023

(exo@tp.zoo)8> tag_u32:call(i:hub(),[pat_clear, 1])
{[0],<<>>}

Nov 17 09:22:31 tp exo_vm[480231]: FIXME: clear pattern nb = 1

next: make the events numeric.
E.g. combine track and note on/off into midi byte, use track as channel.

Alright the compiler is ready.  Needs just testing.

But first I want to fix compilation messages.


Entry: refactor 
Date: Fri Nov 17 02:40:29 PM CET 2023

- test_studio_seq.erl move routines into studio_seq
- compile to tag_u32 sequence
- send tag_u32


Entry: next
Date: Sun Nov 19 01:05:15 PM CET 2023

- shift to raw events in add() DONE

- actually play the sequence

The latter needs to be implemented still, but is straightforward.
Best to do that in Neerpelt.

Anything else on the train?



Entry: next
Date: Sun Nov 19 04:29:00 PM CET 2023

- proper start/stop of jack
- make a single solution for pulse + jack  (= always use dedicated card)


Entry: synchronous start / stop
Date: Mon Nov 20 09:44:13 AM CET 2023

First: one tension point that is hard to resolve: should the Erlang
processes that wrap an external Linux process be just not running, or
running with a state that indicates off?

Can wait.  More important is to have a synchronous start for Pd.

Also starting to think that it might be better to use a Pd external to
perform the linkage to midi.

Another question: can libpd open a gui?
Seems like this is too much to absorb at once.

Ok I'm lost.

Where to start?  There is no full plan.




Entry: data structure tweaks
Date: Mon Nov 20 11:11:04 AM CET 2023

I think the add pattern is not adding the start to the timer.
This needs to be changed somehow.

It's not possible to delete events from the timer queue.  So maybe it
is best to mark the event for deletion instead?

I am running into a lot of issues with this simple model.

What do I want to do?  Find an event in the timer and cancel it.

Actually it might be simpler.  Delete loop can be implemented as:
break loop + push to freelist.  But that does not solve the issue.

It can be solved with indirection.  Instead of linking.


Two changes:
- O(1) loop delete
- Indirection of next pointer.

This way a loop can be changed on the fly: the currently scheduled
event will just play the currently recorded event (separate).

EDIT: that seems to work.  next step is to fix the player.

Problem is that I do not know if an event is started already: it's not
ok to start it twice.

Yeah this data structure is tricky to maintain....

Maybe each loop should just be running from the start already?
I.e. there are no empty loops.


What about this: there is always a "rest" at the end to act as a
sentinel.

( I really cannot focus on this. )

It seems best to keep different invariants: all patterns are always
active, or there is a flag that indicates whether a pattern is active
or not.

Maybe, now that deletion is O(1), this could be managed in the update.

E.g. if a pattern is marked for deletion, its next pointer will be
removed.  Then when it is scheduled it can be deleted.

Best to also keep a freelist for patterns.


Entry: new invariant
Date: Mon Nov 20 01:39:31 PM CET 2023

- an allocated pattern is started
- deletion is lazy: on next schedule, there is no reschedule

EDIT: did some refactoring
i'd really like this to work

next: lazy delete

then everything should just work if a pattern is scheduled when it is
created



Entry: sequencer update
Date: Tue Nov 21 03:31:45 PM CET 2023

i think this might be too hard to manage

one issue i have is the scheduling of events when creating a pattern.

EDIT: i think i have something that would work.  next is to actually
integrate.

EDIT: it is very hard to look past this.  why is that?  more issues to
come?


Entry: sequencer
Date: Wed Nov 22 09:53:49 AM CET 2023

why is it so hard to focus on this?
maybe because i really think it is pointless?

recording additional events is a different problem

maybe work on that

yeah this is not trivial

first problem: where to put the code?

i think it makes sense to do it in Erlang, and leave the C code for
just playback and basic data structure manipulation.

alright... what came out of algebraic manipulation is this:

- initialize the loop with an empty event containing the total duration

- then on each new event patch the last duration and spill the rest
  into the new note


EDIT: I have a test

What next?

Transition from recording to playback.


After recording the last event, the player automatically resumes.
Maybe modify the first event in-place?

Maybe not necessary.

Start by scheduling the first event after a full cycle delay.

Now what is missing?  Stuck again at not really wanting to try to be
disappointed.

EDIT: I think I have what I need to make actual recording work.  Just
missing the energy.



Entry: next
Date: Wed Nov 22 04:06:58 PM CET 2023

Time to just play I guess.


Entry: maybe take a break from the synth
Date: Thu Nov 23 10:42:24 AM CET 2023

Because I don't know... It feels all so random, so hard to plan.
Too much reliant on observation and changing my mind.

Ha

Maybe it is the right thing then!


So, on with it.


Entry: Actually finish up to recording
Date: Thu Nov 23 10:43:48 AM CET 2023

Time to get over the hump.

The offline recorder should use the same mechanism as the online one:
allocate new pattern in the cursor, push new events to it.

Also should start out with pattern length.


Entry: split it up
Date: Thu Nov 23 11:29:04 AM CET 2023

Nov 23 11:28:40 tp exo_vm[308696]: Tape=[{19840,{9,0,60,29}},
Nov 23 11:28:40 tp exo_vm[308696]:       {26752,{8,0,60,35}},
Nov 23 11:28:40 tp exo_vm[308696]:       {33664,{9,0,66,48}},
Nov 23 11:28:40 tp exo_vm[308696]:       {40768,{8,0,66,8}},
Nov 23 11:28:40 tp exo_vm[308696]:       {48768,{9,0,66,44}},
Nov 23 11:28:40 tp exo_vm[308696]:       {57344,{8,0,66,2}},
Nov 23 11:28:40 tp exo_vm[308696]:       {59328,{9,0,60,33}},
Nov 23 11:28:40 tp exo_vm[308696]:       {68800,{8,0,60,25}},
Nov 23 11:28:40 tp exo_vm[308696]:       {74240,{9,0,66,19}},
Nov 23 11:28:40 tp exo_vm[308696]:       {82560,{8,0,66,8}},
Nov 23 11:28:40 tp exo_vm[308696]:       {90304,{9,0,66,44}},
Nov 23 11:28:40 tp exo_vm[308696]:       {97216,{8,0,66,58}}]

I got to the point where the program is sent to hub.c but then it
crashes and I can't see what is happening.

1. How to attach a debugger?

2. Do something simpler: start it up with a generated pattern

In gdb process is exiting normally.
It seems to crash here:
reason: {timeout,2000,{req_u32,[4294967295,2],<<"restart">>}}



Entry: attaching gdb
Date: Thu Nov 23 11:31:11 AM CET 2023

tom@tp:~$ ps aux|grep hub
tom       871492  0.5  0.7 182760 117204 ?       SLsl 11:30   0:00 /i/exo/synth_tools/linux/hub.dynamic.host.elf

tom@tp:/i/exo/synth_tools/linux$ gdb hub.dynamic.host.elf
(gdb) attach 871492



Entry: debugging
Date: Thu Nov 23 12:20:12 PM CET 2023

I think it's not receiving clocks.
Check that first.
Then print the patterns.


Entry: usability
Date: Thu Nov 23 01:30:34 PM CET 2023

On train.  Jack running but FTPro is not plugged in.
Trying restart.

There is no clean restart functionality.


Entry: start/stop
Date: Thu Nov 23 01:38:48 PM CET 2023

I think the mistake is entirely in not making this synchronous.

1. Start/Stop should be idempotent
2. After starting, the daemon is up.
3. After stopping the daemon is down and can be started again.

The synchronous process is necessary because start/stop is not atomic:
there is an intermediate state where side-channels (Jack connections
e.g.) might not work yet.

I think that is the big lesson here when managing daemons using redo
dependency management.

Then second: to manage restarts, the _value_ of a daemon must change.
For wrapped daemons this should be the value of the managed (Linux)
process, not the Erlang.

The port handler is probably enough.


(exo@tp.zoo)264> jack_daemon:start(i:jack()).
{ok,#Port<0.4297>}

So change the redo rule as well.

EDIT: Done


Entry: robustness
Date: Fri Nov 24 09:20:59 AM CET 2023

I still get jack daemons that are not stopped properly. Maybe add a
probe before starting to indicate that a daemon is running already,
then take the time to kill it?

But overall this is an improvements.


Entry: next
Date: Fri Nov 24 09:23:04 AM CET 2023

TODO: Push a simple pattern to the sequencer, and verify that it is
actually playing.

Alright I was going to change pat_add to a local context, i.e. use the
cursor.

EDIT: Done

It is now making it to the play function:

Nov 24 11:53:09 tp exo_vm[955034]: pattern 0
Nov 24 11:53:09 tp exo_vm[955034]: step 3
Nov 24 11:53:09 tp exo_vm[955034]: pat_tick 00 80 42 1c
Nov 24 11:53:09 tp exo_vm[955034]: tick time=996
Nov 24 11:53:09 tp exo_vm[955034]: pattern 0
Nov 24 11:53:09 tp exo_vm[955034]: step 4
Nov 24 11:53:09 tp exo_vm[955034]: pat_tick 00 90 42 1c

Next: make sure this goes to the pd output.

EDIT: ok works. cleaned it up a bit.


Entry: next
Date: Fri Nov 24 03:54:51 PM CET 2023

Next step is context switch into building some sounds.  Not sure if I
can do that right now, but maybe interesting to do with the kids.  Nah
it's finished...


Entry: next
Date: Sun Nov 26 08:30:37 AM CET 2023

So next is polish, and building some instruments and effects.

It still doesn't start up right.
Many details still not ok.

It seems to not connect when the hub comes up.


Entry: The other daemons
Date: Sun Nov 26 08:44:39 AM CET 2023

Maybe they should also be managed by redo.
Because I think I have a case where one of them is not starting properly.

Or maybe because the port process is no longer started automatically,
this doesn't work well?

Ok do it like this: at jack daemon start, it starts the required jack
clients, but also make a redo rule for these.

Indeed: control is not running.


Entry: why is control client different?
Date: Sun Nov 26 08:56:25 AM CET 2023

The main problem in managing this stuff is the non-uniformity.  Maybe
time to make the control client int a normal jack_client.

Actually there are two:

            %% Upstream alsa to jack midi bridge
            a2jmidid -> jack_a2jmidid:start_link(#{});

            %% RPC jack interface
            control ->
                jack_control:start_link(
                  #{client => "studio_control",
                    notify => Notify
                   })


What I want: all jack clients are supported by jack_client.erl

If there are binaries that use a different protocol, let's figure out
how to wrap that in jack_client.erl



Entry: unify jack_client
Date: Sun Nov 26 09:01:49 AM CET 2023

a2jmidid uses just the line protocol

what about this: since we are using socat anyway to allow
exit-on-input-close, let's build something that speaks tag protocol

there is already pd.c to get inspired by
but that is mostly doing something else

i really need just a small socat-like thing

let's call it exec

EDIT: draft ready


Entry: unify i.jackd and jackd.local
Date: Sun Nov 26 09:58:20 AM CET 2023

I don't remember why these are split up, but they should be the same.

Start by removing the a2j stuff, turn it into a proper jack client.



Entry: jack_control
Date: Sun Nov 26 03:19:22 PM CET 2023

First, change it to {packet,4}.

Actually, instead move the functionality to hub.c

I'm actually thinking about moving clock.c into hub.c as well.
There is just no need to microserverize everything.

And maybe it's best to clone the behavior of a2jmidid as well instead.
The 1-1 map is already an indication.

But let's do this with jack_control first.

The jack callbacks have been added to hub.c
It already used pterm so this is easy.

The connect is different:

                char *src = &buf[1];
                char *dst = src + strlen(src) + 1;
                // LOG("connect %s %s\n", src, dst);
                switch(buf[0]) {
                case CMD_CONNECT:
                    jack_connect(client, src, dst);
                    break;
                case CMD_DISCONNECT:
                    jack_disconnect(client, src, dst);
                    break;
                }

This needs to be embedded in a tag protocol.
Preferably tag_u32

Ok done.

Next is to replace this from jack_control.erl:
handle({Port,{data, Data}}, State = #{ port := Port, notify := Notify }) ->
    Notify(Parsed),
...

The notify is passed to jack daemon, so maybe simplest that jack
daemon uses its hub client reference to forward this.

Getting lost in arbitrary connectivity shit...

Think about this for a bit.  There are more of these "where's the
other process" problems.


Entry: global structure
Date: Sun Nov 26 04:30:19 PM CET 2023

Yeah maybe it's just time to stop for today.


Entry: next
Date: Mon Nov 27 11:10:21 AM CET 2023

Find the other process.  That's a deep one.

Maybe it can be avoided.
The notify -> connect path is in the same object (jack_client of hub.c)
What's not there is the data that is used to do the mapping.

It seems that this mapping will have to happen in jack_daemon.

So jack_client hub.c can send to jack_daemon, and jack daemon can send
back to hub.c

Notify is exo_midi:jack_notify/1

Which uses:

    Connect = 
        fun(Src,Dst) ->
                jack_control ! {connect, Src, Dst},
                ok
        end,

So that can already change to

exo:need({jack_client,<<"hub">>}) ! {connect, Src, Dst}.


I need a break.
It's getting worn out.



Entry: things just keep going wrong in weird ways
Date: Mon Nov 27 02:27:35 PM CET 2023

A new thing: 100% cpu usage in beam.smp

I might have introduced an infinite loop

It seems fine after doing another pull (and editing some irrelevant
things).

Yeah no idea what this was.  Transition issue?


Entry: next
Date: Mon Nov 27 03:20:18 PM CET 2023

- multitrack recording
- save recordings
- rotation etc...
- more pd patches

What's first?

You know.  Today is not a day to do overview stuff.
Any details to work out?





Entry: get to the point
Date: Tue Nov 28 04:19:19 PM CET 2023

1. Use at least two instruments.

2. Really work on making things easier to develop and test.
Distributed systems that crash are a huge pain. Was thinking about
reviving expect tests, but that does seem like a distraction.

3. Dump the state



Entry: state dump
Date: Tue Nov 28 05:46:28 PM CET 2023


Nov 28 17:45:29 tp exo_vm[1311780]: pattern 0:
Nov 28 17:45:29 tp exo_vm[1311780]:   00 90 3c 47 10
Nov 28 17:45:29 tp exo_vm[1311780]:   00 80 3c 1f 7
Nov 28 17:45:29 tp exo_vm[1311780]:   00 90 42 13 8
Nov 28 17:45:29 tp exo_vm[1311780]:   00 80 42 16 11
Nov 28 17:45:29 tp exo_vm[1311780]:   00 90 42 11 7
Nov 28 17:45:29 tp exo_vm[1311780]:   00 80 42 05 5
Nov 28 17:45:29 tp exo_vm[1311780]: pattern 1:
Nov 28 17:45:29 tp exo_vm[1311780]:   00 90 3c 47 11
Nov 28 17:45:29 tp exo_vm[1311780]:   00 90 42 4f 2
Nov 28 17:45:29 tp exo_vm[1311780]:   00 80 3c 30 5
Nov 28 17:45:29 tp exo_vm[1311780]:   00 80 42 47 7
Nov 28 17:45:29 tp exo_vm[1311780]:   00 90 42 35 5
Nov 28 17:45:29 tp exo_vm[1311780]:   00 80 42 4f 7
Nov 28 17:45:29 tp exo_vm[1311780]:   00 90 42 4f 5
Nov 28 17:45:29 tp exo_vm[1311780]:   00 80 42 6f 6


Entry: confused
Date: Tue Nov 28 07:15:27 PM CET 2023

It's hard to simplify this.

Maybe it is better to just keep it all in C, inside the same binary.



Entry: recorder locking
Date: Tue Nov 28 07:39:32 PM CET 2023

the real problem here is that I want to run an iterator over the data
structure in the low-priority message handling thread, and not have
that interfere with what happens in the RT thread.

so it would probably make sense to somehow lock the data structure:
playback is still possible when a pattern is dumped, but record is not
allowed.  all ofline pattern processing would do the same.


come back to the fundamental tension: use multiple statements and
transactions lock/unlock, or use larger data structures and atomic
messages.



Entry: binary tag_u32 rpc
Date: Tue Nov 28 10:36:50 PM CET 2023

Works for list of patterns and pattern steps.

EDIT: got same interface for save and load


Entry: implement full save and load
Date: Wed Nov 29 09:55:39 AM CET 2023

This is really so much work...
Mostly trying to figure it out, reworking.

Let's wait with load and save until the very basics work.

The "bootstrap recorder" is implemented, at least almost.
But that is not the most important one.


Entry: online recording
Date: Wed Nov 29 10:35:36 AM CET 2023

How to make that work?
Sequencer is playing.

Ah!

If sequencer is not playing, use the bootstrap sequencer recorder.
If it is playing, use the online recorder.

It's hard to keep the idea in the head...



What do I want?

I want it to behave as an infinite tape where I can just add events.

That won't work in my setup, so I can make finite segments, and
discard them if they are empty.

Press record: it will initialize a sequence.

There will be a "start of loop" event that will create a new sequence
if record is still on.  If the previous sequence was empty it can be
re-used.

If record is pressed off again, the current sequence is finalized.
Deleted if empty.



Entry: is that it?
Date: Wed Nov 29 10:55:00 AM CET 2023

See algo previous post.
Let's try.

EDIT: Seems to work.


Entry: next
Date: Wed Nov 29 02:00:15 PM CET 2023

There are still some bugs transitioning between things.
And still startup issues after crash.  Some lingering state.
I really do not like the record button state.

So, first the bugs
- i see app_play twice DONE
- stop after recording crashes


Nov 29 14:09:11 tp exo_vm[1363188]: fd  0: EOF
Nov 29 14:09:11 tp exo_vm[1237292]: =ERROR REPORT==== 29-Nov-2023::14:09:11.055059 ===
Nov 29 14:09:11 tp exo_vm[1237292]: Error in process <0.4409.16> on node 'exo@tp.zoo' with exit value:
Nov 29 14:09:11 tp exo_vm[1237292]: {{badmatch,[]},
Nov 29 14:09:11 tp exo_vm[1237292]:  [{studio_seq,split_loop,1,[{file,"/i/exo/src/studio_seq.erl"},{line,18}]},
Nov 29 14:09:11 tp exo_vm[1237292]:   {jack_client,handle_proc,2,[{file,"/i/exo/src/jack_client.erl"},{line,167}]},
Nov 29 14:09:11 tp exo_vm[1237292]:   {serv,receive_loop,2,
Nov 29 14:09:11 tp exo_vm[1237292]:         [{file,"/build/erl_tools-exo/src/serv.erl"},{line,203}]}]}
Nov 29 14:09:11 tp exo_vm[1237292]: =SUPERVISOR REPORT==== 29-Nov-2023::14:09:11.055123 ===
Nov 29 14:09:11 tp exo_vm[1237292]:     supervisor: {local,exo_sup}
Nov 29 14:09:11 tp exo_vm[1237292]:     errorContext: child_terminated
Nov 29 14:09:11 tp exo_vm[1237292]:     reason: {{badmatch,[]},
Nov 29 14:09:11 tp exo_vm[1237292]:              [{studio_seq,split_loop,1,
Nov 29 14:09:11 tp exo_vm[1237292]:                           [{file,"/i/exo/src/studio_seq.erl"},{line,18}]},
Nov 29 14:09:11 tp exo_vm[1237292]:               {jack_client,handle_proc,2,
Nov 29 14:09:11 tp exo_vm[1237292]:                            [{file,"/i/exo/src/jack_client.erl"},{line,167}]},
Nov 29 14:09:11 tp exo_vm[1237292]:               {serv,receive_loop,2,
Nov 29 14:09:11 tp exo_vm[1237292]:                     [{file,"/build/erl_tools-exo/src/serv.erl"},{line,203}]}]}
Nov 29 14:09:11 tp exo_vm[1237292]:     offender: [{pid,<0.4409.16>},
Nov 29 14:09:11 tp exo_vm[1237292]:                {id,{jack_client,<<"hub">>}},
Nov 29 14:09:11 tp exo_vm[1237292]:                {mfargs,{exo,start_child,[{jack_client,<<"hub">>}]}},
Nov 29 14:09:11 tp exo_vm[1237292]:                {restart_type,permanent},
Nov 29 14:09:11 tp exo_vm[1237292]:                {significant,false},
Nov 29 14:09:11 tp exo_vm[1237292]:                {shutdown,brutal_kill},
Nov 29 14:09:11 tp exo_vm[1237292]:                {child_type,worker}]
Nov 29 14:09:11 tp exo_vm[1237292]: =SUPERVISOR REPORT==== 29-Nov-2023::14:09:11.055396 ===
Nov 29 14:09:11 tp exo_vm[1237292]:     supervisor: {local,exo_sup}
Nov 29 14:09:11 tp exo_vm[1237292]:     errorContext: shutdown
Nov 29 14:09:11 tp exo_vm[1237292]:     reason: reached_max_restart_intensity
Nov 29 14:09:11 tp exo_vm[1237292]:     offender: [{pid,<0.4409.16>},
Nov 29 14:09:11 tp exo_vm[1237292]:                {id,{jack_client,<<"hub">>}},
Nov 29 14:09:11 tp exo_vm[1237292]:                {mfargs,{exo,start_child,[{jack_client,<<"hub">>}]}},
Nov 29 14:09:11 tp exo_vm[1237292]:                {restart_type,permanent},
Nov 29 14:09:11 tp exo_vm[1237292]:                {significant,false},
Nov 29 14:09:11 tp exo_vm[1237292]:                {shutdown,brutal_kill},
Nov 29 14:09:11 tp exo_vm[1237292]:                {child_type,worker}]






Entry: idea
Date: Wed Nov 29 02:09:47 PM CET 2023

If the last pattern stays referenced, so I can implement delete.
-> better to just use the akai

Entry: 
Date: Wed Nov 29 03:14:06 PM CET 2023

- integrate the akai?
- delete / mute pattern?


Entry: akai
Date: Wed Nov 29 03:15:15 PM CET 2023

display led for new pattern
colors for track codes
pulse the events
later implement merge


Entry: cleanup
Date: Wed Nov 29 03:18:45 PM CET 2023

remove superfluous event interface
first test pattern load/save


Entry: next
Date: Wed Nov 29 03:47:26 PM CET 2023

would be nice to use the akai

so how do i make this work?

whenever hub.c sees the akai arriving, it should send an init sequence
clearning the display, then loading pattern information.



Entry: bugs
Date: Wed Nov 29 04:03:26 PM CET 2023

- don't store empty patterns


Entry: next
Date: Wed Nov 29 04:33:59 PM CET 2023

- continue refactor akai_fire.c
- move it into hub.c

what is nice about this: the difficult part is done, which is
timekeep.  the rest should just be mirroring state on the akai.


Entry: confused now
Date: Wed Nov 29 07:34:12 PM CET 2023

Startup issues again after integrating the akai code.  It doesn't seem
to actually start.  Also missing a good synchronization point to start
it up.  This requires some focus.  Not really focused right now.

Maybe do something else first: make sure the offline recorder still
works.


Entry: fire update is happening too late
Date: Wed Nov 29 08:23:10 PM CET 2023

So let's do it manually for now.
Ok it seems that the data just doesn't arrive.


Entry: wtf moment
Date: Wed Nov 29 08:47:46 PM CET 2023

1. a2jmidid seems to crash
2. nothing making it to the akai midi output

wtf => take a break

wondering if ocnecting loops in jack is illegal?

hyp: the input buffer _is_ an output buffer, and if it's read before
it's written and there is feedback, then this doesn't work.

i think i just proved or at least demonstrated that is what is going
on: fire_out -> z_debug: nothing showed up if this was read fore
fire_out was written

if this is the case, we have a problem. "gui controllers" won't work
well.

EDIT: There has to be documentation about this.  Maybe best to ask on
IRC.

Maybe it is best to use them as alsa ports only.





Entry: Date: Wed Nov 29 10:21:17 PM CET 2023

restarting hub is problematic because it is used to connect the graph
that might be where some retart weirdness comes from


Entry: jack question
Date: Thu Nov 30 08:29:20 AM CET 2023

hi. is it legal to create midi loops in a client graph? i'm using
jackdmp 1.9.19 with a2jmidid version 9. i'm writing code for the akai
flstudio fire midi controller that has connections from my client to
a2jmidid in both directions, one direction to receive button presses,
one direction for button color control etc. getting strange behavior
where the data to the midi controller (via a2jmidid) doesn't seem to
arrive, while i can see it coming out of the jack port of my
application. started wondering whether loops are actually allowed...


anyay, i would be surprised if it is not allowed.

is this the reason that midi buffers are not not cleared by default
maybe?  that way it would automatically "insert delays" in cycle
situations.

ha!

Nov 29 22:36:50 tp exo_vm[1452268]: sysex: f0 47 7f 43 65 02 00 00 00 00 00 01 00 00 00 02 00 00 00 03 00 00 00 04 00 00 00 05 00 00 00 06 00 00 00 07 00 00 00 08 00 00 00 09 00 00 00 0a 00 00 00 0b 00 00 00 0c 00 00 00 0d 00 00 00 0e 00 00 00 0f 00 00 00 10 00 00 00 11 00 00 00 12 00 00 00 13 00 00 00 14 00 00 00 15 00 00 00 16 00 00 00 17 00 00 00 18 00 00 00 19 00 00 00 1a 00 00 00 1b 00 00 00 1c 00 00 00 1d 00 00 00 1e 00 00 00 1f 00 00 00 20 00 00 00 21 00 00 00 22 00 00 00 23 00 00 00 24 00 00 00 25 00 00 00 26 00 00 00 27 00 00 00 28 00 00 00 29 00 00 00 2a 00 00 00 2b 00 00 00 2c 00 00 00 2d 00 00 00 2e 00 00 00 2f 00 00 00 30 00 00 00 31 00 00 00 32 00 00 00 33 00 00 00 34 00 00 00 35 00 00 00 36 00 00 00 37 40 40 40 38 40 40 40 39 40 40 40 3a 00 00 00 3b 00 00 00 3c 00 00 00 3d 00 00 00 3e 00 00 00 3f 00 00 00 f7
Nov 29 22:36:50 tp exo_vm[1452268]: z_debug: f0 47 7f 43 65 02 00 00 00 00 00 01 00 00 00 02 00 00 00 03 00 00 00 04 00 00 00 05 00 00 00 06 00 00 00 07 00 00 00 08 00 00 00 09 00 00 00 0a 00 00 00 0b 00 00 00 0c 00 00 00 0d 00 00 00 0e 00 00 00 0f 00 00 00 10 00 00 00 11 00 00 00 12 00 00 00 13 00 00 00 14 00 00 00 15 00 00 00 16 00 00 00 17 00 00 00 18 00 00 00 19 00 00 00 1a 00 00 00 1b 00 00 00 1c 00 00 00 1d 00 00 00 1e 00 00 00 1f 00 00 00 20 00 00 00 21 00 00 00 22 00 00 00 23 00 00 00 24 00 00 00 25 00 00 00 26 00 00 00 27 00 00 00 28 00 00 00 29 00 00 00 2a 00 00 00 2b 00 00 00 2c 00 00 00 2d 00 00 00 2e 00 00 00 2f 00 00 00 30 00 00 00 31 00 00 00 32 00 00 00 33 00 00 00 34 00 00 00 35 00 00 00 36 00 00 00 37 40 40 40 38 40 40 40 39 40 40 40 3a 00 00 00 3b 00 00 00 3c 00 00 00 3d 00 00 00 3e 00 00 00

It's missing the last "3f 00 00 00 f7"

Ah no that arrives later

I do get:

Nov 29 22:36:50 tp exo_vm[1381092]: JackAudioDriver::ProcessGraphAsyncMaster: Process error
Nov 29 22:36:50 tp exo_vm[1452268]:  3f 00 00 00 f7
Nov 29 22:36:50 tp exo_vm[1381092]: JackEngine::XRun: client = hub was not finished, state = Running
Nov 29 22:36:50 tp exo_vm[1381092]: JackAudioDriver::ProcessGraphAsyncMaster: Process error

But the message gets across.

EDIT: Found a post online mentioning issues with a2jmidid and sysex,
mentioning that j2amidi_bridge worked.

https://linuxmusicians.com/viewtopic.php?t=25434

I had problems with this before, the 3if sysex implementation.

So it seems that first I need to figure out what j2amidi_bridge does
as compared to a2jmidid.

EDIT: This is not for now

Find something else to do.



Entry: fixing this sysex thing
Date: Fri Dec  1 09:00:44 AM CET 2023

Not just for the Fire.  It really needs to work, also for the 3if.

What I smell: I am going to end up doing this myself, creating an alsa
seq client etc.

strogon15: behavior of Jack regarding Sysex messages longer than the
period length is currently undefined, afaik


This shit really doesn't work properly.
Loosing patience.

12 works
24 doesn't
16 works
20 doesn't

EDIT: It was just a hardcoded 

so i have a fix for now.  later maybe make a pull request.



Entry: pattern display
Date: Fri Dec  1 02:45:42 PM CET 2023

First: where do we keep the state?

The sequencer's data structure is probably enough.  It can be used to
regenerate.  So it's ok to just send events to the gui.

Maybe start with adding a mute option.

Ok that was easy.  Now some thinking is needed for the next step.

When a pattern is created, the led needs to be turned on.
How does that work?
Can this be a direct C call?

That's where the difficulty is: how do these things communicate?




Entry: next
Date: Fri Dec  1 03:50:02 PM CET 2023

two things are needed:
- button press event needs to call into the sequencer
- sequencer event needs to update the akai state

i think i want to do this with callbacks
otherwise things will get nested

EDIT:
added these callbacks.

EDIT:
alright, works!

just needs a fix to not let empty patterns linger
